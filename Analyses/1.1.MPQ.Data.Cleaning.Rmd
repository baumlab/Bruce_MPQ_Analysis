---
title: "1.1.MPQ.Data.Cleaning"
author: "Kevin Bruce"
date: "11/10/2020"
output: html_document
---
#Load R Packages
```{r load packages, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load Packages
library(dplyr)
library(ggplot2)
library(stats)
library(Rmisc)
library(here)
library(ggpmisc)
library(knitr)
library(magick)
library(gridExtra)
library(car)
library(tidyr)
library(readxl)
library(vegan)
library(tidyverse)
library(DHARMa)
library(reshape2)

```

# Cloud Compare Volumetric Analysis
```{r Clean CloudCompare Data, include=FALSE}
###################################################
##### NEW CLOUD COMPARE DATA WITH TRUE VALUES ####
##################################################

#Set the Working Directory
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data")

#Load CloudCompare data
CC.new <- read.csv("BaumLab_CloudCompare_Final.csv")

#Change colnames for the collumns
colnames(CC.new)[which(names(CC.new)=="Hum_Dist")] <- "hum_dist"
colnames(CC.new)[which(names(CC.new)=="Period")] <- "timepoint"
colnames(CC.new)[which(names(CC.new)=="MPQ")] <- "ppq"
colnames(CC.new)[which(names(CC.new)=="Site")] <- "site"
colnames(CC.new)[which(names(CC.new)=="Volume")] <- "volume.change"
colnames(CC.new)[which(names(CC.new)=="Added.Volume")] <- "volume.added"
colnames(CC.new)[which(names(CC.new)=="Removed.Volume")] <- "volume.removed"

colnames(CC.new)


#For loop time! Make for looks to add values for human disturbance, publication site name, and region
#Add according values to human dist collumn
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$hum_dist[i] <- "Very Low"
  } else if(CC.new$site[i]=="19") {
    CC.new$hum_dist[i] <- "Very Low"
  } else if(CC.new$site[i]=="15") {
    CC.new$hum_dist[i] <- "Very Low"
  } else if(CC.new$site[i]=="8") {
    CC.new$hum_dist[i] <- "Medium"
  } else if(CC.new$site[i]=="34") {
    CC.new$hum_dist[i] <- "Medium"
  } else if(CC.new$site[i]=="35") {
   CC.new$hum_dist[i] <- "Medium"
  } else if(CC.new$site[i]=="27") {
   CC.new$hum_dist[i] <- "Very High"
  } else if(CC.new$site[i]=="30") {
   CC.new$hum_dist[i] <- "Very High"
  } else if(CC.new$site[i]=="32") {
    CC.new$hum_dist[i] <- "Very High"
  } else if(CC.new$site[i]=="37") {
    CC.new$hum_dist[i] <- "Very Low"
  }}

#2. Create 4 subsections for the region collumn:
#2a: Side of island (2 levels)
CC.new$island.side <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="19") {
    CC.new$island.side[i] <- "Windward"
  } else if(CC.new$site[i]=="15") {
    CC.new$island.side[i] <- "Windward"
  } else if(CC.new$site[i]=="8") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="34") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="35") {
   CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="27") {
   CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="30") {
   CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="32") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="37") {
    CC.new$island.side[i] <- "Leeward"
  }}

#2b. Region.3 = 3 levels
CC.new$region.3 <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$region.3[i] <- "South Shore"
  } else if(CC.new$site[i]=="19") {
    CC.new$region.3[i] <- "Windward"
  } else if(CC.new$site[i]=="15") {
    CC.new$region.3[i] <- "Windward"
  } else if(CC.new$site[i]=="8") {
    CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="34") {
    CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="35") {
   CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="27") {
   CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="30") {
   CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="32") {
    CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="37") {
    CC.new$region.3[i] <- "South Shore"
  }}

#2c. Region.4 = 4 levels
CC.new$region.4 <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$region.4[i] <- "Vaskess Bay"
  } else if(CC.new$site[i]=="19") {
    CC.new$region.4[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="15") {
    CC.new$region.4[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="8") {
    CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="34") {
    CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="35") {
   CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="27") {
   CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="30") {
   CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="32") {
    CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="37") {
    CC.new$region.4[i] <- "Vaskess Bay"
  }}


#2d. Full Region Breakdown (5 levels)
#2c. Region.4 = 4 levels
CC.new$region.full <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$region.full[i] <- "Vaskess Bay"
  } else if(CC.new$site[i]=="19") {
    CC.new$region.full[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="15") {
    CC.new$region.full[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="8") {
    CC.new$region.full[i] <- "South Lagoon"
  } else if(CC.new$site[i]=="34") {
    CC.new$region.full[i] <- "South Lagoon"
  } else if(CC.new$site[i]=="35") {
   CC.new$region.full[i] <- "South Lagoon"
  } else if(CC.new$site[i]=="27") {
   CC.new$region.full[i] <- "North Lagoon"
  } else if(CC.new$site[i]=="30") {
   CC.new$region.full[i] <- "North Lagoon"
  } else if(CC.new$site[i]=="32") {
    CC.new$region.full[i] <- "Mid Lagoon"
  } else if(CC.new$site[i]=="37") {
    CC.new$region.full[i] <- "Vaskess Bay"
  }}

#3 Assign publication name to site
CC.new$pub.site <- "a"

#Assign pub site values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$pub.site[i] <- "VL3"
  } else if(CC.new$site[i]=="19") {
    CC.new$pub.site[i] <- "VL2"
  } else if(CC.new$site[i]=="15") {
    CC.new$pub.site[i] <- "VL1"
  } else if(CC.new$site[i]=="8") {
    CC.new$pub.site[i] <- "M1"
  } else if(CC.new$site[i]=="34") {
    CC.new$pub.site[i] <- "M3"
  } else if(CC.new$site[i]=="35") {
   CC.new$pub.site[i] <- "M2"
  } else if(CC.new$site[i]=="27") {
   CC.new$pub.site[i] <- "VH1"
  } else if(CC.new$site[i]=="30") {
   CC.new$pub.site[i] <- "VH3"
  } else if(CC.new$site[i]=="32") {
    CC.new$pub.site[i] <- "VH2"
  } else if(CC.new$site[i]=="37") {
    CC.new$pub.site[i] <- "VL4"
  }}

colnames(CC.new)





#Remove the extra collums in the cloudcompare data that aren't necessary
CC.new <- subset(CC.new, select = c("pub.site","site", "ppq","hum_dist", "island.side" ,"region.3", "region.4", "region.full", "Initial.Timepoint", "Final.Timepoint", "timepoint", "volume.change"))
colnames(CC.new)
CC.new



#Change levels of sites to match disturbance level
CC.new$site <- factor(CC.new$site, levels = c("27", "30", "32", "8", "34", "35", "5", "15", "19", "37"))


#Check structure of CC
str(CC.new)   ###human_dist is a factor, which we need to change to a character

#Change hum_dist and mpq to a character
CC.new$hum_dist <- as.character(CC.new$hum_dist)
CC.new$ppq <- as.character(CC.new$ppq)
CC.new$site <- as.character(CC.new$site)

str(CC.new)

#Assign levels to CC$hum_dist
levels(CC.new$hum_dist)
CC.new$hum_dist <- factor(CC.new$hum_dist, levels = c("Very High","Medium", "Very Low"))
levels(CC.new$hum_dist)

#Create new collumn to bind two dataframes together with (after creating 2017-2019 calculated dataframe)
CC.new$ID <- paste(CC.new$pub.site, CC.new$ppq, sep=".")

CC.new$timeblock <- "blank"

# #for loop to assign "timeblock" values to timepoints to make future for loop easier
# for(i in 1:length(CC.new$timepoint)) {
#   if(CC.new$timepoint[i] == "2015-2017"){
#     CC.new$timeblock[i] <- 1 } 
#   if(CC.new$timepoint[i] == "2017-2019"){
#     CC.new$timeblock[i] <- 3 }
#   if(CC.new$timepoint[i] == "2015-2019"){
#     CC.new$timeblock[i] <- 2 }
#   }

#for loop to assign "timeblock" values to timepoints to make future for loop easier
for(i in 1:length(CC.new$timepoint)) {
  if(CC.new$timepoint[i] == "A"){
    CC.new$timeblock[i] <- 1 } 
  if(CC.new$timepoint[i] == "B"){
    CC.new$timeblock[i] <- 3 }
  if(CC.new$timepoint[i] == "C"){
    CC.new$timeblock[i] <- 2 }
  }

#Remove unneeded collumns
CC.new.1 <- CC.new[,-(9:10)]

#Calculate 2017-2019 Timepoint
#Create new dataframe
CC.new.2 <- as.data.frame(matrix(data=NA,ncol=12, nrow=50))

colnames(CC.new.2) <- colnames(CC.new.1)

ID.variables <- unique(CC.new.1$ID)

#forloop
for(i in 1:length(ID.variables)) {
  xx <- subset(CC.new.1, ID == ID.variables[i])
  after <- xx %>% filter(timeblock == 3)
  if(length(after$timepoint) > 0) next
  before <- xx %>% filter(timeblock == 1)
  full <- xx %>% filter(timeblock == 2)
  before_value <- before$volume.change[1]
  full_value <- full$volume.change[1]
  after_value <- full_value - before_value
  CC.new.2$island.side[i] <- before$island.side[1]
  CC.new.2$timepoint[i] <- "2017-2019"
  CC.new.2$hum_dist[i] <- before$hum_dist[1]
  CC.new.2$site[i] <- before$site[1]
  CC.new.2$pub.site[i] <- before$pub.site[1]
  CC.new.2$ppq[i] <- before$ppq[1]
  CC.new.2$region.3[i] <- before$region.3[1]
  CC.new.2$region.4[i] <- before$region.4[1]
  CC.new.2$region.full[i] <- before$region.full[1]
  CC.new.2$volume.change[i] <- after_value
  CC.new.2$ID[i] <- before$ID[1]
  CC.new.2$timeblock[i] <- 3  
  
}

CC.new.2.1 <- CC.new.2 %>% drop_na()

#Change structure around of new df
CC.new.2.1$hum_dist <- as.factor(CC.new.2.1$hum_dist)
CC.new.2.1$hum_dist <- factor(CC.new.2.1$hum_dist, levels = c("Very High","Medium", "Very Low"))
levels(CC.new.2.1$hum_dist)

#Change timepoint information from A, B,C to year differences
CC.new.2.1$timepoint <- factor(CC.new.2.1$timepoint, levels =c("A", "B", "C"), labels = c("2015-2017", "2017-2019", "2015-2019"))

str(CC.new.1)
levels(CC.new.1$timepoint)

str(CC.new.2.1)

CC.new.2.1$timepoint <- "B"

#Change timepoint information from A, B,C to year differences
CC.new$timepoint <- factor(CC.new$timepoint, levels =c("A", "B", "C"), labels = c("2015-2017", "2017-2019", "2015-2019"))
CC.new


#Bind two together
CC.total <- rbind(CC.new.1, CC.new.2.1)

#Fix human disturbance values
for(i in c(1:nrow(CC.total))) {
  if(CC.total$site[i]=="5") {
    CC.total$hum_dist[i] <- "Very Low"
  } else if(CC.total$site[i]=="19") {
    CC.total$hum_dist[i] <- "Very Low"
  } else if(CC.total$site[i]=="15") {
    CC.total$hum_dist[i] <- "Very Low"
  } else if(CC.total$site[i]=="8") {
    CC.total$hum_dist[i] <- "Medium"
  } else if(CC.total$site[i]=="34") {
    CC.total$hum_dist[i] <- "Medium"
  } else if(CC.total$site[i]=="35") {
   CC.total$hum_dist[i] <- "Medium"
  } else if(CC.total$site[i]=="27") {
   CC.total$hum_dist[i] <- "Very High"
  } else if(CC.total$site[i]=="30") {
   CC.total$hum_dist[i] <- "Very High"
  } else if(CC.total$site[i]=="32") {
    CC.total$hum_dist[i] <- "Very High"
  } else if(CC.total$site[i]=="37") {
    CC.total$hum_dist[i] <- "Very Low"
  }}

CC.total

#Add in continuous human disturbance gradient scores
CC.total$hdist.cont <- 1

#Input values 
for(i in c(1:nrow(CC.total))) {
  if(CC.total$site[i]=="5") {
    CC.total$hdist.cont[i] <- "0"
  } else if(CC.total$site[i]=="19") {
    CC.total$hdist.cont[i] <- "0"
  } else if(CC.total$site[i]=="15") {
    CC.total$hdist.cont[i] <- "0"
  } else if(CC.total$site[i]=="8") {
    CC.total$hdist.cont[i] <- "1212.82819"
  } else if(CC.total$site[i]=="34") {
    CC.total$hdist.cont[i] <- "1212.82819"
  } else if(CC.total$site[i]=="35") {
   CC.total$hdist.cont[i] <- "1212.82819"
  } else if(CC.total$site[i]=="27") {
   CC.total$hdist.cont[i] <- "7276"
  } else if(CC.total$site[i]=="30") {
   CC.total$hdist.cont[i] <- "5085.68478"
  } else if(CC.total$site[i]=="32") {
    CC.total$hdist.cont[i] <- "4860.7457"
  } else if(CC.total$site[i]=="37") {
    CC.total$hdist.cont[i] <- "0"
  }}


#Create Final Output file to model
CC.final <- CC.total[,-(11:12)]

#Square Root transform the h.dist continuous variable
CC.final$sqrt.hdist.cont <- 1
str(CC.final$hdist.cont) 
CC.final$hdist.cont <- as.numeric(CC.final$hdist.cont) #Make continuous value a numeric
CC.final$sqrt.hdist.cont <- sqrt(CC.final$hdist.cont)

colnames(CC.final)

#Set levels for each dataframe
CC.final$timepoint.site.ppq <- paste(CC.final$timepoint, CC.final$site, CC.final$ppq, sep = ".")
levels(CC.final$timepoint.site.ppq)
head(CC.final$timepoint.site.ppq)
CC.final$timepoint.site.ppq<- factor(CC.final$timepoint.site.ppq, levels = c("A.27.1","A.27.2","A.27.3", "A.32.1","A.32.2", "A.32.3", "A.30.1", "A.30.2","A.30.3", "A.8.1","A.8.2", "A.8.3", "A.35.1","A.35.2", "A.35.3", "A.34.1", "A.34.2", "A.34.3", "A.15.1", "A.15.2", "A.15.3", "A.19.1", "A.19.2", "A.5.1", "A.5.2", "A.5.3","B.27.1","B.27.2","B.27.3", "B.32.1","B.32.2", "B.32.3", "B.30.1", "B.30.2","B.30.3", "B.8.1","B.8.2", "B.8.3", "B.35.1","B.35.2", "B.35.3", "B.34.1", "B.34.2", "B.34.3", "B.5.1","B.5.2", "B.5.3",  "B.37.1", "B.37.2", "B.37.3", "C.27.1","C.27.2","C.27.3", "C.32.1","C.32.2", "C.32.3", "C.30.1", "C.30.2","C.30.3", "C.8.1","C.8.2", "C.8.3", "C.35.1","C.35.2", "C.35.3", "C.34.1", "C.34.2", "C.34.3", "C.5.1","C.5.2", "C.5.3"))

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
CC.final<- CC.final[order(CC.final$timepoint.site.ppq),]
row.names(CC.final) <- 1:nrow(CC.final) #Changes the row names so that they are re-orderd 1-80

#Convert Timepoint to year range
CC.final$timepoint <- factor(CC.final$timepoint, levels =c("A", "B", "C"), labels = c("2015-2017", "2017-2019", "2015-2019"))
CC.final

CC.final <- subset(CC.final, select = c("pub.site", "site", "ppq", "hum_dist","sqrt.hdist.cont", "island.side", "region.3", "region.4", "region.full", "timepoint", "volume.change"))

#Export Clean Data as a csv
write.csv(CC.final, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_CloudCompare_Data_Clean_11Dec2020.csv")
```

# ArcMap Complexity
```{r Clean ArcMap complexity data, include = FALSE}
#Set the Working Directory
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data")

#Load the data
mpq <- read.csv("ArcMAP_MPQ_Complexity_FINAL.csv")

#Change collumn headers to make it easier to code
colnames(mpq)[which(names(mpq)=="Year")] <- "year"
colnames(mpq)[which(names(mpq)=="Site")] <- "site"
colnames(mpq)[which(names(mpq)=="plot")] <- "ppq"
colnames(mpq)[which(names(mpq)=="DEM.scale")] <- "DEM"
colnames(mpq)[which(names(mpq)=="Complexity.Calculation")] <- "rug"
colnames(mpq)[which(names(mpq)=="Avg..BTM_Slope")] <- "slope"
colnames(mpq)[which(names(mpq)=="Avg_terrain_ruggedness..VRM."  )] <- "vrm"
colnames(mpq)[which(names(mpq)=="profile.curvature")] <- "pro.curv"
colnames(mpq)[which(names(mpq)=="planform.curvature")] <- "plan.curv"
colnames(mpq)[which(names(mpq)=="average.curvature")] <- "curv"
colnames(mpq)[which(names(mpq)=="SHAPE_Area")] <- "area_2d"
colnames(mpq)[which(names(mpq)=="SArea")] <- "area_3d"

#Do 3 for-loops of assigning values in new collumns
#1 to assign human disturbance levels
#2 to assign sites to a region 
#3 to assign publication name to site

#1: For look to add human distrubance levels
#Add human_dist collumn to kb Dataframe
mpq$hum_dist <- "a"

# #Delete rows in site collum that are NA
# mpq %>% filter(!is.na(site))
# tail(mpq$site)

#Add according values to human dist collumn
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$hum_dist[i] <- "Very Low"
  } else if(mpq$site[i]=="19") {
    mpq$hum_dist[i] <- "Very Low"
  } else if(mpq$site[i]=="15") {
    mpq$hum_dist[i] <- "Very Low"
  } else if(mpq$site[i]=="8") {
    mpq$hum_dist[i] <- "Medium"
  } else if(mpq$site[i]=="34") {
    mpq$hum_dist[i] <- "Medium"
  } else if(mpq$site[i]=="35") {
   mpq$hum_dist[i] <- "Medium"
  } else if(mpq$site[i]=="27") {
   mpq$hum_dist[i] <- "Very High"
  } else if(mpq$site[i]=="30") {
   mpq$hum_dist[i] <- "Very High"
  } else if(mpq$site[i]=="32") {
    mpq$hum_dist[i] <- "Very High"
  } else if(mpq$site[i]=="37") {
    mpq$hum_dist[i] <- "Very Low"
  }}

#2. Create a collumn for my region assignments & fill it with values
mpq$region.kb <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.kb[i] <- "Vaskes"
  } else if(mpq$site[i]=="19") {
    mpq$region.kb[i] <- "BOW"
  } else if(mpq$site[i]=="15") {
    mpq$region.kb[i] <- "BOW"
  } else if(mpq$site[i]=="8") {
    mpq$region.kb[i] <- "S.Lagoon"
  } else if(mpq$site[i]=="34") {
    mpq$region.kb[i] <- "S.Lagoon"
  } else if(mpq$site[i]=="35") {
   mpq$region.kb[i] <- "S.Lagoon"
  } else if(mpq$site[i]=="27") {
   mpq$region.kb[i] <- "N.Lagoon"
  } else if(mpq$site[i]=="30") {
   mpq$region.kb[i] <- "N.Lagoon"
  } else if(mpq$site[i]=="32") {
    mpq$region.kb[i] <- "N.Lagoon"
  } else if(mpq$site[i]=="37") {
    mpq$region.kb[i] <- "Vaskes"
  }}

#3 Assign publication name to site
mpq$pub.site <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$pub.site[i] <- "VL3"
  } else if(mpq$site[i]=="19") {
    mpq$pub.site[i] <- "VL3"
  } else if(mpq$site[i]=="15") {
    mpq$pub.site[i] <- "VL1"
  } else if(mpq$site[i]=="8") {
    mpq$pub.site[i] <- "M1"
  } else if(mpq$site[i]=="34") {
    mpq$pub.site[i] <- "M3"
  } else if(mpq$site[i]=="35") {
   mpq$pub.site[i] <- "M2"
  } else if(mpq$site[i]=="27") {
   mpq$pub.site[i] <- "VH1"
  } else if(mpq$site[i]=="30") {
   mpq$pub.site[i] <- "VH3"
  } else if(mpq$site[i]=="32") {
    mpq$pub.site[i] <- "VH2"
  } else if(mpq$site[i]=="37") {
    mpq$pub.site[i] <- "VL4"
  }}


mpq

#Create dataframe with only columns I require
mpq.temp <- subset(mpq, select = c("year","hum_dist","site", "pub.site", "ppq", "DEM", "area_2d", "area_3d", "rug", "slope", "vrm", "curv", "pro.curv", "plan.curv", "region.kb"))

#Switch dataframe name back to mpq
mpq <- mpq.temp
str(mpq)

# #Create unique colname
mpq$year.site.ppq <- paste(mpq$year, mpq$site, mpq$ppq, sep = ".")

#Change descriptors to factors (Ex: Year, region, disturbance)
# mpq$region <- as.factor(mpq$region) 
# levels(mpq$region)
mpq$hum_dist <- as.factor(mpq$hum_dist) 
mpq$hum_dist <- factor(mpq$hum_dist, levels = c("Very Low", "Medium", "Very High" ))
mpq$site <- factor(mpq$site, levels =c("27", "30", "32", "8", "34", "35", "5", "15", "19", "37"))
levels(mpq$hum_dist)
#levels(mpq$site.ppq)
#mpq$site.ppq<- factor(mpq$site.ppq, levels = c("27.1", "27.2", "27.3", "30.1", "30.2", "30.3", "32.1", "32.2", "32.3", "8.1", "8.2", "8.3", "34.1", "34.2", "34.3", "35.1", "35.2", "35.3", "5.1", "5.2", "5.3", "15.1", "15.2", "15.3", "19.1", "19.2", "19.3", "37.1", "37.2", "37.3"))

#Reorder the dataframe
colnames(mpq)
mpq <- subset(mpq, select = c ("year",  "hum_dist",  "pub.site", "site","ppq", "DEM", "area_2d", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "region.kb"))

#Add in region collumns according to KI publication records
#2. Create 4 subsections for the region collumn:
#2a: Side of island (2 levels)
mpq$island.side <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="19") {
    mpq$island.side[i] <- "Windward"
  } else if(mpq$site[i]=="15") {
    mpq$island.side[i] <- "Windward"
  } else if(mpq$site[i]=="8") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="34") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="35") {
   mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="27") {
   mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="30") {
   mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="32") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="37") {
    mpq$island.side[i] <- "Leeward"
  }}

#2b. Region.3 = 3 levels
mpq$region.3 <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.3[i] <- "South Shore"
  } else if(mpq$site[i]=="19") {
    mpq$region.3[i] <- "Windward"
  } else if(mpq$site[i]=="15") {
    mpq$region.3[i] <- "Windward"
  } else if(mpq$site[i]=="8") {
    mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="34") {
    mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="35") {
   mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="27") {
   mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="30") {
   mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="32") {
    mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="37") {
    mpq$region.3[i] <- "South Shore"
  }}

#2c. Region.4 = 4 levels
mpq$region.4 <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.4[i] <- "Vaskess Bay"
  } else if(mpq$site[i]=="19") {
    mpq$region.4[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="15") {
    mpq$region.4[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="8") {
    mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="34") {
    mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="35") {
   mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="27") {
   mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="30") {
   mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="32") {
    mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="37") {
    mpq$region.4[i] <- "Vaskess Bay"
  }}


#2d. Full Region Breakdown (5 levels)
#2c. Region.4 = 4 levels
mpq$region.full <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.full[i] <- "Vaskess Bay"
  } else if(mpq$site[i]=="19") {
    mpq$region.full[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="15") {
    mpq$region.full[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="8") {
    mpq$region.full[i] <- "South Lagoon"
  } else if(mpq$site[i]=="34") {
    mpq$region.full[i] <- "South Lagoon"
  } else if(mpq$site[i]=="35") {
   mpq$region.full[i] <- "South Lagoon"
  } else if(mpq$site[i]=="27") {
   mpq$region.full[i] <- "North Lagoon"
  } else if(mpq$site[i]=="30") {
   mpq$region.full[i] <- "North Lagoon"
  } else if(mpq$site[i]=="32") {
    mpq$region.full[i] <- "Mid Lagoon"
  } else if(mpq$site[i]=="37") {
    mpq$region.full[i] <- "Vaskess Bay"
  }}

#Add in continuous human disturbance gradient scores
mpq$hdist.cont <- 1

#Input values 
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$hdist.cont[i] <- "0"
  } else if(mpq$site[i]=="19") {
    mpq$hdist.cont[i] <- "0"
  } else if(mpq$site[i]=="15") {
    mpq$hdist.cont[i] <- "0"
  } else if(mpq$site[i]=="8") {
    mpq$hdist.cont[i] <- "1212.82819"
  } else if(mpq$site[i]=="34") {
    mpq$hdist.cont[i] <- "1212.82819"
  } else if(mpq$site[i]=="35") {
   mpq$hdist.cont[i] <- "1212.82819"
  } else if(mpq$site[i]=="27") {
   mpq$hdist.cont[i] <- "7276"
  } else if(mpq$site[i]=="30") {
   mpq$hdist.cont[i] <- "5085.68478"
  } else if(mpq$site[i]=="32") {
    mpq$hdist.cont[i] <- "4860.7457"
  } else if(mpq$site[i]=="37") {
    mpq$hdist.cont[i] <- "0"
  }}


colnames(mpq)
mpq$hdist.cont <- as.numeric(mpq$hdist.cont)

#Square Root transform the h.dist continuous variable
mpq$sqrt.hdist.cont <- 1
mpq$sqrt.hdist.cont <- sqrt(mpq$hdist.cont) 
str(mpq$sqrt.hdist.cont)

#Reorder dataframe to export for future analyses
mpq1 <- subset(mpq, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont","sqrt.hdist.cont","island.side", "region.3", "region.4", "region.full", "region.kb", "DEM", "area_2d", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv"))



#<----------------------------------------------------------------------------------------------------------------------------------------------------
#Create unique id collumn
mpq1$year.site.ppq <- paste(mpq1$year, mpq1$site, mpq1$ppq, sep = ".")

#Break up by DEM
mpq.1 <- subset(mpq1, DEM == 1)
mpq.4 <- subset(mpq1, DEM == 4)
mpq.8 <- subset(mpq1, DEM == 8)

#<--------------------------------------------------------------------------------------------------------->
#1cm DEM
#Set levels for each dataframe
levels(mpq.1$year.site.ppq)
mpq.1$year.site.ppq<- factor(mpq.1$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.1$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
mpq.1<- mpq.1[order(mpq.1$year.site.ppq),]
row.names(mpq.1) <- 1:nrow(mpq.1) #Changes the row names so that they are re-orderd 1-80

#<--------------------------------------------------------------------------------------------------------->
#4cm DEM
#Set levels for each dataframe
levels(mpq.4$year.site.ppq)
mpq.4$year.site.ppq<- factor(mpq.4$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.4$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
mpq.4<- mpq.4[order(mpq.4$year.site.ppq),]
row.names(mpq.4) <- 1:nrow(mpq.4) #Changes the row names so that they are re-orderd 1-80

#<--------------------------------------------------------------------------------------------------------->
#8cm DEM
#Set levels for each dataframe
levels(mpq.8$year.site.ppq)
mpq.8$year.site.ppq<- factor(mpq.8$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.8$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
mpq.8<- mpq.8[order(mpq.8$year.site.ppq),]
row.names(mpq.8) <- 1:nrow(mpq.8) #Changes the row names so that they are re-orderd 1-80
#<--------------------------------------------------------------------------------------------------------->
#Merge all 3 DEM df's together
mpq.all <- rbind(mpq.1, mpq.4, mpq.8)


#<--------------------------------------------------------------------------------------------------------->
#Break dataframe up into its sub-components
mpq.all #Dataframe with all 5 timepoints for initial modelling

#Export complexity dataframeDataframe
write.csv(mpq.all, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_ALL_Data_Clean_FINAL.11Dec2020.csv")



```

### Fractal Dimension Calculation

- For these caluclations, Atsuko's code mentioned calculating log(3d area/2d area), which she says is "to account for changes in area due to raster aggregate function". We didn't use R to aggregate different resolution values, so therefore I decided to just use 3d area. 

- This appears to be the right decision, as Young et al. (2015) did a similar calcualtion and state that "D is between 2 and 3 for a surface, with a greater number indicating greater complexity" 


```{r Fractal Dimension Calculation}
#Equation is D = 2-(slope log(S(s))/log(s))
#     s = resolution of the DEM in meters (ex: 0.01, 0.04, 0.08)
#     S(s) = 3D surface area at the given resolution 


# Atsuko did 3D/2D ratio to # using log(s_area/area) to account for changes in are due to raster aggregate function (unsure if we should do that. We didn't use aggregate function, but will get values similar to Johns.....)


#Create new dataframe to house fractal dimension data
frac <- mpq1

#Drop Complexity measures
frac <- frac[,-(16:20)] #Remove complexity metrics but leave area_3d
frac <- frac[,-(14)] #Remove area_2d

#And make a single DEM category to link back all metadata to
frac.1 <- subset(mpq, DEM == 1)

#Create unique col name
frac.1$year.site.ppq <- paste(frac.1$year, frac.1$site, frac.1$ppq, sep = ".")

nrow(frac.1) #127
nrow(frac) #381

str(frac)

frac$DEM <- as.numeric(frac$DEM)

#Change DEM scale from cm to meters
frac$resolution <- frac$DEM / 100

#Do math each row to get the frac.val
frac$frac.val <- 1

str(frac)

#Make year.site.ppq collumn
frac$year.site.ppq <- paste(mpq$year, mpq$site, mpq$ppq, sep = ".")

#Now do the math via  a for loop
for(i in 1:nrow(frac)){
frac$frac.val[i] = (log(frac$area_3d[i])/log(frac$resolution[i]))
}

#Make a table for the slopes
slope <- as.data.frame(matrix(data=NA, nrow=length(unique(frac.1$year.site.ppq)), ncol= 2))
colnames(slope) <- c("year.site.ppq", "slope.val")
slope$year.site.ppq <- unique(frac.1$year.site.ppq)
slope$year <- frac.1$year
slope$hum_dist <- frac.1$hum_dist
slope$region <- frac.1$region
slope$pub.site <- frac.1$pub.site
slope$site <- frac.1$site
slope$site.ppq <- frac.1$site.ppq
slope$ppq <- frac.1$ppq
slope$island.side <- frac.1$island.side
slope$region.3 <- frac.1$region.3
slope$region.4 <- frac.1$region.4
slope$region.full <- frac.1$region.full



#### It is refusing to make any slope values for the 2016 data....
for (i in 1:nrow(slope)){
  xx <- subset(frac, year.site.ppq == slope$year.site.ppq[i])
  lm_i <- lm(resolution ~ frac.val, xx)
  slope_i <- coef(lm_i)[[2]]
  slope$slope.val[i] <- slope_i
}


slope$fractal.dimension <- 2- slope$slope.val

ggplot(slope, aes (x= year.site.ppq, y= fractal.dimension)) + geom_point()

colnames(slope)

#Add in continuous human disturbance gradient scores
slope$hdist.cont <- 1

#Input values 
for(i in c(1:nrow(slope))) {
  if(slope$site[i]=="5") {
    slope$hdist.cont[i] <- "0"
  } else if(slope$site[i]=="19") {
    slope$hdist.cont[i] <- "0"
  } else if(slope$site[i]=="15") {
    slope$hdist.cont[i] <- "0"
  } else if(slope$site[i]=="8") {
    slope$hdist.cont[i] <- "1212.82819"
  } else if(slope$site[i]=="34") {
    slope$hdist.cont[i] <- "1212.82819"
  } else if(slope$site[i]=="35") {
   slope$hdist.cont[i] <- "1212.82819"
  } else if(slope$site[i]=="27") {
   slope$hdist.cont[i] <- "7276"
  } else if(slope$site[i]=="30") {
   slope$hdist.cont[i] <- "5085.68478"
  } else if(slope$site[i]=="32") {
    slope$hdist.cont[i] <- "4860.7457"
  } else if(slope$site[i]=="37") {
    slope$hdist.cont[i] <- "0"
  }}


colnames(slope)
slope$hdist.cont <- as.numeric(slope$hdist.cont)

#Square Root transform the h.dist continuous variable
slope$sqrt.hdist.cont <- 1
slope$sqrt.hdist.cont <- sqrt(slope$hdist.cont) 
str(slope$sqrt.hdist.cont)

#Order dataframe properly
#Set levels for each dataframe
levels(slope$year.site.ppq)
slope$year.site.ppq<- factor(slope$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(slope$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
slope<- slope[order(slope$year.site.ppq),]
row.names(slope) <- 1:nrow(slope) #Changes the row names so that they are re-orderd 1-80

head(slope)
#Reorder dataframe
slope1 <- subset(slope, select = c("year", "hum_dist", "sqrt.hdist.cont","pub.site", "site", "ppq", "island.side", "region.3", "fractal.dimension"))


ggplot(slope1, aes(x = year, y=fractal.dimension, fill=year)) + geom_boxplot() + theme_classic(base_size = 16) + xlab("Year") + ylab("Fractal Dimension") +  theme(legend.position="none")

#Fractal Dimension dataframe
slope1
frac <- subset(slope1, select = c("fractal.dimension")) #To combine with other metrics in 1cm DEM group
  
```

### ArcMap Complexity Range Calculations
```{r curvature range calculations}
#Set the Working Directory
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data")

#Load CloudCompare data
ranges <- read.csv("Complexty.Range.Raw.csv", row.names = 1)

#Create new columns
ranges$vrm.range <- 1 
ranges$pro.range <- 2
ranges$plan.range <- 3

#Calculate range values for vrm, pro, & plan curvatures
ranges$vrm.range <- ranges$vrm.max - ranges$vrm.min
ranges$pro.range <- ranges$pro.max - ranges$pro.min
ranges$plan.range <- ranges$plan.max - ranges$plan.min

#Create final dataframe to later merge with other complexity dataset
range.final <- ranges[,-(6:14)]

#ggplot(range.final, aes(x = year, y=pro.range, fill=year)) + geom_boxplot() + theme_classic(base_size = 18) + xlab("") + ylab("Mean") + ggtitle("Profile Curvature") + year.colscale +  theme(legend.position="none") 



#Add onto complexity dataframe
mpq.all #complexity metrics
colnames(mpq.all)
mpq <- cbind(mpq.all, range.final)

#Add collumns of log-transformed profile range
mpq$pro.range.log <- log(mpq$pro.range)
mpq$plan.range.log <- log(mpq$plan.range)

#ReOrder dataframe
colnames(mpq)
mpq <- subset(mpq, select = c("year", "pub.site",  "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "year.site.ppq", "area_2d", "area_3d", "rug", "vrm", "vrm.range", "curv", "pro.curv", "pro.range.log", "plan.curv", "plan.range.log"))



#Sumset total dataframe here by DEM scales
mpq.1cm <- subset(mpq, DEM == 1)
mpq.4cm <- subset(mpq, DEM == 4)
mpq.8cm <- subset(mpq, DEM == 8)

#Add Fractal Dimension data to 1cm
mpq.1cm.t <- cbind(mpq.1cm, frac)

#Export these dataframes as full complexity dataframe
write.csv(mpq.1cm.t, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/MPQ.Habitat.Structure.1cm.FULL.14Jan2020.csv")
write.csv(mpq.4cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/MPQ.Habitat.Structure.4cm.FULL.14Jan2020.csv")
write.csv(mpq.8cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/MPQ.Habitat.Structure.8cm.FULL.14Jan2020.csv")







#Dataframe to combine with digitization dataframe
mpq.3yrs <- subset(mpq, year == 2015 | year == 2017 | year == 2019) #Dataframe to link with digitization datasets
mpq.3yrs.1cm <- subset(mpq.3yrs, DEM == 1)
mpq.3yrs.4cm <- subset(mpq.3yrs, DEM == 4)
mpq.3yrs.8cm <- subset(mpq.3yrs, DEM == 8)

range.final
#Export Fractal Dimension Dataframe
write.csv(range.final, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/Range.Data.Final.csv")
write.csv(mpq, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/Complexity.Data.Final.21Dec2020.csv")


```

### ArcMap Complexity Distributions
```{r distributions of complexity data, include=FALSE}
mpq

#Metrics
#Surface Rugosity = bounded from 1 upwards
#VRM= "bounded" from 4 to -4, but never reaches those so should appear normal
#Profile Curvature = 
#Planform Curvature = 
# Habitat Volume = unbounded/continuous

###Surface Complexity##
#Simple linear model with DHARMa package to see residuals
m1a <- lm(rug ~ year, data= mpq)
m1.1a<- simulateResiduals(m1a)
plot(m1.1a)

#Not good, try going to a log-normal distribution
mpq$log.s.rug <- "blank"
mpq$log.s.rug <- log(mpq$rug)

#Log normal distribution
m1 <- lm(log.s.rug ~ year, data= mpq)
m1.1<- simulateResiduals(m1)
plot(m1.1)

ggplot(mpq, aes(x = rug)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(rug, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)

#Log transformed data
ggplot(mpq, aes(x = log.s.rug)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(log.s.rug, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


#VRM
m2 <- lm(vrm ~ year, data= mpq)
m2.1<- simulateResiduals(m2)
plot(m2.1)

##VRM
ggplot(mpq, aes(x = vrm)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .001, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(vrm, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


#Profile Curvature
m3 <- lm(pro.curv ~ year, data= mpq)
m3.1<- simulateResiduals(m3)
plot(m3.1)

ggplot(mpq, aes(x = pro.curv)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 10, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(pro.curv, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)

#Planform Curvature
m4 <- lm(plan.curv ~ year, data= mpq)
m4.1<- simulateResiduals(m4)
plot(m4.1)

ggplot(mpq, aes(x = plan.curv)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 10, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(plan.curv, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)

#Habitat Volume
m5 <- lm(volume.change ~ timepoint, data= CC.total)
m5.1<- simulateResiduals(m3)
plot(m5.1)

#Non-transformed data  
ggplot(CC.total, aes(x = volume.change)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(volume.change, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)



plot(fitted(m5), resid(m5))
qqnorm(resid(m5))
qqline(resid(m5))



#Transform to new distribution which can compute it out of negative values as well! (apparently not a good idea- according to DOM)
CC.total$cube.change <- "blank"
CC.total$cube.change <- CC.total$volume.change ^ 1/3

m5.a <- lm(cube.change ~ timepoint, data= CC.total)
m5.1.a<- simulateResiduals(m5.a)
plot(m5.1.a)


###### RANGE DATA #######
#VRM Range
m6 <- lm(vrm.range ~ year, data= range.final)
m6.1<- simulateResiduals(m6)
plot(m6.1)

#Non-transformed data  
ggplot(range.final, aes(x = vrm.range)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(vrm.range, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)



#Profile Curvature Range
m7 <- lm(pro.range ~ year, data= range.final)
m7.1<- simulateResiduals(m7)
plot(m7.1)

#Non-transformed data  
ggplot(range.final, aes(x = pro.range)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 100000, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(pro.range, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


#Planform Curvature Range
m8 <- lm(plan.range ~ year, data= range.final)
m8.1<- simulateResiduals(m8)
plot(m8.1)

#Non-transformed data  
ggplot(range.final, aes(x = plan.range)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 100000, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(plan.range, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


```

# ArcMap Digitization

## i. Digitization Data Cleaning (all plots- don't run each time (not required))
```{r complexity data clean, eval=FALSE, include=FALSE}
dig_sum #dataframe WHICH DATAFRAME IS THIS???

#Subset large dataframe into subsets of site
d5 <- subset (dig_sum, site == 5)
d5.1 <- subset (d5, ppq == 1)
d5.2 <- subset (d5, ppq == 2)
d5.3 <- subset (d5, ppq == 3)

d15 <- subset (dig_sum, site == 15)
d15.1 <- subset (d15, ppq == 1)
d15.2 <- subset (d15, ppq == 2)
d15.3 <- subset (d15, ppq == 3)


d19 <- subset (dig_sum, site == 19)
d19.1 <- subset (d19, ppq == 1)
d19.2 <- subset (d19, ppq == 2)
d19.3 <- subset (d19, ppq == 3)

d27 <- subset (dig_sum, site == 27)
d27.1 <- subset (d27, ppq == 1)
d27.2 <- subset (d27, ppq == 2)
d27.3 <- subset (d27, ppq == 3)

d30 <- subset (dig_sum, site == 30)
d30.1 <- subset (d30, ppq == 1)
d30.2 <- subset (d30, ppq == 2)
d30.3 <- subset (d30, ppq == 3)

d32 <- subset (dig_sum, site == 32)
d32.1 <- subset (d32, ppq == 1)
d32.2 <- subset (d32, ppq == 2)
d32.3 <- subset (d32, ppq == 3)

d8 <- subset (dig_sum, site == 8)
d8.1 <- subset (d8, ppq == 1)
d8.2 <- subset (d8, ppq == 2)
d8.3 <- subset (d8, ppq == 3)

d34 <- subset (dig_sum, site == 34)
d34.1 <- subset (d34, ppq == 1)
d34.2 <- subset (d34, ppq == 2)
d34.3 <- subset (d34, ppq == 3)

d35 <- subset (dig_sum, site == 35)
d35.1 <- subset (d35, ppq == 1)
d35.2 <- subset (d35, ppq == 2)
d35.3 <- subset (d35, ppq == 3)

d37 <- subset (dig_sum, site == 37)
d37.1 <- subset (d37, ppq == 1)
d37.2 <- subset (d37, ppq == 2)
d37.3 <- subset (d37, ppq == 3)

#Plot stacked barcharts of each subset with PPQ on X axis,=
#Site 5
ggplot(d5.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d5.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d5.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))


#Site 15
ggplot(d15.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d15.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d15.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

#Site 19
ggplot(d19.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d19.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d19.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

#Site 27
ggplot(d27.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d27.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d27.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

#Site 30
ggplot(d30.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d30.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d30.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))


#Site 32
ggplot(d32.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d32.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d32.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

#Site 8
ggplot(d8.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d8.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d8.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))


#Site 34
ggplot(d34.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d34.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d34.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

#Site 35
ggplot(d35.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d35.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d35.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

#Site 37
ggplot(d37.1, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d37.2, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

ggplot(d37.3, aes(y=Area, x=year.site.ppq, fill= Benthic_Morphology))+facet_wrap(~Benthic_Morphology, scales = "fixed", ncol= 3)  +geom_bar(stat = 'identity')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

```

### 1. Combine full dataframe 
```{r Combining and cleaning dataframes of digitization data, include = FALSE}
#loading the data
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data") 
dig.15 <- read.csv("2015.MPQ.Digitization.Data.Final.csv")
dig.17 <- read.csv("2017.MPQ.Digitization.Data.Final.csv")
dig.19 <- read.csv("2019.MPQ.Digitization.Data.Final.csv")

#Filter out extra collumns that mess up the merging process (if they exist)
names(dig.15)
names(dig.17)
names(dig.19)
#dig.15 <- dig.15 %>% select(-c (X, X.1, X.2, X.3, X.4, X.5)) <- to take out collumns I don't want
#dig.17 <- dig.17 %>% select(-c (X, X.1))
#dig.19 <- dig.19 %>% select(-c (X, X.1, X.2, X.3, X.4, X.5))

#Merge all data together
dig <- rbind(dig.15, dig.17, dig.19)

#Rename shape_area to area
colnames(dig)[which(names(dig)=="Year")] <- "year"
colnames(dig)[which(names(dig)=="SHAPE_Area")] <- "area"

#For loop time! Make for looks to add values for human disturbance, publication site name, and region
#1. Add according values to human dist collumn
#1a. Create a collumn for region & fill it with values
dig$hum_dist <- "a"

#1b. Add human dist values
for(i in c(1:nrow(dig))) {
  if(dig$site[i]=="5") {
    dig$hum_dist[i] <- "Very Low"
  } else if(dig$site[i]=="19") {
    dig$hum_dist[i] <- "Very Low"
  } else if(dig$site[i]=="15") {
    dig$hum_dist[i] <- "Very Low"
  } else if(dig$site[i]=="8") {
    dig$hum_dist[i] <- "Medium"
  } else if(dig$site[i]=="34") {
    dig$hum_dist[i] <- "Medium"
  } else if(dig$site[i]=="35") {
   dig$hum_dist[i] <- "Medium"
  } else if(dig$site[i]=="27") {
   dig$hum_dist[i] <- "Very High"
  } else if(dig$site[i]=="30") {
   dig$hum_dist[i] <- "Very High"
  } else if(dig$site[i]=="32") {
    dig$hum_dist[i] <- "Very High"
  } else if(dig$site[i]=="37") {
    dig$hum_dist[i] <- "Very Low"
  }}

#2a. Create a collumn for region & fill it with values
dig$region <- "a"

#2b. Assign Region values
for(i in c(1:nrow(dig))) {
  if(dig$site[i]=="5") {
    dig$region[i] <- "Vaskes"
  } else if(dig$site[i]=="19") {
    dig$region[i] <- "BOW"
  } else if(dig$site[i]=="15") {
    dig$region[i] <- "BOW"
  } else if(dig$site[i]=="8") {
    dig$region[i] <- "S.Lagoon"
  } else if(dig$site[i]=="34") {
    dig$region[i] <- "S.Lagoon"
  } else if(dig$site[i]=="35") {
   dig$region[i] <- "S.Lagoon"
  } else if(dig$site[i]=="27") {
   dig$region[i] <- "N.Lagoon"
  } else if(dig$site[i]=="30") {
   dig$region[i] <- "N.Lagoon"
  } else if(dig$site[i]=="32") {
    dig$region[i] <- "N.Lagoon"
  } else if(dig$site[i]=="37") {
    dig$region[i] <- "Vaskes"
  }}

#3a. Assign publication name to site
dig$pub.site <- "a"

#3b. Assign Region values
for(i in c(1:nrow(dig))) {
  if(dig$site[i]=="5") {
    dig$pub.site[i] <- "VL3"
  } else if(dig$site[i]=="19") {
    dig$pub.site[i] <- "VL2"
  } else if(dig$site[i]=="15") {
    dig$pub.site[i] <- "VL1"
  } else if(dig$site[i]=="8") {
    dig$pub.site[i] <- "M1"
  } else if(dig$site[i]=="34") {
    dig$pub.site[i] <- "M3"
  } else if(dig$site[i]=="35") {
   dig$pub.site[i] <- "M2"
  } else if(dig$site[i]=="27") {
   dig$pub.site[i] <- "VH1"
  } else if(dig$site[i]=="30") {
   dig$pub.site[i] <- "VH3"
  } else if(dig$site[i]=="32") {
    dig$pub.site[i] <- "VH2"
  } else if(dig$site[i]=="37") {
    dig$pub.site[i] <- "VL4"
  }}

# Make a unique column for year.site.ppq
dig$year.site.ppq <- paste(dig$year, dig$site, dig$ppq, sep=".") 
dig$site.ppq <- paste(dig$site, dig$ppq, sep=".") 


#Remove the extra collums in the digitization dataframe that aren't necessary
colnames(dig)
dig <- subset(dig, select = c("year", "hum_dist", "region",  "pub.site", "site", "site.ppq", "year.site.ppq", "ppq" ,"digitizer", "Benthic_Morphology", "area", "SArea"))
colnames(dig)
dig


#Levels of dataframe (make first 4 collumns factors that align with mpq dataframe)
str(dig)
dig$year <- as.factor(dig$year)
dig$hum_dist<- as.factor(dig$hum_dist)
dig$hum_dist <- factor(dig$hum_dist, levels = c("Very High", "Medium", "Very Low" ))
dig$site <- factor(dig$site, levels =c("27", "30", "32", "8", "34", "35", "5", "15", "19", "37"))
dig$site.ppq<- factor(dig$site.ppq, levels = c("27.1", "27.2", "27.3", "30.1", "30.2", "30.3", "32.1", "32.2", "32.3", "8.1", "8.2", "8.3", "34.1", "34.2", "34.3", "35.1", "35.2", "35.3", "5.1", "5.2", "5.3", "15.1", "15.2", "15.3", "19.1", "19.2", "19.3", "37.1", "37.2", "37.3"))
dig$year.site.ppq <- as.factor(dig$year.site.ppq)

dig$year.site.ppq<- factor(dig$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))

levels(dig$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig<- dig[order(dig$year.site.ppq),]
row.names(dig) <- 1:nrow(dig) #Changes the row names so that they are re-orderd 1-80


```

#### A. Create simplified Live/Dead Dataframe and summarize
```{r Live dead dataframe, echo=FALSE}
############################################################################################
#<-----------CREATE Simple Live/Dead Coral Cover Dataframe------------>#
############################################################################################
dig.simple <- dig

#Add new collumn
dig.simple$status <- "Blank"

#4Loop transferring any live coral morphs to "live" and dead = "dead" (macroalgae stays the same)
for(i in c(1:nrow(dig.simple))) {
  if(dig.simple$Benthic_Morphology[i]=="Live_Branching") {
   dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Columnar") {
    dig.simple$status[i] <- "Live.Coral"
 } else if(dig.simple$Benthic_Morphology[i]=="Live_Digitate") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Encrusting") {
    dig.simple$status[i] <- "Live.Coral"
 } else if(dig.simple$Benthic_Morphology[i]=="Live_Encrusting_Columnar") {
    dig.simple$status[i] <- "Live.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Live_Foliose") {
    dig.simple$status[i] <- "Live.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Live_FreeLiving") {
  dig.simple$status[i] <- "Live.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Live_Massive") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Massive_Grooved") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Porites") {
    dig.simple$status[i] <- "Live.Coral"
   } else if(dig.simple$Benthic_Morphology[i]=="Live_SubMassive") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Tabulate") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Macroalgae") {
    dig.simple$status[i] <- "Macroalgae"
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_Branching") {
    dig.simple$status[i] <- "Dead.Coral"
   } else if(dig.simple$Benthic_Morphology[i]=="Dead_Columnar") {
    dig.simple$status[i] <- "Dead.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_Foliose") {
    dig.simple$status[i] <- "Dead.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Dead_Massive") {
    dig.simple$status[i] <- "Dead.Coral"  
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_SoftCoral") {
    dig.simple$status[i] <- "Dead.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_Tabulate") {
    dig.simple$status[i] <- "Dead.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_Branching") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_Encrusting") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_Massive") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_SubMassive") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Rubble") {
    dig.simple$status[i] <- "Rubble"
} else if(dig.simple$Benthic_Morphology[i]=="Sand") {
    dig.simple$status[i] <- "Sand"
} else if(dig.simple$Benthic_Morphology[i]=="SoftCoral_Nodular") {
    dig.simple$status[i] <- "Soft.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="SoftCoral_Plating") {
    dig.simple$status[i] <- "Soft.Coral"
}}

                       #<-----------Summarize Area by Morphology------------>#

#Change area to numeric
dig.simple$area <- as.numeric(dig.simple$area)

# Summarize the total area of each morphology in Long format
str(dig.simple$area)
dig_sum_simple <- dig.simple %>% dplyr::group_by(year, hum_dist, region, site, ppq, year.site.ppq, status) %>% dplyr::summarise(Area = sum(area))

#creating a matrix with the total areas for each year site ppq combination
total_area1 <- dig_sum_simple %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig_sum_simple$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig_sum_simple$year)) {
  xx <- subset(total_area1, year.site.ppq == dig_sum_simple$year.site.ppq[i])
  
  dig_sum_simple$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area into a numeric
dig_sum_simple$Tot_Area <- as.numeric(dig_sum_simple$Tot_Area)

#Calculate proportional and percent cover
dig_sum_simple$per_area <- (dig_sum_simple$Area / dig_sum_simple$Tot_Area) *100 #Calculate percent coverage of each type
dig_sum_simple$prop_area <- (dig_sum_simple$Area / dig_sum_simple$Tot_Area)  #Calculate proportional coverage of each type

#Create unique collumn site.ppq
dig_sum_simple$site.ppq <- paste(dig_sum_simple$site, dig_sum_simple$ppq, sep=".")
colnames(dig_sum_simple)
dig.simple.final <- subset(dig_sum_simple, select = c("year", "hum_dist", "region","site", "ppq","site.ppq", "year.site.ppq", "status", "per_area", "prop_area"))


#Convert to wide format
dig_simple_per_w <- dcast(dig_sum_simple, year + hum_dist + region+ site + site.ppq + year.site.ppq ~status, value.var="per_area", fun.aggregate = sum) 
dig_simple_prop_w <- dcast(dig_sum_simple, year + hum_dist + region+ site + site.ppq + year.site.ppq ~status, value.var="prop_area", fun.aggregate = sum) 

#Dataframes
dig_simple_per_w 
dig_simple_prop_w 


# < ---------- 2b Plot percent cover ---------> #

#Set Color Pallette
#Correct levels for how the morphologies will show up on the graph (first ones listed will be the bars stacked on the top)
dig_sum_simple$status <- factor(dig_sum_simple$status, levels = c("Sand", "Rubble", "Dead.Coral", "Macroalgae", "Non.Coral", "Soft.Coral", "Live.Coral"))

##<------Set Colour Pallettes for each morphology type ----->
sum.simple.cols <- c("Gray30", "Gray35", "Gray40", "Forest Green", "yellow","mediumseagreen", "Dodger Blue")

morph.sum.simple.colscale<- scale_fill_manual(name="", values=sum.simple.cols, breaks=c("Sand", "Rubble", "Dead.Coral", "Macroalgae", "Non.Coral", "Soft.Coral", "Live.Coral"))





# <--------- 3b. Calculating colony counts of this dataframe -------> #
dig.simple

#Create new dataframe for simple polygon # count
dig.simple2 <- subset(dig.simple, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "status"))
colnames(dig.simple2)

#Add a collumn called "count" with a 1 in it
dig.simple2$count <- 1

#Switch to wide format now
dig.simple2.w <- dcast(dig.simple2, year + hum_dist + region+ site + site.ppq + year.site.ppq ~status, value.var="count", fun.aggregate = sum)

dig.simple2.w

#Summarize by year
dig.simple2.w2 <- dcast(dig.simple2, year ~status, value.var="count", fun.aggregate = sum)

#2015 = 7867 Living Colonies
#2017 = 2504 Living Colonies
#2019 = 5497 Living Colonies
#Total Colonies Digitized = #15,868
#7867+ 2504 + 5497 #15,868

```

##### A1. live/dead plot through time
```{r simple plot, eval=FALSE, include=FALSE}
#Plot
ggplot(dig_sum_simple, aes(y=per_area, x=year.site.ppq, fill= status)) + geom_bar(stat = 'identity', position = 'stack') + morph.sum.simple.colscale +theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1) +  geom_vline(xintercept = 20.5, linetype="dashed", color="black", size=0.5)) + geom_vline(xintercept = 56.5, linetype="solid", color="red", size=0.5) + 
    xlab("Year-Site-PPQ") + ylab("Percent Cover") + #label titles
  geom_vline(xintercept = 26.5, linetype="solid", color="red", size=0.5)+ theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) + 
  geom_vline(xintercept = 18.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) + 
  geom_vline(xintercept = 9.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))  + 
  geom_vline(xintercept = 35.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) +
geom_vline(xintercept = 44.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) +
geom_vline(xintercept = 65.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) +
geom_vline(xintercept = 74.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))


```

#### B. Create and Summarize Grouped live_massive category
```{r grouped dead massive summary }
#<----CREATE dataframe where massive category includes Porites and Massive_grooved --->#

dig2 <- dig

dig2$Benthic_Morphology[dig2$Benthic_Morphology == "Live_Massive_Grooved"] <- "Live_Massive"
# dig2$Benthic_Morphology[dig2$Benthic_Morphology == "Live_Porites"] <- "Live_Massive"

dig2


#Change area to numeric
dig2$area <- as.numeric(dig2$area)

#Re-input this column
dig2$year.site.ppq <- paste(dig2$year, dig2$site, dig2$ppq, sep=".") 

# Summarize the total area of each morphology in Long format
str(dig2$area)
dig2_sum <- dig2 %>% dplyr::group_by(year, hum_dist, region, site, site.ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(Area = sum(area))


# Wide format total area
dig2.wide <- tidyr::spread(dig2_sum, Benthic_Morphology, Area)
dig2.wide[is.na(dig2.wide)] <- 0

#Create a matrix with the total areas for each year site ppq combination
total_area2 <- dig2_sum %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig2_sum$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig2_sum$year)) {
  xx <- subset(total_area2, year.site.ppq == dig2_sum$year.site.ppq[i])
  
  dig2_sum$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area into a numeric
dig2_sum$Tot_Area <- as.numeric(dig2_sum$Tot_Area)

#Calculate proportional and percent cover
dig2_sum$per_area <- (dig2_sum$Area / dig2_sum$Tot_Area) *100 #Calculate percent coverage of each type
dig2_sum$prop_area <- (dig2_sum$Area / dig2_sum$Tot_Area)  #Calculate proportional coverage of each type

#Convert to wide format
dig2_prop_w <- dcast(dig2_sum, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="prop_area", fun.aggregate = sum) #Convert to wide format

dig2_perc_w <- dcast(dig2_sum, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="per_area", fun.aggregate = sum) #Convert to wide format


# <--------- 3b. Calculating colony counts of this dataframe -------> #
dig2 

#Create new dataframe for simple polygon # count
dig2.num <- subset(dig2, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Benthic_Morphology"))
colnames(dig2.num)

#Add a collumn called "count" with a 1 in it
dig2.num$count <- 1

#Switch to wide format now
dig2.num.w <- dcast(dig2.num, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="count", fun.aggregate = sum)

#Only include categories of "live" colonies
dig2.num.live <- subset(dig2.num.w, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Live_Branching",  "Live_Columnar", "Live_Digitate", "Live_Encrusting", "Live_Encrusting_Columnar", "Live_Foliose", "Live_FreeLiving" , "Live_Massive" , "Live_SubMassive", "Live_Tabulate" , "NonCoral_Encrusting" , "NonCoral_Massive" , "NonCoral_SubMassive",  "SoftCoral_Nodular" , "SoftCoral_Plating",  "NonCoral_Branching"))


#Dataframe for colony count (wide)
dig2.num.w <- dig2.num.live

#End Databases
dig2_prop_w 
dig2_perc_w 
dig2.num.w





```


#### C. Summarize Full dataframe
```{r Full dataframe summary}
#Change area to numeric
dig$area <- as.numeric(dig$area)

# Summarize the total area of each morphology in Long format
str(dig$area)
dig_sum <- dig %>% dplyr::group_by(year, hum_dist, region, site, site.ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(Area = sum(area))

# Wide format total area
dig_wide <- tidyr::spread(dig_sum, Benthic_Morphology, Area)
dig_wide[is.na(dig_wide)] <- 0

#Summarized dataframe of 2d surface area in the plots
dig_sum

#Calculate the % of each morphology at each plot & Graph the proportion of  each morphology   present at each plot using stacked bar charts

#creating a matrix with the total areas for each year site ppq combination
total_area <- dig_sum %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig_sum$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig_sum$year)) {
  xx <- subset(total_area, year.site.ppq == dig_sum$year.site.ppq[i])
  
  dig_sum$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area
dig_sum$Tot_Area <- as.numeric(dig_sum$Tot_Area)

#Calculate percent cover
dig_sum$per_area <- (dig_sum$Area / dig_sum$Tot_Area) * 100 #Calculate percent coverage of each type

#Convert to wide format
dig_per_w<- dcast(dig_sum, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="per_area", fun.aggregate = sum) #Convert to wide format


#### <----- 3a. Proportional Coverage Data ----> ###
#Create a proportional coverage dataframe too
dig_cover <- dig_sum
dig_cover$prop_area <- (dig_cover$Area / dig_cover$Tot_Area) #Calculate proportional coverage of each type
dig_prop_w <- dcast(dig_cover, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="prop_area", fun.aggregate = sum) #Convert to wide format

#Dataframes
dig_per_w #Percent coverage wide
dig_prop_w #Proportional coverage wide


# <--------- 3b. Calculating colony counts of this dataframe -------> #

#Create new dataframe for simple polygon # count
dig.num <- subset(dig, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Benthic_Morphology"))
colnames(dig.num)

#Add a collumn called "count" with a 1 in it
dig.num$count <- 1

#Summarize by status
dig.num.summarized <- dig.num %>% dplyr::group_by(year, hum_dist, region, site, site.ppq, Benthic_Morphology) %>% dplyr::summarise(Count = sum(count))

#Switch to wide format now
dig.num.w <- dcast(dig.num, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="count", fun.aggregate = sum)
colnames(dig.num.w)
  
#Only include categories of "live" colonies
dig.num.w1 <- subset(dig.num.w, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Live_Branching", "Live_Columnar", "Live_Digitate", "Live_Encrusting","Live_Encrusting_Columnar","Live_Foliose",     "Live_FreeLiving", "Live_Massive","Live_Massive_Grooved", "Live_Porites", "Live_SubMassive", "Live_Tabulate", "NonCoral_Encrusting", "NonCoral_Massive", "NonCoral_SubMassive",  "SoftCoral_Nodular", "SoftCoral_Plating", "NonCoral_Branching"))

#Add unique code at end to differentiate these #'s from the % cover df
#Change Names of collumns
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Branching")] <- "DB.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Columnar")] <- "DC.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Foliose")] <- "DF.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Massive")] <- "DM.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_SoftCoral")] <- "DS.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Tabulate")] <- "DT.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Branching")] <- "LB.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Columnar")] <- "LC.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Digitate")] <- "LD.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Encrusting")] <- "LE.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Encrusting_Columnar")] <- "LEC.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Foliose")] <- "LF.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_FreeLiving")] <- "LFL.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Massive")] <- "LM.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Massive_Grooved")] <- "LMG.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Porites")] <- "LP.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_SubMassive")] <- "LS.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Tabulate")] <- "LT.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Macroalgae")] <- "M.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_Encrusting")] <- "NCE.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_Massive")] <- "NCM.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_SubMassive")] <- "NCS.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Rubble")] <- "R.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Sand")] <- "S.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="SoftCoral_Nodular")] <- "SCN.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="SoftCoral_Plating")] <- "SCP.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_Branching")] <- "NCB.count"

#Dataframe for colony count (wide)
dig.num.w1

```

### 2. DF Export
#### A. Live/Dead Dataframe
```{r live or dead df database prep and exportation}
dig_simple_per_w 
dig_simple_prop_w 



dig.simple.final #long format

##### <------- Export Dataframes to use for nmds -----> ######
write.csv(dig.simple.final, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Simple_Long_Cover_Data_Clean.csv")

write.csv(dig_simple_per_w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Simple_Wide_PerCover_Data_Clean.csv")
write.csv(dig_simple_prop_w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Simple_Wide_PropCover_Data_Clean.csv")

```

#### B. Simplified dataframe (live massive emagulmation)
```{r grouped dm database prep and exportation}
#End Databases of of massive structure merged dataframe (porites, live_massive, & live_massive_grooved)
dig2_prop_w  #Proportional cover 
dig2_perc_w  #Percent cover
dig2.num.w   #Colony Count of live corals


#Export
write.csv(dig2_prop_w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Simplified_Wide_PropCover_Data_Clean.csv")
write.csv(dig2_perc_w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Simplified_Wide_PerCover_Data_Clean.csv")
write.csv(dig2.num.w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Simplified_Wide_ColonyCount_Data_Clean.csv")




```

#### C. Full Dataframe
```{r full dataframe exportation}
dig_per_w #Percent coverage wide
dig_prop_w #Proportional coverage wide
dig.num.w1 #Colony Counts

#Export
write.csv(dig.num.w1, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Wide_ColonyCount_Data_Clean.csv")
write.csv(dig_per_w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Wide_PercentCover_Data_Clean.csv")
write.csv(dig_prop_w, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Digitization_Wide_PropCover_Data_Clean.csv")

```

# 3. Combine MPQ Complexity data with different digitization dataframes
```{r combine complexity with coral digitization}
#Add in all digitization information at each DEM scale
#This data will be from the coarse dataframe and full dataframe (doesn't include modified/reduced full classification system, so if I need that data, I will have to check back in and change the code here)

#1. Create complexity dataframe first with ALL different metrics
#Dataframe to combine with digitization dataframe
mpq.3yrs.1cm.need.frac <- subset(mpq.3yrs, DEM == 1)
mpq.3yrs.4cm <- subset(mpq.3yrs, DEM == 4)
mpq.3yrs.8cm <- subset(mpq.3yrs, DEM == 8)

nrow(mpq.3yrs.1cm) #80
nrow(mpq.3yrs.4cm) #80
nrow(mpq.3yrs.8cm) #80

#Need to add in fractal dimension to 1cm dataframe
slope1 #Fractal dataframe
nrow(slope1) #127
slope <- subset(slope1, year == 2015 | year == 2017 | year == 2019)
nrow(slope) #80


mpq.1cm <- cbind(mpq.3yrs.1cm,slope)
mpq.3yrs.1cm <- subset(mpq.1cm, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "area_3d", "rug", "vrm", "vrm.range", "curv", "pro.curv", "pro.range", "plan.curv", "plan.range", "fractal.dimension"))


mpq.4cm <- cbind(mpq.3yrs.4cm,slope)
mpq.3yrs.4cm <- subset(mpq.4cm, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "area_3d", "rug", "vrm", "vrm.range", "curv", "pro.curv", "pro.range", "plan.curv", "plan.range"))

mpq.8cm <- cbind(mpq.3yrs.8cm,slope)
mpq.3yrs.8cm <- subset(mpq.8cm, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "area_3d", "rug", "vrm", "vrm.range", "curv", "pro.curv", "pro.range", "plan.curv", "plan.range"))


#Final Complexity Dataframes
mpq.3yrs.1cm
mpq.3yrs.4cm
mpq.3yrs.8cm



#<---------- Combine Complexity + Digitization dataframes ------>
#1cm
mpq.dig.full.1cm <- cbind(mpq.3yrs.1cm,dig.per.full)
mpq.dig.semi.1cm <- cbind(mpq.3yrs.1cm,dig.per.semi)
mpq.dig.simple.1cm <- cbind(mpq.3yrs.1cm,dig.per.simple)



############################################################################################
#<---------- Export dataframes ------>
#A. 1cm Dataframes
write.csv(mpq.dig.full.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_FULL_1cm_Data_11Jan21.csv")
write.csv(mpq.dig.semi.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SEMI_1cm_Data_11Jan21.csv")
write.csv(mpq.dig.simple.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SIMPLE_1cm_Data_11Jan21.csv")




# write.csv(mpq.dig.4cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_FULL_4cm_Data_11Jan21.csv")
# write.csv(mpq.dig.8cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_FULL_8cm_Data_11Jan21.csv")
# write.csv(mpq.dig.semi.4cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SEMI_4cm_Data_11Jan21.csv")
# write.csv(mpq.dig.semi.8cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SEMI_8cm_Data_11Jan21.csv")


```

# 4. Surface Complexity Calculations (Sum 3D and 2D Surface areas by morphology)
```{r Area calculation for Surface Complexity values, include=FALSE}
#1. Summarize the total shape area for each year.site.ppq combination by benthic morphology
#Erase all rows with an NA in it
str(dig) #area is a number and SArea is a factor because it includes <Null> values

#Create new dataframe that both: removes the null values from polygons too small, and converts SArea to a numeric
dig.area <- dig %>% filter(SArea != "<Null>") %>% mutate(area_3d = as.numeric(as.character(SArea)))
str(dig.area)

str(dig.area$area_3d) #number
str(dig.area$area) #number

# Summarize the total 2D area of each morphology in Long format
dig_sum_2d <- dig.area %>% dplyr::group_by(year, hum_dist, site, ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(area_2d = sum(area))

# Summarize the total 3D area of each morphology in Long format
dig_sum_3d <- dig.area %>% dplyr::group_by(year, hum_dist, site, ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(area_3d = sum(area_3d))

#Create unique ID collumn for both dataframes
dig_sum_3d$ID <- paste(dig_sum_3d$year, dig_sum_3d$site, dig_sum_3d$ppq,dig_sum_3d$Benthic_Morphology, sep=".")

dig_sum_2d$ID <- paste(dig_sum_2d$year, dig_sum_2d$site, dig_sum_2d$ppq,dig_sum_2d$Benthic_Morphology, sep=".")

#Plot proportional data to see if ~16m for all (they are)
#Test plot to see if it works for 2d area 
ggplot(dig_sum_2d, aes(y=area_2d, x=year.site.ppq, fill= Benthic_Morphology)) + geom_bar(stat = 'identity', position = 'stack')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) + scale_y_continuous(breaks=seq(0,16,1))

#Test plot to see if it works for 3d area 
ggplot(dig_sum_3d, aes(y=area_3d, x=year.site.ppq, fill= Benthic_Morphology)) + geom_bar(stat = 'identity', position = 'stack')+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))+ scale_y_continuous(breaks=seq(0,50,5))

#Combine two dataframes using for loop
dig_sum_2d$area_3d <- "blank"
for(i in 1:length(dig_sum_2d$year)){
  xx <- subset(dig_sum_3d, ID == dig_sum_2d$ID[i])
  dig_sum_2d$area_3d[i] <- xx$area_3d[1]
}

#Test to see
dig_sum_2d

#Transform area_3d into numeric in order to do SR calculations
str(dig_sum_2d)
dig_sum_2d$area_3d <- as.numeric(dig_sum_2d$area_3d)

#Create new dataframe (causing some issues with some of the data....)
dig_area <- dig_sum_2d %>% group_by(ID) %>% mutate(surface.complexity = area_3d/area_2d)

dig_area$surface.complexity

##################################################################################################################################################################################
######### Plots created for talk with John Burns Oct 19 2020#######
##################################################################################################################################################################################
# ggplot(dig_area, aes(x = Benthic_Morphology, y=surface.complexity)) + geom_boxplot() + ylim(0, 5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) 
# 
# #Redo plot so that the boxplots are sorted from most complex to least complex 
# dig_area_sorted <- dig_area %>% mutate(Benthic_Morphology = fct_reorder(Benthic_Morphology, -surface.complexity))
# 
# ggplot(dig_area_sorted, aes(x = Benthic_Morphology, y = surface.complexity)) +
#   geom_boxplot()+ ylim(0, 5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))
# 
# #Redo plot so that the morphology is on the y axis (easier to read) and getting less complex as we go down 
# dig_area_sorted2 <- dig_area %>% mutate(Benthic_Morphology = fct_reorder(Benthic_Morphology, +surface.complexity))
# 
# ggplot(dig_area_sorted2, aes(x = Benthic_Morphology, y = surface.complexity)) +
#   geom_boxplot()+ ylim(0, 4)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))+ coord_flip() + xlab("Benthic Morphology") + ylab("Surface Complexity")

```

# 5. Fish Data
```{r load fish data, eval=FALSE, include=FALSE}
#Set the Working Directory
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/FishSurveys")

#Load the data
## < ----- 2015 fish data -----> ##
fish.15a <-read.csv("KI_fishsurvey_2015_SD.csv",stringsAsFactors = FALSE)
fish.15b <- read.csv("KI_fishsurvey_2015_SC.csv",stringsAsFactors = FALSE)
ki.15 <- rbind(fish.15a, fish.15b)

#Convert depth from feet to m
ki.15$`Depth(m)` <- (ki.15$`Depth(m)`) *0.3048

#Remove extra collumns
ki.15 <- ki.15[,c(1:13)] #removing extra columns from each dataframe

#Make all colnames match
names(ki.15) <- c("KI_Date", "Site", "Observer", "Transect", "Species_Code", "Species", "Size(cm)", "Number", "Sexual.Phase..TP..IP..juv.", "Time", "Depth(m)", "Slope", "Note")


## < ----- 2017 fish data -----> ##
fish.17a <- read.csv("2017_Kiritimati_FISH_SD_FINAL.csv",stringsAsFactors = FALSE)
fish.17b <- read.csv("2017_Kiritimati_FISH_TAP_FINAL.csv",stringsAsFactors = FALSE)

#Remove extra collumns
ki_17_tap <- fish.17b[,c(1:13)] #removing extra columns from each dataframe
ki_17_sd <- fish.17a[,c(1:13)] #removing extra columns from each dataframe

#Make names the same
names(ki_17_tap) <- c("KI_Date", "Site", "Observer", "Transect", "Species_Code", "Species", "Size(cm)", "Number", "Sexual.Phase..TP..IP..juv.", "Time", "Depth(m)", "Slope", "Note")
names(ki_17_sd) <- c("KI_Date", "Site", "Observer", "Transect", "Species_Code", "Species", "Size(cm)", "Number", "Sexual.Phase..TP..IP..juv.", "Time", "Depth(m)", "Slope", "Note")

ki.17 <- rbind(ki_17_tap, ki_17_sd)


## < ----- 2019 fish data -----> ##
fish.19a <- read.csv("2019_Kiritimati_FISH_SD_FINAL.csv",stringsAsFactors = FALSE)
fish.19b <- read.csv("2019_Kiritimati_FISH_SC_FINAL.csv",stringsAsFactors = FALSE)
fish.19c <- read.csv("2019_Kiritimati_FISH_KB_FINAL.csv",stringsAsFactors = FALSE)

#Remove extra collumns from each dataframe
ki.19a <- fish.19a[,c(1:13)] #removing extra columns from each dataframe
ki.19b <- fish.19b[,c(1:13)] #removing extra columns from each dataframe
ki.19c <- fish.19c[,c(1:13)] #removing extra columns from each dataframe

#Make all colnames match
names(ki.19a) <- c("KI_Date", "Site", "Observer", "Transect", "Species_Code", "Species", "Size(cm)", "Number", "Sexual.Phase..TP..IP..juv.", "Time", "Depth(m)", "Slope", "Note")
names(ki.19b) <- c("KI_Date", "Site", "Observer", "Transect", "Species_Code", "Species", "Size(cm)", "Number", "Sexual.Phase..TP..IP..juv.", "Time", "Depth(m)", "Slope", "Note")
names(ki.19c) <- c("KI_Date", "Site", "Observer", "Transect", "Species_Code", "Species", "Size(cm)", "Number", "Sexual.Phase..TP..IP..juv.", "Time", "Depth(m)", "Slope", "Note")

ki.19 <- rbind(ki.19a, ki.19b, ki.19c)


#Remove collumns not needed in my analyses
names(ki.17)
ki_19 <- subset(ki.19, select =c("KI_Date", "Site", "Observer", "Transect", "Species", "Size(cm)", "Number", "Time", "Depth(m)", "Note"))
ki_17 <-subset(ki.17, select =c("KI_Date", "Site", "Observer", "Transect", "Species", "Size(cm)", "Number", "Time", "Depth(m)", "Note"))
ki_15 <- subset(ki.15, select =c("KI_Date", "Site", "Observer", "Transect", "Species", "Size(cm)", "Number", "Time", "Depth(m)", "Note"))

#adding year column to each
ki_15$Year <- 2015
ki_17$Year <- 2017
ki_19$Year <- 2019
  
#Only include sites that I will use
ki.15.mine <-  subset(ki_15, Site == 5 | Site == 19 | Site == 15 | Site == 37 | Site == 8 | Site == 34 | Site == 35 | Site == 27 | Site ==30 | Site == 32)
ki.17.mine <-  subset(ki_17, Site == 5 | Site == 19 | Site == 15 | Site == 37 | Site == 8 | Site == 34 | Site == 35 | Site == 27 | Site ==30 | Site == 32)
ki.19.mine <-  subset(ki_19, Site == 5 | Site == 19 | Site == 15 | Site == 37 | Site == 8 | Site == 34 | Site == 35 | Site == 27 | Site ==30 | Site == 32)

#binding all years into ONE dataframe
ki_full <- rbind(ki.15.mine, ki.17.mine, ki.19.mine)

### Check that no data was lost in binding
dim(ki_full); dim(ki.15.mine)[1] + dim(ki.17.mine)[1] + dim(ki.19.mine)[1] #9556 rows


### Clean data frame #19240 observations of 10 variables
#See if any collumns have any na's
apply(ki_full, 2, function(x) any(is.na(x))) #No NA's
str(ki_full)
ki_full$Number <- as.numeric(ki_full$Number)
ki_full$Year <- as.character(ki_full$Year)
ki_full$Depth <- as.character(ki_full$Depth)


### Remove data from training dives, etc. # removes 654 rows #end up with 38112
unique(ki_full$Note)
ki_full <- ki_full[!grepl("Training", ki_full$Note), ]
ki_full <- ki_full[!grepl("Trainiing", ki_full$Note), ]
ki_full <- ki_full[!grepl("TRAINING", ki_full$Note), ]
ki_full <- ki_full[!grepl("Bad data", ki_full$Note), ]
ki_full <- ki_full[!grepl("TRAINING NOT FOR USE", ki_full$Note), ]
ki_full <- ki_full[!grepl("Training Dive", ki_full$Note), ]
ki_full <- ki_full[!grepl("Training Dive - did not finish", ki_full$Note), ]
ki_full <- ki_full[!grepl("Training", ki_full$Note), ]

dim(ki_full) #9232 Rows Now


### Clean some typos
ki_full <- ki_full[order(ki_full$Species), ]
ki_full$Species <- paste(toupper(substr(ki_full$Species, 1, 1)), substr(ki_full$Species, 2, nchar(ki_full$Species)), sep = "")

unique(ki_full$Species)

#Just a few corrections
ki_full$Species[ki_full$Species == "Acanthurus achiles"] <- "Acanthurus achilles"
ki_full$Species[ki_full$Species == "Acanthurus flavicaudus"] <- "Ctenochaetus flavicauda"
ki_full$Species[ki_full$Species == "Acanthurus leucochilus"] <- "Acanthurus leucocheilus"
ki_full$Species[ki_full$Species == "Acanthurus nigricans "] <- "Acanthurus nigricans"
ki_full$Species[ki_full$Species == "Acanthurus nirgricauda"] <- "Acanthurus nigricauda"
ki_full$Species[ki_full$Species == "Acanturus nigroris"] <- "Acanthurus nigroris"
ki_full$Species[ki_full$Species == "Acanthurus olivacious"] <- "Acanthurus olivaceus"
ki_full$Species[ki_full$Species == "Acanthurus tricolor "] <- "Scarus tricolor"
ki_full$Species[ki_full$Species == "Apogon angustus"] <- "Ostorhinchus angustatus"
ki_full$Species[ki_full$Species == "Apogon apogonides"] <- "Ostorhinchus apogonoides"
ki_full$Species[ki_full$Species == "Arothron caruleopunctatus"] <- "Arothron caeruleopunctatus"
ki_full$Species[ki_full$Species == "BAlistapus undulatus"] <- "Balistapus undulatus"
ki_full$Species[ki_full$Species == "Blenniid sp."] <- "Blenniidae sp"
ki_full$Species[ki_full$Species == "Unknown Blenniidae"] <- "Blenniidae sp"
ki_full$Species[ki_full$Species == "Cantherhines dumerelii"] <- "Cantherhines dumerilii"
ki_full$Species[ki_full$Species == "Centropyger loricula"] <- "Centropyge loricula"
ki_full$Species[ki_full$Species == "Centropygi loricula"] <- "Centropyge loricula"
ki_full$Species[ki_full$Species == "Cephalopholis hexagonatus"] <- "Epinephelus hexagonatus"
ki_full$Species[ki_full$Species == "Cephalopholis minita"] <- "Cephalopholis miniata"
ki_full$Species[ki_full$Species == "Cephaloppholis miniata"] <- "Cephalopholis miniata"
ki_full$Species[ki_full$Species == "Cephalopholis urodeta "] <- "Cephalopholis urodeta"
ki_full$Species[ki_full$Species == "Chaetodon citronelis"] <- "Chaetodon citrinellus"
ki_full$Species[ki_full$Species == "Chaetodon kleini"] <- "Chaetodon kleinii"
ki_full$Species[ki_full$Species == "Chaetodon loricula"] <- "Centropyge loricula"
ki_full$Species[ki_full$Species == "Chaetodon vagabundas"] <- "Chaetodon vagabundus"
ki_full$Species[ki_full$Species == "Chelinus trilobatus"] <- "Cheilinus trilobatus"
ki_full$Species[ki_full$Species == "Chlorurus spp."] <- "Chlorurus sp."
ki_full$Species[ki_full$Species == "Chromis ternatenis "] <- "Chromis ternatensis"
ki_full$Species[ki_full$Species == "Chhromis vanderbilti"] <- "Chromis vanderbilti"
ki_full$Species[ki_full$Species == "Chromis xanth"] <- "Chromis xanthura"
ki_full$Species[ki_full$Species == "Cirrhitichthys oxycephalis"] <- "Cirrhitichthys oxycephalus"
ki_full$Species[ki_full$Species == "Cirripectes spp."] <- "Cirripectes sp."
ki_full$Species[ki_full$Species == "Coris Centralis"] <- "Coris centralis"
ki_full$Species[ki_full$Species == "Ctenochaetus cyanocheilus "] <- "Ctenochaetus cyanocheilus"
ki_full$Species[ki_full$Species == "Ctenochaetus flavissimus"] <- "Ctenochaetus striatus"
ki_full$Species[ki_full$Species == "Enchelychore pardalis"] <- "Enchelycore pardalis"
ki_full$Species[ki_full$Species == "Epinephelus miniata"] <- "Cephalopholis miniata"
ki_full$Species[ki_full$Species == "Epinephalis spilotoceps"] <- "Epinephelus spilotoceps"
ki_full$Species[ki_full$Species == "Epinephelos spilotoceps"] <- "Epinephelus spilotoceps"
ki_full$Species[ki_full$Species == "Eviola cometa"] <- "Eviota cometa"
ki_full$Species[ki_full$Species == "Forcipiger longorostris"] <- "Forcipiger longirostris"
ki_full$Species[ki_full$Species == "Gobiid sp"] <- "Gobiidae sp"
ki_full$Species[ki_full$Species == "Gomphosis varius"] <- "Gomphosus varius"
ki_full$Species[ki_full$Species == "Gracila albomarinata"] <- "Gracila albomarginata"
ki_full$Species[ki_full$Species == "Gracila albomarginata\n\n"] <- "Gracila albomarginata"
ki_full$Species[ki_full$Species == "Gymnothorax species"] <- "Gymnothorax sp"
ki_full$Species[ki_full$Species == "Gymnothorax thrysoideus"] <- "Gymnothorax thyrsoideus"
ki_full$Species[ki_full$Species == "Iniistius auropuctatus"] <- "Iniistius auropunctatus"
ki_full$Species[ki_full$Species == "Labrid sp."] <- "Labridae sp"
ki_full$Species[ki_full$Species == "Labroides rubroviolacious"] <- "Labroides rubrolabiatus"
ki_full$Species[ki_full$Species == "Lethrines meleagris"] <- "Lethrinus olivaceus"
ki_full$Species[ki_full$Species == "Lutjanus monotaxis"] <- "Lutjanus monostigma"
ki_full$Species[ki_full$Species == "MAcropharyngodon meleagris"] <- "Macropharyngodon meleagris"
ki_full$Species[ki_full$Species == "Melicthys niger"] <- "Melichthys niger"
ki_full$Species[ki_full$Species == "Melicthys vidua"] <- "Melichthys vidua"
ki_full$Species[ki_full$Species == "Myripristis tiere"] <- "Sargocentron tiere"
ki_full$Species[ki_full$Species == "Ostorhinchus apogonides"] <- "Ostorhinchus apogonoides"
ki_full$Species[ki_full$Species == "Oxycheilinus diagrammus"] <- "Oxycheilinus digramma"
ki_full$Species[ki_full$Species == "Paracanthus hepatus"] <- "Paracanthurus hepatus"
ki_full$Species[ki_full$Species == "Paracirrhites xanthus?"] <- "Paracirrhites xanthus"
ki_full$Species[ki_full$Species == "Parapercis spp."] <- "Parapercis sp."
ki_full$Species[ki_full$Species == "Parupeneus cyclostomas"] <- "Parupeneus cyclostomus"
ki_full$Species[ki_full$Species == "PArupeneus insularis"] <- "Parupeneus insularis"
ki_full$Species[ki_full$Species == "Parupeneus mimicus"] <- "Mulloidichthys mimicus"
ki_full$Species[ki_full$Species == "Parupeneus multifaciatus"] <- "Parupeneus multifasciatus"
ki_full$Species[ki_full$Species == "Parupeneus pleurostrigma"] <- "Parupeneus pleurostigma"
ki_full$Species[ki_full$Species == "Pempheris oulensis"] <- "Pempheris oualensis"
ki_full$Species[ki_full$Species == "Pervagor aspricauda"] <- "Pervagor aspricaudus"
ki_full$Species[ki_full$Species == "Plagiotremis sp."] <- "Plagiotremus sp."
ki_full$Species[ki_full$Species == "Plagiotremus species"] <- "Plagiotremus sp."
ki_full$Species[ki_full$Species == "PLectroglyphidodon dickii"] <- "Plectroglyphidodon dickii"
ki_full$Species[ki_full$Species == "Pseudocheilinus evanides"] <- "Pseudocheilinus evanidus"
ki_full$Species[ki_full$Species == "Pseduocheilnus octotaenia"] <- "Pseudocheilinus octotaenia"
ki_full$Species[ki_full$Species == "Pseudanthias hexataniea"] <- "Pseudocheilinus hexataenia"
ki_full$Species[ki_full$Species == "Pteroleotris zebra"] <- "Ptereleotris zebra"
ki_full$Species[ki_full$Species == "Caesio tile"] <- "Pterocaesio tile"
ki_full$Species[ki_full$Species == "Pterocaesio spp."] <- "Pterocaesio sp."
ki_full$Species[ki_full$Species == "Scorpaenidae sp."] <- "Pterois sp."
ki_full$Species[ki_full$Species == "Sargocentron tiare"] <- "Sargocentron tiere"
ki_full$Species[ki_full$Species == "Scarus frenatus "] <- "Scarus frenatus"
ki_full$Species[ki_full$Species == "Scarus frontalis"] <- "Chlorurus frontalis"
ki_full$Species[ki_full$Species == "Scarus ghobon"] <- "Scarus ghobban"
ki_full$Species[ki_full$Species == "Sccarus oviceps"] <- "Scarus oviceps"
ki_full$Species[ki_full$Species == "Scarus rubrovioulacious"] <- "Scarus rubroviolaceus"
ki_full$Species[ki_full$Species == "Scombroides lysan"] <- "Scomberoides lysan"
ki_full$Species[ki_full$Species == "Unknown Scorpaenidae"] <- "Scorpaenidae sp."
ki_full$Species[ki_full$Species == "Stegastes fasciatus"] <- "Stegastes fasciolatus"
ki_full$Species[ki_full$Species == "Sufflamen fraenatus"] <- "Sufflamen fraenatum"
ki_full$Species[ki_full$Species == "Synchiropus ocellatus"] <- "Neosynchiropus ocellatus"
ki_full$Species[ki_full$Species == "Synodus sp"] <- "Synodus sp."
ki_full$Species[ki_full$Species == "Thalassoma quinquevittatum\n"] <- "Thalassoma quinquevittatum"
ki_full$Species[ki_full$Species == "Variola lauti"] <- "Variola louti"
ki_full$Species[ki_full$Species == "Acanthurus nigrofuscus "] <- "Acanthurus nigrofuscus"
ki_full$Species[ki_full$Species == "Blennidaae sp"] <- "Blenniidae sp"
ki_full$Species[ki_full$Species == "Blenniidae sp."] <- "Blenniidae sp"
ki_full$Species[ki_full$Species == "Blenniidae spp"] <- "Blenniidae sp"
ki_full$Species[ki_full$Species == "Cephalopholis argus "] <- "Cephalopholis argus"
ki_full$Species[ki_full$Species == "Chomis vanderbilti "] <- "Chromis vanderbilti"
ki_full$Species[ki_full$Species == "Chromis acares "] <- "Chromis acares"
ki_full$Species[ki_full$Species == "Cirrihilabrus exquisitus"] <- "Cirrhilabrus exquisitus"
ki_full$Species[ki_full$Species == "Ctenochaetus multifasciatus"] <- "Ctenochaetus marginatus" #this must be a mis-entered mistake, the species doesn't exist
ki_full$Species[ki_full$Species == "Pseudodax molucanus"] <- "Pseudodax moluccanus"
ki_full$Species[ki_full$Species == "Cephalophoilis argus "] <- "Cephalopholis argus"
ki_full$Species[ki_full$Species == "Aluterus scripta"] <- "Aluterus scriptus"
ki_full$Species[ki_full$Species == "Lujanus monostigma"] <- "Lutjanus monostigma"

unique(ki_full$Species) #Went from 260 options to 233 types

#Load Cred and TMP Data
load("/Users/kevin/Desktop/GitHub/Bruce_MPQ_Analysis/Data/FishSurveys/TMPwd.Rdata") #TMP Data
cred.allo <- read.csv("/Users/kevin/Desktop/GitHub/Bruce_MPQ_Analysis/Data/FishSurveys/Deith_CRED_FG_Allocation.csv")
cred <- wd

colnames(cred)
ki_full$lw_a <- cred$LW_A[match(ki_full$Species, cred$SCIENTIFIC_NAME)]
ki_full$lw_b <- cred$LW_B[match(ki_full$Species, cred$SCIENTIFIC_NAME)]
ki_full$LENGTH_CONVERSION_FACTOR <- cred$LENGTH_CONVERSION_FACTOR[match(ki_full$Species, cred$SCIENTIFIC_NAME)]


# See which species are missing l-w data
dim(ki_full[is.na(ki_full$lw_a),] ) #15 rows without length data
unique(ki_full$Species[is.na(ki_full$lw_a)] ) # 21 species
sum(as.numeric(ki_full$Number[is.na(ki_full$lw_a)] ), na.rm = TRUE) # number of individuals without l/w information - 669


### Add Fishbase parameters for species not in CRED dataset
ki_full$lw_a[ki_full$Species == "Arothron caeruleopunctatus"] <- 0.02692
ki_full$lw_b[ki_full$Species == "Arothron caeruleopunctatus"] <- 2.88
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Arothron caeruleopunctatus"] <- 1

ki_full$lw_a[ki_full$Species == "Bothus pantherinus"] <- 0.00912
ki_full$lw_b[ki_full$Species == "Bothus pantherinus"] <- 3.07
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Bothus pantherinus"] <- 1

# ki_full$lw_a[ki_full$Species == "Chromis atripes"] <- 0.0229
# ki_full$lw_b[ki_full$Species == "Chromis atripes"] <- 3.175
# ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Chromis atripes"] <- 1

ki_full$lw_a[ki_full$Species == "Cirripectes auritus"] <- 0.00741
ki_full$lw_b[ki_full$Species == "Cirripectes auritus"] <- 3.00
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Cirripectes auritus"] <- 1

ki_full$lw_a[ki_full$Species == "Eviota albolineata"] <- 0.00631
ki_full$lw_b[ki_full$Species == "Eviota albolineata"] <- 3.08
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Eviota albolineata"] <- 1

# ki_full$lw_a[ki_full$Species == "Eviota cometa"] <- 0.00891
# ki_full$lw_b[ki_full$Species == "Eviota cometa"] <- 3.08
# ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Eviota cometa"] <- 1

ki_full$lw_a[ki_full$Species == "Gnatholepis anjerensis"] <- 0.00871
ki_full$lw_b[ki_full$Species == "Gnatholepis anjerensis"] <- 3.05
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Gnatholepis anjerensis"] <- 1

ki_full$lw_a[ki_full$Species == "Gymnothorax thyrsoideus"] <- 0.0005
ki_full$lw_b[ki_full$Species == "Gymnothorax thyrsoideus"] <- 3.303
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Gymnothorax thyrsoideus"] <- 1

ki_full$lw_a[ki_full$Species == "Iniistius auropunctatus"] <- 0.01122
ki_full$lw_b[ki_full$Species == "Iniistius auropunctatus"] <- 3.04
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Iniistius auropunctatus"] <- 1

ki_full$lw_a[ki_full$Species == "Neosynchiropus ocellatus"] <- 0.01047
ki_full$lw_b[ki_full$Species == "Neosynchiropus ocellatus"] <- 2.96
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Neosynchiropus ocellatus"] <- 1

ki_full$lw_a[ki_full$Species == "Ostorhinchus angustatus"] <- 0.01479
ki_full$lw_b[ki_full$Species == "Ostorhinchus angustatus"] <- 3.07
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Ostorhinchus angustatus"] <- 1

ki_full$lw_a[ki_full$Species == "Ostorhinchus apogonoides"] <- 0.01479
ki_full$lw_b[ki_full$Species == "Ostorhinchus apogonoides"] <- 3.07
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Ostorhinchus apogonoides"] <- 1

# ki_full$lw_a[ki_full$Species == "Oxycheilinus diagramma"] <- 0.01950
# ki_full$lw_b[ki_full$Species == "Oxycheilinus diagramma"] <- 2.95
# ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Oxycheilinus diagramma"] <- 1

ki_full$lw_a[ki_full$Species == "Parapercis lata"] <- 0.0133
ki_full$lw_b[ki_full$Species == "Parapercis lata"] <- 2.943
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Parapercis lata"] <- 1

ki_full$lw_a[ki_full$Species == "Priacanthus hamrur"] <- 0.03
ki_full$lw_b[ki_full$Species == "Priacanthus hamrur"] <- 2.801
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Priacanthus hamrur"] <- 1

ki_full$lw_a[ki_full$Species == "Pterocaesio lativittata"] <- 0.0092
ki_full$lw_b[ki_full$Species == "Pterocaesio lativittata"] <- 3.234
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species=="Pterocaesio lativittata"] <- 1

ki_full$lw_a[ki_full$Species == "Synodus jaculum"] <- 0.0085
ki_full$lw_b[ki_full$Species == "Synodus jaculum"] <- 3.078
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Synodus jaculum"] <- 1

# ki_full$lw_a[ki_full$Species == "Valenciennea helsdingenii"] <- 0.0104
# ki_full$lw_b[ki_full$Species == "Valenciennea helsdingenii"] <- 2.859
# ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Valenciennea helsdingenii"] <- 1

ki_full$lw_a[ki_full$Species == "Echidna nebulosus"] <- 0.0183
ki_full$lw_b[ki_full$Species == "Echidna nebulosus"] <- 3.64
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Echidna nebulosus"] <- 1

#using the same length weight formula as echidna nebulosus
ki_full$lw_a[ki_full$Species == "Echidna unicolor"] <- 0.0183
ki_full$lw_b[ki_full$Species == "Echidna unicolor"] <- 3.64
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Echidna unicolor"] <- 1

### Assign fish identified to genus or Family with mean l-w parameters
ki_full$lw_a[ki_full$Species == "Blenniidae sp"] <- mean(cred$LW_A[grepl("Blenniella", cred$SCIENTIFIC_NAME)])
ki_full$lw_b[ki_full$Species == "Blenniidae sp"] <- mean(cred$LW_B[grepl("Blenniella", cred$SCIENTIFIC_NAME)])
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Blenniidae sp"] <- mean(cred$LENGTH_CONVERSION_FACTOR[grepl("Blenniella", cred$SCIENTIFIC_NAME)])

ki_full$lw_a[ki_full$Species == "Epinephelus sp."] <- mean(cred$LW_A[grepl("Epinephelus", cred$SCIENTIFIC_NAME)])
ki_full$lw_b[ki_full$Species == "Epinephelus sp."] <- mean(cred$LW_B[grepl("Epinephelus", cred$SCIENTIFIC_NAME)])
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Epinephelus sp."] <- mean(cred$LENGTH_CONVERSION_FACTOR[grepl("Epinephelus", cred$SCIENTIFIC_NAME)])

ki_full$lw_a[ki_full$Species == "Gobiidae sp"] <- mean(cred$LW_A[grepl("Gobiidae", cred$SCIENTIFIC_NAME)])
ki_full$lw_b[ki_full$Species == "Gobiidae sp"] <- mean(cred$LW_B[grepl("Gobiidae", cred$SCIENTIFIC_NAME)])
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Gobiidae sp"] <- mean(cred$LENGTH_CONVERSION_FACTOR[grepl("Gobiidae", cred$SCIENTIFIC_NAME)])

ki_full$lw_a[ki_full$Species == "Halichoeres sp."] <- mean(cred$LW_A[grepl("Halichoeres", cred$SCIENTIFIC_NAME)])
ki_full$lw_b[ki_full$Species == "Halichoeres sp."] <- mean(cred$LW_B[grepl("Halichoeres", cred$SCIENTIFIC_NAME)])
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Halichoeres sp."] <- mean(cred$LENGTH_CONVERSION_FACTOR[grepl("Halichoeres", cred$SCIENTIFIC_NAME)])

ki_full$lw_a[ki_full$Species == "Labridae sp"] <- mean(cred$LW_A[grepl("Labroides", cred$SCIENTIFIC_NAME)])
ki_full$lw_b[ki_full$Species == "Labridae sp"] <- mean(cred$LW_B[grepl("Labroides", cred$SCIENTIFIC_NAME)])
ki_full$LENGTH_CONVERSION_FACTOR[ki_full$Species == "Labridae sp"] <- mean(cred$LENGTH_CONVERSION_FACTOR[grepl("Labroides", cred$SCIENTIFIC_NAME)])

#Double Check everything is good
dim(ki_full[is.na(ki_full$lw_a),] ) #0 NA's out of 15 collumns
unique(ki_full$Species[is.na(ki_full$lw_a)] ) #None

## Add Family info
ki_full$Family <- as.character(cred.allo$X[match(ki_full$Species, cred.allo$CREDSpecies)])
dim(ki_full[is.na(ki_full$Family),])

# Add in Family info for species not in 'trophic' dataset
unique(ki_full$Species[is.na(ki_full$Family)])

colnames(ki_full)

### Add functional group data
ki_full$CoarseFG <- as.character(cred.allo$CoarseFG[match(ki_full$Species, cred.allo$CREDSpecies)])
ki_full$FineFG <- as.character(cred.allo$FineFG[match(ki_full$Species, cred.allo$CREDSpecies)])

colnames(ki_full)

ki.fish <- subset(ki_full, select = c("Year", "KI_Date", "Site", "Observer", "Transect", "Species", "Family", "CoarseFG", "FineFG", "Size(cm)", "Number", "Note"))


#Rename some collumns
colnames(ki.fish)[which(names(ki.fish)=="Year")] <- "year"
colnames(ki.fish)[which(names(ki.fish)=="Site")] <- "site"
colnames(ki.fish)[which(names(ki.fish)=="Observer")] <- "diver"
colnames(ki.fish)[which(names(ki.fish)=="Transect")] <- "transect"
colnames(ki.fish)[which(names(ki.fish)=="Species")] <- "species"
colnames(ki.fish)[which(names(ki.fish)=="Family")] <- "family"
colnames(ki.fish)[which(names(ki.fish)=="Size(cm)")] <- "size(cm)"
colnames(ki.fish)[which(names(ki.fish)=="Number")] <- "count"



```


#Summarize fish dataset
```{r}
ki.fish
colnames(ki.fish)

#Total Fish Abundance by year/site/transect
ki_AB <- ki.fish %>% dplyr::group_by(year, KI_Date, site, diver, transect) %>% dplyr::summarise(AB_total = sum(count))

#Which years have double surveys completed? Go through and delete the first of the two, as that is most likely a training dive
#1 2015, site 8 


## Total abundance
# ki_AB <- ki_full %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_total = sum(number))

## Functional group abundance
# Corallivores
ki_AB_coral <- ki_coral %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_coral = sum(number))
# Detritivores
ki_AB_det <- ki_det %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_det = sum(number))
# Generalist carnivores
ki_AB_gen <- ki_gen %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_gen = sum(number))
# Herbivores
ki_AB_herb <- ki_herb %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_herb = sum(number))
# Invertivores
ki_AB_inv <- ki_inv %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_inv = sum(number))
# Omnivores
ki_AB_omn <- ki_omn %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_omn = sum(number))
# Piscivores
ki_AB_pisc <- ki_pisc %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_pisc = sum(number))
# Planktivores
ki_AB_plank <- ki_plank %>% group_by(heat, year, ki.date, site, observer) %>% summarise(AB_plank = sum(number))





#Create unique collumn
ki.fish$year.site.transect <- paste(ki.fish$year, ki.fish$site, ki.fish$transect, sep= ".")

# #Try subsetting by coarseFG
# ki.herbs <- subset(ki.fish, CoarseFG == "Herbivore")
# 
# str(ki.herbs$count) #numeric
# 
# #Summarize by year.site.transect
# ki.herbs.sum <- ki.herbs %>% group_by(year, site, diver, transect, CoarseFG, year.site.transect) %>% summarise(Abundance = sum(count))
# colnames(ki.herbs)
# 
# # ki.herbs.sum <- ddply(ki.herbs, c("year", "site", "diver", "transect", "species", "family", "CoarseFG"), summarise, Abundance = sum(count) )
# 
# ki.herbs.sum <- ddply(ki.herbs, c("year", "site", "transect", "CoarseFG"), summarise, Abundance = sum(count) )
# ki.herbs.sum
# 







#KB's WORK
#Summarize all fish counts by transect
ki.fish.sum <- ddply(ki.fish, c("year", "site", "transect", "CoarseFG"), summarise, Abundance = sum(count) )
ki.fish.sum$year.site.transect <- paste(ki.fish.sum$year, ki.fish.sum$site, ki.fish.sum$transect, sep = ".")

#Order levels by year.site.transect
levels(ki.fish.sum$year.site.transect)
ki.fish.sum$year.site.transect<- factor(ki.fish.sum$year.site.transect, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(ki.fish.sum$year.site.transect)

#Re-Order dataframe
ki.fish.sum<- ki.fish.sum[order(ki.fish.sum$year.site.transect),]
ki.fish.sum <- na.omit(ki.fish.sum)
row.names(ki.fish.sum) <- 1:nrow(ki.fish.sum) #Changes the row names so that they are re-orderd 1-80

#Subset by functional group
ki.herb <- subset(ki.fish.sum, CoarseFG == "Herbivore")
nrow(ki.herb) #80 (Perfect!)

ki.plank <- subset(ki.fish.sum, CoarseFG == "Planktivore")
nrow(ki.plank) #80 (Perfect!)

ki.carn <- subset(ki.fish.sum, CoarseFG == "Carnivore")
nrow(ki.carn) #80 (Perfect!)

ki.det <- subset(ki.fish.sum, CoarseFG == "Detritivore")
nrow(ki.det) #68 

ki.om <- subset(ki.fish.sum, CoarseFG == "Omnivore")
nrow(ki.om) #79

ki.plcr <-  subset(ki.fish.sum, CoarseFG == "Planktivore/Carnivore")
nrow(ki.plcr) #11


```

# Subset fishes by size
```{r }
str(ki.fish)
colnames(ki.fish)[which(names(ki.fish)=="size(cm)")] <- "size"
ki.fish$size <- as.numeric(ki.fish$size)

#Put fish sizes into bins (0-5cm, 6-10cm, 11-15cm, and 16-20cm)
fish.xs <- subset(ki.fish, size <= 5)
fish.small <- subset(ki.fish, size > 5 & size < 11)
fish.med <- subset(ki.fish, size > 10 & size < 16)
fish.large <- subset(ki.fish, size > 15 & size < 21)
fish.xl <- subset(ki.fish, size > 20)



#Summarize all fish counts by transect
fish.xs <- ddply(ki.fish, c("year", "site", "transect", "CoarseFG"), summarise, Abundance = sum(count) )
fish.xs$year.site.transect <- paste(fish.xs$year, fish.xs$site, fish.xs$transect, sep = ".")

#Order levels by year.site.transect
levels(fish.xs$year.site.transect)
fish.xs$year.site.transect<- factor(fish.xs$year.site.transect, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(fish.xs$year.site.transect)

#Re-Order dataframe
fish.xs<- fish.xs[order(fish.xs$year.site.transect),]
fish.xs <- na.omit(fish.xs)
row.names(fish.xs) <- 1:nrow(fish.xs) #Changes the row names so that they are re-orderd 1-80


#Subset by functional group
xs.herb <- subset(fish.xs, CoarseFG == "Herbivore")
nrow(xs.herb) #80 (Perfect!)

xs.plank <- subset(fish.xs, CoarseFG == "Planktivore")
nrow(xs.plank) #80 (Perfect!)

xs.carn <- subset(fish.xs, CoarseFG == "Carnivore")
nrow(xs.carn) #80 (Perfect!)

xs.det <- subset(fish.xs, CoarseFG == "Detritivore")
nrow(xs.det) #68 

xs.om <- subset(fish.xs, CoarseFG == "Omnivore")
nrow(xs.om) #79

xs.plcr <-  subset(fish.xs, CoarseFG == "Planktivore/Carnivore")
nrow(xs.plcr) #11

#Add STR Complexity data
#Merge together
xs.herb.com.1cm  <-  cbind(mpq.fish.1cm, xs.herb)
xs.herb.com.1cm <-xs.herb.com.1cm[,-c(20)] #remove row 20
xs.herb.com.1cm <-xs.herb.com.1cm[,-c(15:17)] #remove row 15-17







#Plot those
ggscatter(xs.herb.com.1cm, x = "rug", y = "Abundance", add = "reg.line") + stat_cor(label.x = 2, label.y = 100) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")




```
# Summarise complexity data to merge with fish data
```{r summarize complexity data}
#<----- Complexity Data for 3 timepoints -----> 
mpq.3yrs <- subset(mpq, year == 2015 | year == 2017 | year == 2019) #Dataframe to link with digitization datasets
mpq.3yrs$year.site.transect <- paste(mpq.3yrs$year, mpq.3yrs$site, mpq.3yrs$ppq, sep=".")

#Order levels by site.ppq.transect
levels(mpq.3yrs$year.site.transect)
mpq.3yrs$year.site.transect<- factor(mpq.3yrs$year.site.transect, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.3yrs$year.site.transect)

#Re-Order dataframe
mpq.3yrs<- mpq.3yrs[order(mpq.3yrs$year.site.transect),]
row.names(mpq.3yrs) <- 1:nrow(mpq.3yrs) #Changes the row names so that they are re-orderd 1-80

#Subset by DEM scale
mpq.3yrs.1cm <- subset(mpq.3yrs, DEM == 1)
mpq.3yrs.4cm <- subset(mpq.3yrs, DEM == 4)
mpq.3yrs.8cm <- subset(mpq.3yrs, DEM == 8)

#Create separate dataframe for each DEM scale
mpq.f.1cm <- subset(mpq.3yrs.1cm, select = c("year", "site", "ppq", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "year.site.transect"))
mpq.f.4cm <- subset(mpq.3yrs.4cm, select = c("year", "site", "ppq", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "year.site.transect"))
mpq.f.8cm <- subset(mpq.3yrs.8cm, select = c("year", "site", "ppq", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "year.site.transect"))


#<----- Fractal Dimension ----->
frac.3yrs <- subset(slope1, year == 2015 | year == 2017 | year == 2019) #Dataframe to link with digitization datasets
frac.3yrs$year.site.transect <- paste(frac.3yrs$year, frac.3yrs$site, frac.3yrs$ppq, sep=".")
frac.3yrs.f <- subset(frac.3yrs, select = c("year", "site", "ppq", "fractal.dimension", "year.site.transect"))

#Order levels by site.ppq.transect
levels(frac.3yrs.f$year.site.transect)
frac.3yrs.f$year.site.transect<- factor(frac.3yrs.f$year.site.transect, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(frac.3yrs.f$year.site.transect)

#Re-Order dataframe
frac.3yrs.f<- frac.3yrs.f[order(frac.3yrs.f$year.site.transect),]
row.names(frac.3yrs.f) <- 1:nrow(frac.3yrs.f) #Changes the row names so that they are re-orderd 1-80

frac.3yrs.f


#<----- Curvature Range Data ----->
range.final
range.final$year.site.transect <- paste(range.final$year, range.final$site, range.final$ppq, sep=".")
range.finals <- subset(range.final, year == 2015 | year == 2017 | year == 2019)

#Order levels by site.ppq.transect
levels(range.finals$year.site.transect)
range.finals$year.site.transect<- factor(range.finals$year.site.transect, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(range.finals$year.site.transect)

#Re-Order dataframe
range.finals<- range.finals[order(range.finals$year.site.transect),]
row.names(range.finals) <- 1:nrow(range.finals) #Changes the row names so that they are re-orderd 1-80

#Subset by DEM scale
range.final.1cm <- subset(range.finals, DEM == 1)
range.final.4cm <- subset(range.finals, DEM == 4)
range.final.8cm <- subset(range.finals, DEM == 8)

#Create Final dataframes
range.1cm.f <- subset(range.final.1cm, select = c("year", "site", "ppq", "vrm.range", "pro.range", "plan.range", "year.site.transect"))
row.names(range.1cm.f) <- 1:nrow(range.1cm.f) #Changes the row names so that they are re-orderd 1-80

range.4cm.f <- subset(range.final.4cm, select = c("year", "site", "ppq", "vrm.range", "pro.range", "plan.range", "year.site.transect"))
row.names(range.4cm.f) <- 1:nrow(range.4cm.f) #Changes the row names so that they are re-orderd 1-80

range.8cm.f <- subset(range.final.8cm, select = c("year", "site", "ppq", "vrm.range", "pro.range", "plan.range", "year.site.transect"))
row.names(range.8cm.f) <- 1:nrow(range.8cm.f) #Changes the row names so that they are re-orderd 1-80


#Merge All together into single DEM dataframes (Fractal dimension goes with 1cm dataframe)
mpq.fish.1 <- cbind(mpq.f.1cm, range.1cm.f,frac.3yrs.f)
mpq.fish.4 <- cbind(mpq.f.4cm, range.4cm.f,frac.3yrs.f)
mpq.fish.8 <- cbind(mpq.f.8cm, range.8cm.f,frac.3yrs.f)


colnames(mpq.fish.1)

mpq.fish.1cm <- subset(mpq.fish.1, select =c("year", "site", "ppq", "year.site.transect",  "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "vrm.range", "pro.range", "plan.range", "fractal.dimension"))

mpq.fish.4cm <- subset(mpq.fish.4, select =c("year", "site", "ppq", "year.site.transect","area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "vrm.range", "pro.range", "plan.range", "fractal.dimension"))

mpq.fish.8cm <- subset(mpq.fish.8, select =c("year", "site", "ppq", "year.site.transect","area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "vrm.range", "pro.range", "plan.range", "fractal.dimension"))

```

# Merge fish + complex dataframes
```{R}
#Fish Abundances with Complexity DF's
mpq.fish.1cm
mpq.fish.4cm
mpq.fish.8cm

#Fish DF's
ki.herb #80 rows
ki.plank #80 rows
ki.carn #80 rows
ki.det #68 rows
ki.om #79 rows
ki.plcr #11 rows


#Merge together
herb.com.1  <-  cbind(mpq.fish.1cm, ki.herb)
herb.com.1 <-herb.com.1[,-c(20)] #remove row 20
herb.com.1 <-herb.com.1[,-c(15:17)] #remove row 15-17

herb.com.4 <- cbind(mpq.fish.4cm, ki.herb)
herb.com.4 <-herb.com.4[,-c(20)] #remove row 20
herb.com.4 <-herb.com.4[,-c(15:17)] #remove row 15-17

herb.com.8 <-  cbind(mpq.fish.8cm, ki.herb)
herb.com.8 <-herb.com.8[,-c(20)] #remove row 20
herb.com.8 <-herb.com.8[,-c(15:17)] #remove row 15-17




#Correlelograms
library(corrgram)
corrgram(herb.com.1, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt, main="Coral Morphology Correlations")
corrgram(herb.com.4, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt, main="Coral Morphology Correlations")
corrgram(herb.com.8, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt, main="Coral Morphology Correlations")



#Scatterplots
#RUG
ggscatter(herb.com.1, x = "rug", y = "Abundance", add = "reg.line") + stat_cor(label.x = 2, label.y = 100) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "rug", y = "Abundance", add = "reg.line") + stat_cor(label.x = 1.6, label.y = 160) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "rug", y = "Abundance", add = "reg.line") + stat_cor(label.x = 2, label.y = 160) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")


#VRM
ggscatter(herb.com.1, x = "vrm", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.075, label.y = 100) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "vrm", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.075, label.y = 100) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "vrm", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.075, label.y = 100) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")

#VRM Range
ggscatter(herb.com.1, x = "vrm.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.60, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "vrm.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.5, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "vrm.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.35, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")


#Fractal Dimension
ggscatter(herb.com.1, x = "fractal.dimension", y = "Abundance", add = "reg.line") + stat_cor(label.x = 2, label.y = 100) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")

#Profile Curvature
ggscatter(herb.com.1, x = "pro.curv", y = "Abundance", add = "reg.line") + stat_cor(label.x = -400, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "pro.curv", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.2, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "pro.curv", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.6, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")

#Profile Curvature Range
ggscatter(herb.com.1, x = "pro.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 1000000, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "pro.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 50000, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "pro.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 12000, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")


#Planform Curvature
ggscatter(herb.com.1, x = "plan.curv", y = "Abundance", add = "reg.line") + stat_cor(label.x = -400, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "plan.curv", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.2, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "plan.curv", y = "Abundance", add = "reg.line") + stat_cor(label.x = 0.6, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")

#Planform Curvature Range
ggscatter(herb.com.1, x = "plan.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 1000000, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.4, x = "plan.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 50000, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")
ggscatter(herb.com.8, x = "plan.range", y = "Abundance", add = "reg.line") + stat_cor(label.x = 12000, label.y = 140) #+ stat_regline_equation(label.x = 2, label.y = 100, colour= "red")

```