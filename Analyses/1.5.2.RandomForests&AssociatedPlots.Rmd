---
title: "1.5.2.RandomForests&Plots"
author: "Kevin Bruce"
date: "29/01/2021"
output: html_document
---

#Load Packages/Data
```{r Load the packages and load mpq data, include=FALSE}
rm(list = ls()) #This clears the environment
dev.off()

library(dplyr)
library(ggplot2)
library(stats)
library(Rmisc)
library(here)
library(ggpmisc)
library(knitr)
library(magick)
library(gridExtra)
library(car)
library(tidyr)
library(readxl)
library(vegan)
library(tidyverse)
library(ade4)
library(MASS)
library(ellipse)
library(FactoMineR)
library(arm)
library(ape)
library(ggrepel)
library(FactoMineR)
library(ggpubr)
library(corrplot)
library(Matrix)
library(lme4)
library(TMB)
library(glmmTMB)
library(MuMIn)
library(vegan)
library(nlme)
library(randomForest)
library(qpcR)
library(emmeans)
library(sjPlot)
library(lmtest) #Durbin-Watson Test

# <---------------------------- DATA -------------------------->
#ArcMap Complexity/Curvature Data
mpq.1cm <- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_FULL_1cm_Data_14Jan21.csv", row.names=1)

mpq.4cm <- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_FULL_4cm_Data_22Jan21.csv")

mpq.8cm <- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_FULL_8cm_Data_22Jan21.csv")


#Digitization + Complexity Dataframes (3years, 2015, 2017, 2019)
mpq.dig.semi.1cm <- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SEMI_1cm_Data_11Jan21.csv")


mpq.dig.jm.1cm <-read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_JM.Classificaition_1cm_Data_11Jan21.csv")





#Habitat Volume Data
CC.final <- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_CloudCompare_Data_FINAL_14Jan2021.csv", row.names = 1)

#Subset out the overall changes in data (2015-2019 datapoints)
cc <- subset(CC.final, timepoint == "2015-2017" | timepoint == "2017-2019")

#Level time interval
cc$time.interval <- factor(cc$time.interval, levels = c("'15-'17","'17-'19"))

cc.2tps <- subset(cc, timepoint == "2015-2017" | timepoint == "2017-2019")


#<----------------------- Random Forest Data ------------------------->
#Detailed Morphological Categorization
mpq.dig.semi.1cm<- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SEMI_1cm_Data_11Jan21.csv", row.names = 1)

#Simplified Morphological Categorization
mpq.dig.simple.1cm<- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SIMPLE_1cm_Data_11Jan21.csv", row.names = 1)

#JM's Classification
mpq.dig.jm.1cm <- read.csv("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_JM.Classificaition_1cm_Data_11Jan21.csv", row.names = 1)

#Create Dataframes of all options, then just coral morphologys (no abiotic sand/rubble)
vrm.per.1cm.semi <- mpq.dig.semi.1cm[c(12,20:41)] #1cm semi df, all colonies
vrm.per.1cm.semi.live <- mpq.dig.semi.1cm[c(12,26:35,37,40:41)] #no abiotic str or macroalgae
vrm.per.1cm.jm <- mpq.dig.jm.1cm[c(12,20:24)] #All colonies
vrm.per.1cm.jm.live <- mpq.dig.jm.1cm[c(12,21,23:24)] #Only live coral colonies (No abiotic + Macroalgae)

#Surface Complexity
rug.per.1cm.semi <- mpq.dig.semi.1cm[c(11,20:41)] #1cm semi df, all
rug.per.1cm.semi.live <- mpq.dig.semi.1cm[c(11,26:35,37,40:41)] #no abiotic str or macroalgae
rug.per.1cm.jm<- mpq.dig.jm.1cm[c(11,20:24)] #entire simple dataframe
rug.per.1cm.jm.live <- mpq.dig.jm.1cm[c(11,21,23:24)]

#Fractal Dimension
fractal.dimension.per.1cm.semi <- mpq.dig.semi.1cm[c(19,20:41)] #1cm semi df, all
fractal.dimension.per.1cm.semi.live <- mpq.dig.semi.1cm[c(19,26:35,37,40:41)] #no abiotic str or macroalgae
fractal.dimension.per.1cm.jm <- mpq.dig.jm.1cm[c(19,20:24)] #entire simple dataframe
fractal.dimension.per.1cm.jm.live <- mpq.dig.jm.1cm[c(19,21,23:24)] #Only live coral colonies (No abiotic + Macroalgae)

#Profile Curvature
pro.per.1cm.semi <- mpq.dig.semi.1cm[c(16,20:41)] #1cm semi df, all
pro.per.1cm.semi.live <- mpq.dig.semi.1cm[c(16,26:35,37,40:41)] #no abiotic str
pro.per.1cm.jm <- mpq.dig.jm.1cm[c(16,20:24)] #entire simple dataframe
pro.per.1cm.jm.live <- mpq.dig.jm.1cm[c(16,21,23:24)] #entire simple dataframe

#Planform Curvature
plan.per.1cm.semi <- mpq.dig.semi.1cm[c(18,20:41)] #1cm semi df, all
plan.per.1cm.semi.live <- mpq.dig.semi.1cm[c(18,26:35,37,40:41)] #no abiotic str
plan.per.1cm.jm <- mpq.dig.jm.1cm[c(18,20:24)] #entire simple dataframe
plan.per.1cm.jm.live <- mpq.dig.jm.1cm[c(18,21,23:24)] #entire simple dataframe



```



# Random Forests

Progressed with Random Forest of Semi Dataframe (will rename later) to have Porites as its own independent morphology ("Mounding_Lobate" in manuscript, or even simply Porites lobata) and merged Live_Massive & Live_Massive_Grooved together, wiht Live_Branching & Live_Digitate merged into a singular Live_Branching category

## A different way to do a RF, check with Matt what he'd recommend
```{r}
index.vrm <- 1:nrow(vrm.per.1cm.semi)
trainindex.vrm <- sample(index.vrm, trunc(length(index.vrm)/2))
trainset.vrm1 <- vrm.per.1cm.semi[trainindex.vrm, ]
testset.vrm1 <- vrm.per.1cm.semi[-trainindex.vrm, ]

# fit a model to the training set (column 1, Sepal.Length, will be the outcome)
set.seed(2)
model.vrm1 <- randomForest(x=trainset.vrm1[ ,-1],y=trainset.vrm1[ ,1])

# predict values for the testing set (the first column is the outcome, leave it out)
predicted.vrm1 <- predict(model.vrm1, testset.vrm1[ ,-1])

# what's the squared correlation coefficient between predicted and actual values?
cor(predicted.vrm1, testset.vrm1[, 1])^2   #51.4%

# now, refit the model using built-in x.test and y.test
set.seed(2)
randomForest(x=trainset.vrm1[ ,-1], y=trainset.vrm1[ ,1], xtest=testset.vrm1[ ,-1], ytest=testset.vrm1[ ,1])

#See if R2 match
y <- testset.vrm1[,1]
1 - sum((y-predicted.vrm1)^2)/sum((y-mean(y))^2) #78.27 (bottom value)
```



## VRM
### VRM - Semi (all) (optimal mtry = 6) 

```{r VRM with abiotic determining optimal mtry value using training dataset, include=FALSE}
#Create training data
set.seed(2)
nrow(vrm.per.1cm.semi) #80rows total
train.vrm = sample(1:nrow(vrm.per.1cm.semi),53) #53 = 66% of the rows in full dataset

#Run Random Forest
vrm.classify <- randomForest(vrm ~., data = vrm.per.1cm.semi, subset = train.vrm, ntree = 500, importance=TRUE)
print(vrm.classify)
plot(vrm.classify)
varImpPlot(vrm.classify)



# #1. Determine # of trees where mse is the lowest
# which.min(vrm.classify$mse) #407 trees

#2. Determine optimal # of variables/node
#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(vrm.per.1cm.semi) #There are 23-1 = 22 predictors in this dataset

#Collect OOB Error
oob.err=double(22)
test.err=double(22)

#mtry is # of Variables randomly chosen at each split (we go up to maximum # which is 22 in this dataset)
for(mtry in 1:22) 
{
  rf=randomForest(vrm ~ . , data = vrm.per.1cm.semi , subset = train.vrm,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,vrm.per.1cm.semi[-train.vrm,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(vrm.per.1cm.semi[-train.vrm,], mean( (vrm - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test.Error"),pch=19, cex = 0.5, col=c("red","blue"))

#X axis value with lowest MSE = optimal # of variables/node


#<------------ Run Random Forest Again with optimal variables --------->
set.seed(2)
vrm.classify <- randomForest(vrm~., data = vrm.per.1cm.semi, subset=train.vrm, mtry = 6, ntree = 500, importance = TRUE,keep.forest=TRUE)
print(vrm.classify)
varImpPlot(vrm.classify, cex=1)

# #Make a dataframe with predictor names and their importance
# imp.vrm.semi.1cm <- importance(vrm.classify)
# imp.vrm.semi.1cm <- data.frame(predictors = rownames(imp.vrm.semi.1cm), imp.vrm.semi.1cm)
# 
# colnames(imp.vrm.semi.1cm)
# 
# # Order the predictor levels by importance
# imp.vrm.semi.1cm.sort <- arrange(imp.vrm.semi.1cm, desc(IncNodePurity))
# imp.vrm.semi.1cm.sort$predictors <- factor(imp.vrm.semi.1cm.sort$predictors, levels = imp.vrm.semi.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.vrm.semi.1cm.top.5 <- imp.vrm.semi.1cm.sort[1:5, ]
# imp.vrm.semi.1cm.top.10 <- imp.vrm.semi.1cm.sort[1:10, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.vrm.semi.1cm.top.10, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 10 most important morphologies for VRM 1cm classification")

```


### VRM - Semi (no abiotic or macroalgae) (optimal mtry = 4 ) 

```{r VRM no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(vrm.per.1cm.semi.live) #80
train.vrm2=sample(1:nrow(vrm.per.1cm.semi.live),53) #53 rows

#Run Random Forest
vrm.classify2 <- randomForest(vrm ~., data = vrm.per.1cm.semi.live, subset = train.vrm2, ntree = 500, importance=TRUE)
print(vrm.classify2)
plot(vrm.classify2)
varImpPlot(vrm.classify2)
# #Determine # of trees where mse is the lowest
# which.min(vrm.classify2$mse) #38 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(vrm.per.1cm.semi.live) #There are 14-1 = 13 predictors in this dataset

#Collect OOB Error
oob.err=double(13)
test.err = double(13)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(vrm ~ . , data = vrm.per.1cm.semi.live , subset = train.vrm2,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,vrm.per.1cm.semi.live[-train.vrm2,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(vrm.per.1cm.semi.live[-train.vrm2,], mean( (vrm - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red","blue"))



#Random Forrest with Optimal Parameters
set.seed(2)
vrm.classify2 <- randomForest(vrm~., data = vrm.per.1cm.semi.live, subset=train.vrm2, mtry= 5, ntree = 500, importance=TRUE) #Add ,importance=TRUE if you want %IncMSE
print(vrm.classify2)
varImpPlot(vrm.classify2, cex=1)


# #Make a dataframe with predictor names and their importance
# imp.vrm2.full.1cm <- importance(vrm.classify2)
# imp.vrm2.full.1cm <- data.frame(predictors = rownames(imp.vrm2.full.1cm), imp.vrm2.full.1cm)
# 
# colnames(imp.vrm2.full.1cm)
# 
# # Order the predictor levels by importance
# imp.vrm2.full.1cm.sort <- arrange(imp.vrm2.full.1cm, desc(IncNodePurity))
# imp.vrm2.full.1cm.sort$predictors <- factor(imp.vrm2.full.1cm.sort$predictors, levels = imp.vrm2.full.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.vrm2.full.1cm.top.5 <- imp.vrm2.full.1cm.sort[1:5, ]
# imp.vrm2.full.1cm.top.10 <- imp.vrm2.full.1cm.sort[1:10, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.vrm2.full.1cm.top.10, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 5 most important morphologies for VRM 1cm (without Abiotic) classification")


```

### VRM - Jenn Magel (all) (optimal mtry = 3) 

```{r VRM JM determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(vrm.per.1cm.jm) #80
train.vrm3=sample(1:nrow(vrm.per.1cm.jm),53) #80 rows

#Run Random Forest
vrm.classify3 <- randomForest(vrm ~., data = vrm.per.1cm.jm, subset = train.vrm3, ntree = 500, importance=TRUE)
print(vrm.classify3)
plot(vrm.classify3)
varImpPlot(vrm.classify3)
#Determine # of trees where mse is the lowest
which.min(vrm.classify3$mse) #12 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(vrm.per.1cm.jm) #There are 6-1 = 5 predictors in this dataset

#Collect OOB Error
oob.err=double(5)
test.err=double(5)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:5) 
{
  rf=randomForest(vrm ~ . , data = vrm.per.1cm.jm , subset = train.vrm3,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,vrm.per.1cm.jm[-train.vrm3,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(vrm.per.1cm.jm[-train.vrm3,], mean( (vrm - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error"),pch=1, col=c("red"))


#Re-run random forest with optimal parameters 
set.seed(2)
vrm.classify3 <- randomForest(vrm~., data = vrm.per.1cm.jm, subset=train.vrm3, mtry = 4, ntree = 500, importance=TRUE)
print(vrm.classify3)
varImpPlot(vrm.classify3)

# #Make a dataframe with predictor names and their importance
# imp.vrm.jm.1cm <- importance(vrm.classify3)
# imp.vrm.jm.1cm <- data.frame(predictors = rownames(imp.vrm.jm.1cm), imp.vrm.jm.1cm)
# 
# colnames(imp.vrm.jm.1cm)
# 
# # Order the predictor levels by importance
# imp.vrm.jm.1cm.sort <- arrange(imp.vrm.jm.1cm, desc(IncNodePurity))
# imp.vrm.jm.1cm.sort$predictors <- factor(imp.vrm.jm.1cm.sort$predictors, levels = imp.vrm.jm.1cm.sort$predictors)
# 
# # Select all predictors (5)
# imp.vrm.jm.1cm.top.7 <- imp.vrm.jm.1cm.sort[1:5, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.vrm.jm.1cm.top.7, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 5 most important morphologies for RUG 1cm classification")
# 
# #varImpPlot(vrm.classify3, cex=1)
# 

```

### VRM - Jenn Magel (no abiotic or macroalgae) (optimal mtry = 1 | # of trees = 188) 

```{r VRM no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(vrm.per.1cm.jm.live) #80
train.vrm4=sample(1:nrow(vrm.per.1cm.jm.live),53) #53 rows

#Run Random Forest
vrm.classify4 <- randomForest(vrm ~., data = vrm.per.1cm.jm.live, subset = train.vrm4, ntree = 500, importance=TRUE)
print(vrm.classify4)
plot(vrm.classify4)
varImpPlot(vrm.classify4)
# #Determine # of trees where mse is the lowest
# which.min(vrm.classify4$mse) #281 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(vrm.per.1cm.jm.live) #There are 4-1 = 3 predictors in this dataset

#Collect OOB Error
oob.err=double(3)
test.err = double(3)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:3) 
{ rf=randomForest(vrm ~ . , data = vrm.per.1cm.jm.live , subset = train.vrm4,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,vrm.per.1cm.jm.live[-train.vrm4,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(vrm.per.1cm.jm.live[-train.vrm4,], mean( (vrm - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Rerun Random Forrest with optimal parameters
set.seed(2)
vrm.classify4 <- randomForest(vrm~., data = vrm.per.1cm.jm.live, subset=train.vrm4, mtry= 3, ntree = 500, importance=TRUE) #Add ,importance=TRUE if you want %IncMSE
print(vrm.classify4)
varImpPlot(vrm.classify4, cex=1)
# 
# #Make a dataframe with predictor names and their importance
# imp.vrm2.full.1cm <- importance(vrm.classify4)
# imp.vrm2.full.1cm <- data.frame(predictors = rownames(imp.vrm2.full.1cm), imp.vrm2.full.1cm)
# 
# colnames(imp.vrm2.full.1cm)
# 
# # Order the predictor levels by importance
# imp.vrm2.full.1cm.sort <- arrange(imp.vrm2.full.1cm, desc(IncNodePurity))
# imp.vrm2.full.1cm.sort$predictors <- factor(imp.vrm2.full.1cm.sort$predictors, levels = imp.vrm2.full.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.vrm2.full.1cm.top.3 <- imp.vrm2.full.1cm.sort[1:3, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.vrm2.full.1cm.top.3, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 5 most important morphologies for VRM 1cm (without Abiotic) classification")

```









## Surface Complexity
### Surface Complexity - Semi  (optimal mtry = 3) 

```{r rug with abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(rug.per.1cm.semi) #80
train.rug1=sample(1:nrow(rug.per.1cm.semi),53) #80 rows

#Run Random Forest
rug.classify <- randomForest(rug ~., data = rug.per.1cm.semi, subset = train.rug1, ntree = 500, importance = TRUE)
print(rug.classify)
plot(rug.classify)
varImpPlot(rug.classify)

#Determine # of trees where mse is the lowest
which.min(rug.classify$mse) #481 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(rug.per.1cm.semi) #There are 23-1 = 22 predictors in this dataset

#Collect OOB Error
oob.err=double(22)
test.err=double(22)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:22) 
{
  rf=randomForest(rug ~ . , data = rug.per.1cm.semi , subset = train.rug1, mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,rug.per.1cm.semi[-train.rug1,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(rug.per.1cm.semi[-train.rug1,], mean( (rug - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
test.err
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

##### Re-Run Random Forest with optimal parameters ###
set.seed(2)
rug.classify <- randomForest(rug ~., data = rug.per.1cm.semi, subset = train.rug1, mtry= 3, ntree = 500, importance = TRUE)
print(rug.classify)
varImpPlot(rug.classify)


# #Make a dataframe with predictor names and their importance
# imp.rug.semi.1cm <- importance(rug.classify)
# imp.rug.semi.1cm <- data.frame(predictors = rownames(imp.rug.semi.1cm), imp.rug.semi.1cm)
# 
# colnames(imp.rug.semi.1cm)
# 
# # Order the predictor levels by importance
# imp.rug.semi.1cm.sort <- arrange(imp.rug.semi.1cm, desc(IncNodePurity))
# imp.rug.semi.1cm.sort$predictors <- factor(imp.rug.semi.1cm.sort$predictors, levels = imp.rug.semi.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.rug.semi.1cm.top.5 <- imp.rug.semi.1cm.sort[1:5, ]
# imp.rug.semi.1cm.top.15 <- imp.rug.semi.1cm.sort[1:15, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.rug.semi.1cm.top.10, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 15 most important morphologies for Surface Complexity with Abiotic 1cm classification") +labs(y= "Variable Importance (IncNodePurity)", x = "")
# 
# 

```

### Surface Complexity - Semi (no abiotic) (optimal mtry = 4) 

```{r rug no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(rug.per.1cm.semi.live) #80
train.rug2=sample(1:nrow(rug.per.1cm.semi.live),53) #80 rows

#Run Random Forest
rug.classify2 <- randomForest(rug ~., data = rug.per.1cm.semi.live, subset = train.rug2, ntree = 500, importance=TRUE)
print(rug.classify2)
plot(rug.classify2)
varImpPlot(rug.classify2)

#Determine # of trees where mse is the lowest
which.min(rug.classify2$mse) #104 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(rug.per.1cm.semi.live) #There are 14-1 = 13 predictors in this dataset

#Collect OOB Error
oob.err=double(13)
test.err=double(13)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(rug ~ . , data = rug.per.1cm.semi.live , subset = train.rug2,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,rug.per.1cm.semi.live[-train.rug2,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(rug.per.1cm.semi.live[-train.rug2,], mean( (rug - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red"))

#Re-Run Random Forrest with tuned parameters
set.seed(2)
rug.classify2 <- randomForest(rug~., data = rug.per.1cm.semi.live, subset = train.rug2, mtry=4, ntree = 500, importance=TRUE)
print(rug.classify2)
varImpPlot(rug.classify2)

# #Make a dataframe with predictor names and their importance
# imp.rug2.full.1cm <- importance(rug.classify2)
# imp.rug2.full.1cm <- data.frame(predictors = rownames(imp.rug2.full.1cm), imp.rug2.full.1cm)
# 
# colnames(imp.rug2.full.1cm)
# 
# # Order the predictor levels by importance
# imp.rug2.full.1cm.sort <- arrange(imp.rug2.full.1cm, desc(IncNodePurity))
# imp.rug2.full.1cm.sort$predictors <- factor(imp.rug2.full.1cm.sort$predictors, levels = imp.rug2.full.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.rug2.full.1cm.top.5 <- imp.rug2.full.1cm.sort[1:5, ]
# imp.rug2.full.1cm.top.10 <- imp.rug2.full.1cm.sort[1:10, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.vrm2.full.1cm.top.10, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 10 most important morphologies for Surface Complexity without Abiotic 1cm classification")

```


### Surface Complexity - JM full (optimal mtry = 2) 

```{r rug JM with abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(rug.per.1cm.jm) #80
train.rug3=sample(1:nrow(rug.per.1cm.jm),53) #80 rows

#Run Random Forest
rug.classify3 <- randomForest(rug ~., data = rug.per.1cm.jm, subset = train.rug3, ntree = 500, importance=TRUE)
print(rug.classify3)
plot(rug.classify3)
varImpPlot(rug.classify3)

#Determine # of trees where mse is the lowest
which.min(rug.classify3$mse) #321 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(rug.per.1cm.jm) #There are 6-1 = 5 predictors in this dataset

#Collect OOB Error
oob.err=double(5)
test.err=double(5)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:5) 
{
  rf=randomForest(rug ~ . , data = rug.per.1cm.jm , subset = train.rug3,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,rug.per.1cm.jm[-train.rug3,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(rug.per.1cm.jm[-train.rug3,], mean( (rug - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))


#Re-run Random Forest with optimal parameters tuned
set.seed(2)
rug.classify3 <- randomForest(rug~., data = rug.per.1cm.jm, mtry= 2, subset = train.rug3, ntree = 500, importance=TRUE)
print(rug.classify3)
varImpPlot(rug.classify3)

# #Make a dataframe with predictor names and their importance
# imp.rug3.simple.1cm <- importance(rug.classify3)
# imp.rug3.simple.1cm <- data.frame(predictors = rownames(imp.rug3.simple.1cm), imp.rug3.simple.1cm)
# 
# colnames(imp.rug3.simple.1cm)
# 
# # Order the predictor levels by importance
# imp.rug3.simple.1cm.sort <- arrange(imp.rug3.simple.1cm, desc(IncNodePurity))
# imp.rug3.simple.1cm.sort$predictors <- factor(imp.rug3.simple.1cm.sort$predictors, levels = imp.rug3.simple.1cm.sort$predictors)
# 
# # Select all predictors (7)
# imp.rug3.simple.1cm.sort.top.5 <- imp.rug3.simple.1cm.sort[1:5, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.rug3.simple.1cm.sort.top.5, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top most important morphologies for Surface Complexity 1cm Simple classification")

```


### Surface Complexity - JM no abiotic (optimal mtry = 1) 

```{r rug JM no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(rug.per.1cm.jm.live) #80
train.rug4=sample(1:nrow(rug.per.1cm.jm.live),53) #80 rows

#Run Random Forest
rug.classify4 <- randomForest(rug ~., data = rug.per.1cm.jm.live, subset = train.rug4, ntree = 500, importance=TRUE)
print(rug.classify4)
plot(rug.classify4)
varImpPlot(rug.classify4)

#Determine # of trees where mse is the lowest
which.min(rug.classify4$mse) #102 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(rug.per.1cm.jm.live) #There are 4-1 = 3 predictors in this dataset

#Collect OOB Error
oob.err=double(3)
test.err=double(3)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:3) 
{
  rf=randomForest(rug ~ . , data = rug.per.1cm.jm.live , subset = train.rug4, mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,rug.per.1cm.jm.live[-train.rug4,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(rug.per.1cm.jm.live[-train.rug4,], mean( (rug - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Re-Run Random Forrest with tuned parametrs
set.seed(3)
rug.classify4 <- randomForest(rug~., data = rug.per.1cm.jm.live, subset=train.rug4,mtry= 1, ntree = 500, importance=TRUE)
print(rug.classify4)
varImpPlot(rug.classify4)

# #Make a dataframe with predictor names and their importance
# imp.rug3.simple.1cm <- importance(rug.classify3)
# imp.rug3.simple.1cm <- data.frame(predictors = rownames(imp.rug3.simple.1cm), imp.rug3.simple.1cm)
# 
# colnames(imp.rug3.simple.1cm)
# 
# # Order the predictor levels by importance
# imp.rug3.simple.1cm.sort <- arrange(imp.rug3.simple.1cm, desc(IncNodePurity))
# imp.rug3.simple.1cm.sort$predictors <- factor(imp.rug3.simple.1cm.sort$predictors, levels = imp.rug3.simple.1cm.sort$predictors)
# 
# # Select all predictors (7)
# imp.rug3.simple.1cm.sort.top.5 <- imp.rug3.simple.1cm.sort[1:5, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.rug3.simple.1cm.sort.top.5, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top most important morphologies for Surface Complexity 1cm Simple classification")


```

## Fractal Dimension 
### Fractal Dimension - Semi  (optimal mtry = 9) 

```{r Fractal Dimension with abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(fractal.dimension.per.1cm.semi) #80
frac.train1=sample(1:nrow(fractal.dimension.per.1cm.semi),53) #53/80 = 66% training data

#Run Random Forest
fractal.dimension.classify <- randomForest(fractal.dimension ~., data = fractal.dimension.per.1cm.semi, subset = frac.train1, ntree = 500, importance=TRUE)
print(fractal.dimension.classify)
plot(fractal.dimension.classify)
varImpPlot(fractal.dimension.classify)

# #Determine # of trees where mse is the lowest
# which.min(fractal.dimension.classify$mse) #486 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(fractal.dimension.per.1cm.semi) #There are 23-1 = 22 predictors in this dataset

#Collect OOB Error
oob.err=double(22)
test.err=double(22)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:22) 
{
  rf=randomForest(fractal.dimension ~ . , data = fractal.dimension.per.1cm.semi , subset = frac.train1, mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,fractal.dimension.per.1cm.semi[-frac.train1,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(fractal.dimension.per.1cm.semi[-frac.train1,], mean( (fractal.dimension - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
test.err
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))



#Re-Random Forrest with tuned parameters
set.seed(2)
fractal.dimension.classify <- randomForest(fractal.dimension~., data = fractal.dimension.per.1cm.semi, subset = frac.train1, mtry= 9, ntree = 500, importance = TRUE)
print(fractal.dimension.classify)
varImpPlot(fractal.dimension.classify)


```


### Fractal Dimension - Semi (no abiotic) (optimal mtry = 10) 

```{r Fractal Dimension no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
frac.train2=sample(1:nrow(fractal.dimension.per.1cm.semi.live),53) #80 rows

#Run Random Forest
fractal.dimension.classify2 <- randomForest(fractal.dimension ~., data = fractal.dimension.per.1cm.semi.live, subset = frac.train2, ntree = 500, importance=TRUE)
print(fractal.dimension.classify2)
plot(fractal.dimension.classify2)
varImpPlot(fractal.dimension.classify2)

# #Determine # of trees where mse is the lowest
# which.min(fractal.dimension.classify2$mse) #125 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(fractal.dimension.per.1cm.semi.live) #There are 14-1 = 13 predictors in this dataset

#Collect OOB Error
oob.err=double(13)
test.err=double(13)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(fractal.dimension ~ . , data = fractal.dimension.per.1cm.semi.live , subset = frac.train2,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,fractal.dimension.per.1cm.semi.live[-frac.train2,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(fractal.dimension.per.1cm.semi.live[-frac.train2,], mean( (fractal.dimension - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Random Forrest
set.seed(2)
fractal.dimension.classify2 <- randomForest(fractal.dimension~., data = fractal.dimension.per.1cm.semi.live, subset = frac.train2, mtry=10, ntree = 500, importance=TRUE)
print(fractal.dimension.classify2)
varImpPlot(fractal.dimension.classify2)


```

### Fractal Dimension - JM (with abiotic) (optimal mtry = 1) 

```{r Fractal Dimension simple determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
frac.train3=sample(1:nrow(fractal.dimension.per.1cm.jm),53) 

#Run Random Forest
fractal.dimension.classify3 <- randomForest(fractal.dimension ~., data = fractal.dimension.per.1cm.jm, subset = frac.train3, ntree = 500, importance=TRUE)
print(fractal.dimension.classify3)
plot(fractal.dimension.classify3)
varImpPlot(fractal.dimension.classify3)

# #Determine # of trees where mse is the lowest
# which.min(fractal.dimension.classify3$mse) #183 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(fractal.dimension.per.1cm.jm) #There are 7-1 = 5 predictors in this dataset

#Collect OOB Error
oob.err=double(5)
test.err=double(5)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:5) 
{
  rf=randomForest(fractal.dimension ~ . , data = fractal.dimension.per.1cm.jm , subset = frac.train3,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,fractal.dimension.per.1cm.jm[-frac.train3,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(fractal.dimension.per.1cm.jm[-frac.train3,], mean( (fractal.dimension - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red","blue"))


#Random Forrest
set.seed(2)
fractal.dimension.classify3 <- randomForest(fractal.dimension~., data = fractal.dimension.per.1cm.jm, subset=frac.train3, mtry= 1, ntree = 500, importance=TRUE)
print(fractal.dimension.classify3)
varImpPlot(fractal.dimension.classify3)


```


### Fractal Dimension - JM (no abiotic) (optimal mtry = 1) 

```{r Fractal Dimension simple determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
frac.train4=sample(1:nrow(fractal.dimension.per.1cm.jm.live),53) 

#Run Random Forest
fractal.dimension.classify4 <- randomForest(fractal.dimension ~., data = fractal.dimension.per.1cm.jm.live, subset = frac.train4, ntree = 500, importance=TRUE)
print(fractal.dimension.classify4)
plot(fractal.dimension.classify4)
varImpPlot(fractal.dimension.classify4)

# #Determine # of trees where mse is the lowest
# which.min(fractal.dimension.classify3$mse) #183 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(fractal.dimension.per.1cm.jm.live) #There are 4-1 = 3 predictors in this dataset

#Collect OOB Error
oob.err=double(3)
test.err=double(3)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:3) 
{
  rf=randomForest(fractal.dimension ~ . , data = fractal.dimension.per.1cm.jm.live , subset = frac.train4,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,fractal.dimension.per.1cm.jm.live[-frac.train4,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(fractal.dimension.per.1cm.jm.live[-frac.train4,], mean( (fractal.dimension - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red","blue"))


#Random Forrest
set.seed(2)
fractal.dimension.classify3 <- randomForest(fractal.dimension~., data = fractal.dimension.per.1cm.jm.live, subset=frac.train4, mtry= 1, ntree = 500, importance=TRUE)
print(fractal.dimension.classify3)
varImpPlot(fractal.dimension.classify3)


```

## Profile Curvature Range
### Profile Curvature Range - Semi  (optimal mtry = 1) 

```{r Profile Curvature Range with abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(pro.per.1cm.semi) #80
train.pro1 =sample(1:nrow(pro.per.1cm.semi),53) #53 rows = 66% of data (2/3)

#Run Random Forest
pro.classify <- randomForest(pro.range.log ~., data = pro.per.1cm.semi, subset = train.pro1, ntree = 500,importance=TRUE)
print(pro.classify)
plot(pro.classify)
varImpPlot(pro.classify)

# #Determine # of trees where mse is the lowest
# which.min(pro.classify$mse) #378 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(pro.per.1cm.semi) #There are 23-1 = 22 predictors in this dataset

#Collect OOB Error
oob.err=double(22)
test.err=double(22)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:22) 
{
  rf=randomForest(pro.range.log ~ . , data = pro.per.1cm.semi , subset = train.pro1, mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,pro.per.1cm.semi[-train.pro1,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(pro.per.1cm.semi[-train.pro1,], mean( (pro.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
test.err
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Re-Run andom Forrest
set.seed(2)
pro.classify <- randomForest(pro.range.log ~., data = pro.per.1cm.semi, subset = train.pro1, ntree = 500, mtry=1, importance=TRUE)
print(pro.classify)
varImpPlot(pro.classify)


# 
# #Make a dataframe with predictor names and their importance
# imp.pro.semi.1cm <- importance(pro.classify)
# imp.pro.semi.1cm <- data.frame(predictors = rownames(imp.pro.semi.1cm), imp.pro.semi.1cm)
# 
# colnames(imp.pro.semi.1cm)
# 
# # Order the predictor levels by importance
# imp.pro.semi.1cm.sort <- arrange(imp.pro.semi.1cm, desc(IncNodePurity))
# imp.pro.semi.1cm.sort$predictors <- factor(imp.pro.semi.1cm.sort$predictors, levels = imp.pro.semi.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.pro.semi.1cm.top.5 <- imp.pro.semi.1cm.sort[1:5, ]
# imp.pro.semi.1cm.top.20 <- imp.pro.semi.1cm.sort[1:20, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.pro.semi.1cm.top.20, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 20 most important morphologies for Pro (with abiotic) 1cm classification")
# 

```


### Profile Curvature Range - Semi (no abiotic) (optimal mtry = 1) 
```{r Profile Curvature Range no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
train.pro2=sample(1:nrow(pro.per.1cm.semi.live),53) #80 rows

#Run Random Forest
pro.classify2 <- randomForest(pro.range.log ~., data = pro.per.1cm.semi.live, subset = train.pro2, ntree = 500, importance=TRUE)
print(pro.classify2)
plot(pro.classify2)
varImpPlot(pro.classify2)


# #Determine # of trees where mse is the lowest
# which.min(pro.classify2$mse) #11 trees 


#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(pro.per.1cm.semi.live) #There are 14-1 = 13 predictors in this dataset

#Collect OOB Error
oob.err=double(13)
test.err=double(13)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(pro.range.log ~ . , data = pro.per.1cm.semi.live , subset = train.pro2,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,pro.per.1cm.semi.live[-train.pro2,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(pro.per.1cm.semi.live[-train.pro2,], mean( (pro.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))




#Re-Run Random Forrest
set.seed(2)
pro.classify2 <- randomForest(pro.range.log ~., data = pro.per.1cm.semi.live, subset = train.pro2, ntree = 500, mtry = 1, importance=TRUE)
print(pro.classify2)
varImpPlot(pro.classify2)

# #Make a dataframe with predictor names and their importance
# imp.pro2.full.1cm <- importance(pro.classify2)
# imp.pro2.full.1cm <- data.frame(predictors = rownames(imp.pro2.full.1cm), imp.pro2.full.1cm)
# 
# colnames(imp.pro2.full.1cm)
# 
# # Order the predictor levels by importance
# imp.pro2.full.1cm.sort <- arrange(imp.pro2.full.1cm, desc(IncNodePurity))
# imp.pro2.full.1cm.sort$predictors <- factor(imp.pro2.full.1cm.sort$predictors, levels = imp.pro2.full.1cm.sort$predictors)
# 
# # Select the top 10 predictors
# imp.pro2.full.1cm.top.5 <- imp.pro2.full.1cm.sort[1:5, ]
# imp.pro2.full.1cm.top.10 <- imp.pro2.full.1cm.sort[1:10, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.pro2.full.1cm.top.10, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top 10 most important morphologies for ProCurv (without Abiotic) 1cm classification")

```


### Profile Curvature Range - JM with Abiotic (optimal mtry = 1) 
```{r Profile Curvature Range simple determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
train.pro3=sample(1:nrow(pro.per.1cm.jm),53) #80 rows

#Run Random Forest
pro.classify3 <- randomForest(pro.range.log ~., data = pro.per.1cm.jm, subset = train.pro3, ntree = 500, importance=TRUE)
print(pro.classify3)
plot(pro.classify3)
varImpPlot(pro.classify3)

# #Determine # of trees where mse is the lowest
# which.min(pro.classify3$mse) #52 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(pro.per.1cm.jm) #There are 6-1 = 5 predictors in this dataset

#Collect OOB Error
oob.err=double(5)
test.err=double(5)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:5) 
{
  rf=randomForest(pro.range.log ~ . , data = pro.per.1cm.jm , subset = train.pro3,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,pro.per.1cm.jm[-train.pro3,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(pro.per.1cm.jm[-train.pro3,], mean( (pro.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Random Forrest
set.seed(2)
pro.classify3 <- randomForest(pro.range.log~., data = pro.per.1cm.jm, subset = train.pro3, mtry= 1, ntree = 500, importance=TRUE)
print(pro.classify3)
varImpPlot(pro.classify3)

# #Make a dataframe with predictor names and their importance
# imp.pro3.simple.1cm <- importance(pro.classify3)
# imp.pro3.simple.1cm <- data.frame(predictors = rownames(imp.pro3.simple.1cm), imp.pro3.simple.1cm)
# 
# colnames(imp.pro3.simple.1cm)
# 
# # Order the predictor levels by importance
# imp.pro3.simple.1cm.sort <- arrange(imp.pro3.simple.1cm, desc(IncNodePurity))
# imp.pro3.simple.1cm.sort$predictors <- factor(imp.pro3.simple.1cm.sort$predictors, levels = imp.pro3.simple.1cm.sort$predictors)
# 
# # Select all predictors (7)
# imp.pro3.simple.1cm.top.7 <- imp.pro3.simple.1cm.sort[1:7, ]
# 
# 
# # Plot top morphologies
# ggplot(imp.pro3.simple.1cm.top.7, aes(x = predictors, y = IncNodePurity)) + geom_bar(stat = "identity", fill = "indianred") + coord_flip() + ggtitle("Top most important morphologies for Pro Curv Simple 1cm classification")


```

### Profile Curvature Range - JM without Abiotic (optimal mtry = 1) 

```{r Profile Curvature Range simple determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
train.pro4=sample(1:nrow(pro.per.1cm.jm.live),53) #80 rows

#Run Random Forest
pro.classify4 <- randomForest(pro.range.log ~., data = pro.per.1cm.jm.live, subset = train.pro4, ntree = 500, importance=TRUE)
print(pro.classify4)
plot(pro.classify4)
varImpPlot(pro.classify4)

# #Determine # of trees where mse is the lowest
# which.min(pro.classify4$mse) #116 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(pro.per.1cm.jm.live) #There are 4-1 = 3 predictors in this dataset

#Collect OOB Error
oob.err=double(3)
test.err=double(3)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:3) 
{
  rf=randomForest(pro.range.log ~ . , data = pro.per.1cm.jm.live , subset = train.pro4,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,pro.per.1cm.jm.live[-train.pro4,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(pro.per.1cm.jm.live[-train.pro4,], mean( (pro.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Random Forrest
set.seed(2)
pro.classify4 <- randomForest(pro.range.log~., data = pro.per.1cm.jm.live, subset = train.pro4, mtry= 1, ntree = 500, importance=TRUE)
print(pro.classify4)
varImpPlot(pro.classify4)

```



## Planform Curvature Range
### Planform Curvature Range - Semi  (optimal mtry = 2) 

```{r Planform Curvature Range with abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
train.plan1=sample(1:nrow(plan.per.1cm.semi),53) #53 rows is 66% (2/3)

#Run Random Forest
plan.classify <- randomForest(plan.range.log ~., data = plan.per.1cm.semi, subset = train.plan1, ntree = 500, importance=TRUE)
print(plan.classify)
plot(plan.classify)
varImpPlot(plan.classify)

# #Determine # of trees where mse is the lowest
# which.min(plan.classify$mse) #39 trees 
# 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(plan.per.1cm.semi) #There are 23-1 = 22 predictors in this dataset

#Collect OOB Error
oob.err=double(22)
test.err=double(22)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:22) 
{
  rf=randomForest(plan.range.log ~ . , data = plan.per.1cm.semi , subset = train.plan1, mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,plan.per.1cm.semi[-train.plan1,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(plan.per.1cm.semi[-train.plan1,], mean( (plan.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
test.err
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))


#Re-Run Random Forrest
set.seed(2)
plan.classify <- randomForest(plan.range.log~., data = plan.per.1cm.semi, subset=train.plan1, mtry= 2, ntree = 500, importance = TRUE)
print(plan.classify)
varImpPlot(plan.classify)


```

### Planform Curvature Range - Semi (no abiotic) (optimal mtry = 2) 

```{r Planform Curvature Range no abiotic determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
nrow(plan.per.1cm.semi.live) #80
train.plan2=sample(1:nrow(plan.per.1cm.semi.live),53) 

#Run Random Forest
plan.classify2 <- randomForest(plan.range.log ~., data = plan.per.1cm.semi.live, subset = train.plan2, ntree = 500, importance=TRUE)
print(plan.classify2)
plot(plan.classify2)
varImpPlot((plan.classify2))
# #Determine # of trees where mse is the lowest
# which.min(plan.classify2$mse) #71 trees 



#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(plan.per.1cm.semi.live) #There are 14-1 = 13 predictors in this dataset

#Collect OOB Error
oob.err=double(13)
test.err=double(13)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(plan.range.log ~ . , data = plan.per.1cm.semi.live , subset = train.plan2,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,plan.per.1cm.semi.live[-train.plan2,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(plan.per.1cm.semi.live[-train.plan2,], mean( (plan.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err

#Plot it
matplot(1:mtry , cbind(oob.err,test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error"),pch=1, col=c("red"))

#Re-run Random Forrest
set.seed(2)
plan.classify2 <- randomForest(plan.range.log~., data = plan.per.1cm.semi.live, subset=train.plan2, mtry=2, ntree = 500, importance = TRUE)
print(plan.classify2)
varImpPlot(plan.classify2)

```

### Planform Curvature Range - JM with Abiotic (optimal mtry = 1) 
```{r Planform Curvature Range simple determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
train.plan3=sample(1:nrow(plan.per.1cm.jm),53) #80 rows

#Run Random Forest
plan.classify3 <- randomForest(plan.range.log ~., data = plan.per.1cm.jm, subset = train.plan3, ntree = 500, importance=TRUE)
print(plan.classify3)
plot(plan.classify3)
varImpPlot(plan.classify3)

# #Determine # of trees where mse is the lowest
# which.min(plan.classify3$mse) #67 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(plan.per.1cm.jm) #There are 6-1 = 5 predictors in this dataset

#Collect OOB Error
oob.err=double(5)
test.err=double(5)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:5) 
{
  rf=randomForest(plan.range.log ~ . , data = plan.per.1cm.jm , subset = train.plan3,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,plan.per.1cm.jm[-train.plan3,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(plan.per.1cm.jm[-train.plan3,], mean( (plan.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Random Forrest
set.seed(2)
plan.classify3 <- randomForest(plan.range.log~., data = plan.per.1cm.jm, subset = train.plan3, mtry= 1, ntree = 500, importance=TRUE)
print(plan.classify3)
varImpPlot(plan.classify3)

```

### Planform Curvature Range - JM without Abiotic (optimal mtry = 1) 

```{r Planform Curvature Range jm without determining optimal mtry value, include=FALSE}
#Create training data
set.seed(2)
train.plan4=sample(1:nrow(plan.per.1cm.jm.live),53) #53/80 rows for training data

#Run Random Forest
plan.classify4 <- randomForest(plan.range.log ~., data = plan.per.1cm.jm.live, subset = train.plan4, ntree = 500, importance=TRUE)
print(plan.classify4)
plot(plan.classify4)
varImpPlot(plan.classify4)
# #Determine # of trees where mse is the lowest
# which.min(plan.classify4$mse) #139 trees 

#Testing to see what # of predictors chosen at each split is best (aka has lowest OOB)
ncol(plan.per.1cm.jm.live) #There are 4-1 = 3 predictors in this dataset

#Collect OOB Error
oob.err=double(3)
test.err=double(3)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:3) 
{
  rf=randomForest(plan.range.log ~ . , data = plan.per.1cm.jm.live , subset = train.plan4,mtry=mtry,ntree=500) 
  oob.err[mtry] = rf$mse[500] #Error of all Trees fitted
  
  pred<-predict(rf,plan.per.1cm.jm.live[-train.plan4,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(plan.per.1cm.jm.live[-train.plan4,], mean( (plan.range.log - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}

#Get the OOB error
oob.err
test.err

#Plot it
matplot(1:mtry , cbind(oob.err, test.err), pch=1 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error", "Test Error"),pch=1, col=c("red", "blue"))

#Random Forrest
set.seed(2)
plan.classify4 <- randomForest(plan.range.log~., data = plan.per.1cm.jm.live, subset = train.plan4, mtry= 1, ntree = 500, importance=TRUE)
print(plan.classify4)
varImpPlot(plan.classify4)

```












# Plots
## 1. %MSE for each comparison as discussed with JKB
```{r mse percent plots done by rbind instead}
#To collect the importance values for each variable
#VRM
vrm.classify2$importance
varImpPlot(vrm.classify2, cex=1, scale=TRUE)
varImpPlot(vrm.classify2, cex=1, scale=FALSE)

#The varImpPlot function when scale is not set to false provides % inc MSE by dividing the importance value in the table by the importanceSD. So in order to calculate the %'s, I will need to first collect the importance, importanceSD into same dataframe then divide importance/sd to get the %. 

#Load 2 dataframes
vrm.semi.imp <- vrm.classify2$importance
vrm.semi.sd <- vrm.classify2$importanceSD

#Convert to dataframe
vrm.semi.imp <- as.data.frame(vrm.semi.imp)
vrm.semi.sd <- as.data.frame(vrm.semi.sd)

#Bind two df's together
vrm.semi.imp.df  <- cbind(vrm.semi.imp,vrm.semi.sd)
colnames(vrm.semi.imp.df) 
str(vrm.semi.imp.df) #All numeric

colnames(vrm.semi.imp.df)[which(names(vrm.semi.imp.df)=="%IncMSE")] <- "MSE"
colnames(vrm.semi.imp.df)[which(names(vrm.semi.imp.df)=="IncNodePurity")] <- "nodepurity"
colnames(vrm.semi.imp.df)[which(names(vrm.semi.imp.df)=="vrm.semi.sd")] <- "imp.sd"
colnames(vrm.semi.imp.df)

vrm.semi.imp.df$Percent.Inc.MSE <- (vrm.semi.imp.df$MSE) / (vrm.semi.imp.df$imp.sd)
vrm.semi.imp.df$metric <- "vrm"
vrm.semi.imp.df$morphology <- rownames(vrm.semi.imp.df)

#Rename rownames as numbers
dim(vrm.semi.imp.df)
rownames(vrm.semi.imp.df)<-c(1:21)

#Order from low% to high% mse
vrm.semi.imp.df<- vrm.semi.imp.df[order(vrm.semi.imp.df$Percent.Inc.MSE),]
row.names(vrm.semi.imp.df) <- 1:nrow(vrm.semi.imp.df) #Changes the row names so that they are re-orderd 1-21

#Subset out only top 7 shared morphologies
vrm.semi.imp.df <- vrm.semi.imp.df[c(4:13),c(1:6)]


#Surface Complexity
#Load 2 dataframes
rug.semi.imp <- rug.classify2$importance
rug.semi.sd <- rug.classify2$importanceSD

#Convert to dataframe
rug.semi.imp <- as.data.frame(rug.semi.imp)
rug.semi.sd <- as.data.frame(rug.semi.sd)

#Bind two df's together
rug.semi.imp.df  <- cbind(rug.semi.imp,rug.semi.sd)
colnames(rug.semi.imp.df) 
str(rug.semi.imp.df) #All numeric

colnames(rug.semi.imp.df)[which(names(rug.semi.imp.df)=="%IncMSE")] <- "MSE"
colnames(rug.semi.imp.df)[which(names(rug.semi.imp.df)=="IncNodePurity")] <- "nodepurity"
colnames(rug.semi.imp.df)[which(names(rug.semi.imp.df)=="rug.semi.sd")] <- "imp.sd"

colnames(rug.semi.imp.df)

rug.semi.imp.df$Percent.Inc.MSE <- (rug.semi.imp.df$MSE) / (rug.semi.imp.df$imp.sd)
rug.semi.imp.df$metric <- "surface.complexity"
rug.semi.imp.df$morphology <- rownames(rug.semi.imp.df)

#Rename rownames as numbers
dim(rug.semi.imp.df)
rownames(rug.semi.imp.df)<-c(1:21)

#Order from low% to high% mse
rug.semi.imp.df<- rug.semi.imp.df[order(rug.semi.imp.df$Percent.Inc.MSE),]
row.names(rug.semi.imp.df) <- 1:nrow(rug.semi.imp.df) #Changes the row names so that they are re-orderd 1-21

#Subset out only top 7 morphologies
rug.semi.imp.df2 <- rug.semi.imp.df[c(4:13),c(1:6)]


rug.semi.imp.df #Compare with varImpPlot(rug.classify2, cex=1, scale=TRUE)


#Combine rug _ vrm together
complexity.inc.mse<- rbind(vrm.semi.imp.df,rug.semi.imp.df)

#Check Levels of Morphology
levels(complexity.inc.mse$morphology)
complexity.inc.mse$morphology <- factor(complexity.inc.mse$morphology, levels = vrm.semi.imp.df$morphology)

mse1 <- ggplot(complexity.inc.mse, aes(x = Percent.Inc.MSE, y=morphology, colour= metric, factor(Percent.Inc.MSE))) + geom_point() + theme_classic(base_size = 16) + xlab("") + ylab("") +  theme(legend.position="none")














#<------------ Jenn's Classification ------------>
#VRM
vrm.jm.imp <- vrm.classify3$importance
vrm.jm.sd <- vrm.classify3$importanceSD

#Convert to dataframe
vrm.jm.imp <- as.data.frame(vrm.jm.imp)
vrm.jm.sd <- as.data.frame(vrm.jm.sd)

#Bind two df's together
vrm.jm.imp.df  <- cbind(vrm.jm.imp,vrm.jm.sd)
colnames(vrm.jm.imp.df) 
str(vrm.jm.imp.df) #All numeric

colnames(vrm.jm.imp.df)[which(names(vrm.jm.imp.df)=="%IncMSE")] <- "MSE"
colnames(vrm.jm.imp.df)[which(names(vrm.jm.imp.df)=="IncNodePurity")] <- "nodepurity"
colnames(vrm.jm.imp.df)[which(names(vrm.jm.imp.df)=="vrm.jm.sd")] <- "imp.sd"
colnames(vrm.jm.imp.df)

vrm.jm.imp.df$Percent.Inc.MSE <- (vrm.jm.imp.df$MSE) / (vrm.jm.imp.df$imp.sd)
vrm.jm.imp.df$metric <- "vrm"
vrm.jm.imp.df$morphology <- rownames(vrm.jm.imp.df)

#Rename rownames as numbers
dim(vrm.jm.imp.df)
rownames(vrm.jm.imp.df)<-c(1:5)

#Order from low% to high% mse
vrm.jm.imp.df<- vrm.jm.imp.df[order(vrm.jm.imp.df$Percent.Inc.MSE),]
row.names(vrm.jm.imp.df) <- 1:nrow(vrm.jm.imp.df) #Changes the row names so that they are re-orderd 1-21

vrm.jm.imp.df #Compare with varImpPlot(vrm.classify2, cex=1, scale=TRUE)



#<----- Surface Complexity ----->
#Load 2 dataframes
rug.jm.imp <- rug.classify3$importance
rug.jm.sd <- rug.classify3$importanceSD

#Convert to dataframe
rug.jm.imp <- as.data.frame(rug.jm.imp)
rug.jm.sd <- as.data.frame(rug.jm.sd)

#Bind two df's together
rug.jm.imp.df  <- cbind(rug.jm.imp,rug.jm.sd)
colnames(rug.jm.imp.df) 
str(rug.jm.imp.df) #All numeric

colnames(rug.jm.imp.df)[which(names(rug.jm.imp.df)=="%IncMSE")] <- "MSE"
colnames(rug.jm.imp.df)[which(names(rug.jm.imp.df)=="IncNodePurity")] <- "nodepurity"
colnames(rug.jm.imp.df)[which(names(rug.jm.imp.df)=="rug.jm.sd")] <- "imp.sd"

colnames(rug.jm.imp.df)

rug.jm.imp.df$Percent.Inc.MSE <- (rug.jm.imp.df$MSE) / (rug.jm.imp.df$imp.sd)
rug.jm.imp.df$metric <- "surface.complexity"
rug.jm.imp.df$morphology <- rownames(rug.jm.imp.df)

#Rename rownames as numbers
dim(rug.jm.imp.df)
rownames(rug.jm.imp.df)<-c(1:5)

#Order from low% to high% mse
rug.jm.imp.df<- rug.jm.imp.df[order(rug.jm.imp.df$Percent.Inc.MSE),]
row.names(rug.jm.imp.df) <- 1:nrow(rug.jm.imp.df) #Changes the row names so that they are re-orderd 1-21

rug.jm.imp.df #Compare with varImpPlot(rug.classify2, cex=1, scale=TRUE)


#Combine rug _ vrm together
complexity.jm.inc.mse<- rbind(vrm.jm.imp.df,rug.jm.imp.df)

#Check Levels of Morphology
levels(complexity.jm.inc.mse$morphology)
complexity.jm.inc.mse$morphology <- factor(complexity.jm.inc.mse$morphology, levels = vrm.jm.imp.df$morphology)

mse2 <- ggplot(complexity.jm.inc.mse, aes(x = Percent.Inc.MSE, y=morphology, colour= metric, factor(Percent.Inc.MSE))) + geom_point() + theme_classic(base_size = 16) + xlab("") + ylab("") +  theme(legend.position="none") 



#Plot 2 figures together into publication-worthy plot as requested by JKB
arrange <- ggarrange(mse1, mse2) 

annotate_figure(arrange, top = text_grob("Blue=VRM | Red=SurfaceComplexity", color = "black", face = "bold", size = 18),  bottom = text_grob("% Increase MSE", color = "black", size = 18, face = "bold"))










```


