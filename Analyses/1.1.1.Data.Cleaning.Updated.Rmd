---
title: "1.1.1 MPQ.data.cleaning.updated"
author: "Kevin Bruce"
date: "14/01/2021"
output: html_document
---
#Load R Packages
```{r load packages, include=FALSE}
#Load Packages
library(dplyr)
library(ggplot2)
library(stats)
library(Rmisc)
library(here)
library(ggpmisc)
library(knitr)
library(magick)
library(gridExtra)
library(car)
library(tidyr)
library(readxl)
library(vegan)
library(tidyverse)
library(DHARMa)
library(reshape2)

# knitr::opts_chunk$set(echo = TRUE)

```

# Cloud Compare Volumetric Analysis
```{r Clean CloudCompare Data, include=FALSE}
###################################################
##### NEW CLOUD COMPARE DATA WITH TRUE VALUES ####
##################################################

#Set the Working Directory
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data")

#Load CloudCompare data
CC.new <- read.csv("BaumLab_CloudCompare_Final.csv")

#Change colnames for the collumns
colnames(CC.new)[which(names(CC.new)=="Hum_Dist")] <- "hum_dist"
colnames(CC.new)[which(names(CC.new)=="Period")] <- "timepoint"
colnames(CC.new)[which(names(CC.new)=="MPQ")] <- "ppq"
colnames(CC.new)[which(names(CC.new)=="Site")] <- "site"
colnames(CC.new)[which(names(CC.new)=="Volume")] <- "volume.change"
colnames(CC.new)[which(names(CC.new)=="Added.Volume")] <- "volume.added"
colnames(CC.new)[which(names(CC.new)=="Removed.Volume")] <- "volume.removed"

colnames(CC.new)


#For loop time! Make for looks to add values for human disturbance, publication site name, and region
#Add according values to human dist collumn
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$hum_dist[i] <- "Very Low"
  } else if(CC.new$site[i]=="19") {
    CC.new$hum_dist[i] <- "Very Low"
  } else if(CC.new$site[i]=="15") {
    CC.new$hum_dist[i] <- "Very Low"
  } else if(CC.new$site[i]=="8") {
    CC.new$hum_dist[i] <- "Medium"
  } else if(CC.new$site[i]=="34") {
    CC.new$hum_dist[i] <- "Medium"
  } else if(CC.new$site[i]=="35") {
   CC.new$hum_dist[i] <- "Medium"
  } else if(CC.new$site[i]=="27") {
   CC.new$hum_dist[i] <- "Very High"
  } else if(CC.new$site[i]=="30") {
   CC.new$hum_dist[i] <- "Very High"
  } else if(CC.new$site[i]=="32") {
    CC.new$hum_dist[i] <- "Very High"
  } else if(CC.new$site[i]=="37") {
    CC.new$hum_dist[i] <- "Very Low"
  }}

#2. Create 4 subsections for the region collumn:
#2a: Side of island (2 levels)
CC.new$island.side <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="19") {
    CC.new$island.side[i] <- "Windward"
  } else if(CC.new$site[i]=="15") {
    CC.new$island.side[i] <- "Windward"
  } else if(CC.new$site[i]=="8") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="34") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="35") {
   CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="27") {
   CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="30") {
   CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="32") {
    CC.new$island.side[i] <- "Leeward"
  } else if(CC.new$site[i]=="37") {
    CC.new$island.side[i] <- "Leeward"
  }}

#2b. Region.3 = 3 levels
CC.new$region.3 <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$region.3[i] <- "South Shore"
  } else if(CC.new$site[i]=="19") {
    CC.new$region.3[i] <- "Windward"
  } else if(CC.new$site[i]=="15") {
    CC.new$region.3[i] <- "Windward"
  } else if(CC.new$site[i]=="8") {
    CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="34") {
    CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="35") {
   CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="27") {
   CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="30") {
   CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="32") {
    CC.new$region.3[i] <- "Leeward"
  } else if(CC.new$site[i]=="37") {
    CC.new$region.3[i] <- "South Shore"
  }}

#2c. Region.4 = 4 levels
CC.new$region.4 <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$region.4[i] <- "Vaskess Bay"
  } else if(CC.new$site[i]=="19") {
    CC.new$region.4[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="15") {
    CC.new$region.4[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="8") {
    CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="34") {
    CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="35") {
   CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="27") {
   CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="30") {
   CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="32") {
    CC.new$region.4[i] <- "Leeward"
  } else if(CC.new$site[i]=="37") {
    CC.new$region.4[i] <- "Vaskess Bay"
  }}


#2d. Full Region Breakdown (5 levels)
#2c. Region.4 = 4 levels
CC.new$region.full <- "a"

#Assign Region values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$region.full[i] <- "Vaskess Bay"
  } else if(CC.new$site[i]=="19") {
    CC.new$region.full[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="15") {
    CC.new$region.full[i] <- "Bay of Wrecks"
  } else if(CC.new$site[i]=="8") {
    CC.new$region.full[i] <- "South Lagoon"
  } else if(CC.new$site[i]=="34") {
    CC.new$region.full[i] <- "South Lagoon"
  } else if(CC.new$site[i]=="35") {
   CC.new$region.full[i] <- "South Lagoon"
  } else if(CC.new$site[i]=="27") {
   CC.new$region.full[i] <- "North Lagoon"
  } else if(CC.new$site[i]=="30") {
   CC.new$region.full[i] <- "North Lagoon"
  } else if(CC.new$site[i]=="32") {
    CC.new$region.full[i] <- "Mid Lagoon"
  } else if(CC.new$site[i]=="37") {
    CC.new$region.full[i] <- "Vaskess Bay"
  }}

#3 Assign publication name to site
CC.new$pub.site <- "a"

#Assign pub site values
for(i in c(1:nrow(CC.new))) {
  if(CC.new$site[i]=="5") {
    CC.new$pub.site[i] <- "VL3"
  } else if(CC.new$site[i]=="19") {
    CC.new$pub.site[i] <- "VL2"
  } else if(CC.new$site[i]=="15") {
    CC.new$pub.site[i] <- "VL1"
  } else if(CC.new$site[i]=="8") {
    CC.new$pub.site[i] <- "M1"
  } else if(CC.new$site[i]=="34") {
    CC.new$pub.site[i] <- "M3"
  } else if(CC.new$site[i]=="35") {
   CC.new$pub.site[i] <- "M2"
  } else if(CC.new$site[i]=="27") {
   CC.new$pub.site[i] <- "VH1"
  } else if(CC.new$site[i]=="30") {
   CC.new$pub.site[i] <- "VH3"
  } else if(CC.new$site[i]=="32") {
    CC.new$pub.site[i] <- "VH2"
  } else if(CC.new$site[i]=="37") {
    CC.new$pub.site[i] <- "VL4"
  }}

colnames(CC.new)





#Remove the extra collums in the cloudcompare data that aren't necessary
CC.new <- subset(CC.new, select = c("pub.site","site", "ppq","hum_dist", "island.side" ,"region.3", "region.4", "region.full", "Initial.Timepoint", "Final.Timepoint", "timepoint", "volume.change"))
colnames(CC.new)
CC.new



#Change levels of sites to match disturbance level
CC.new$site <- factor(CC.new$site, levels = c("27", "30", "32", "8", "34", "35", "5", "15", "19", "37"))


#Check structure of CC
str(CC.new)   ###human_dist is a factor, which we need to change to a character

#Change hum_dist and mpq to a character
CC.new$hum_dist <- as.character(CC.new$hum_dist)
CC.new$ppq <- as.character(CC.new$ppq)
CC.new$site <- as.character(CC.new$site)

str(CC.new)

#Assign levels to CC$hum_dist
levels(CC.new$hum_dist)
CC.new$hum_dist <- factor(CC.new$hum_dist, levels = c("Very High","Medium", "Very Low"))
levels(CC.new$hum_dist)

#Create new collumn to bind two dataframes together with (after creating 2017-2019 calculated dataframe)
CC.new$ID <- paste(CC.new$pub.site, CC.new$ppq, sep=".")

CC.new$timeblock <- "blank"

# #for loop to assign "timeblock" values to timepoints to make future for loop easier
# for(i in 1:length(CC.new$timepoint)) {
#   if(CC.new$timepoint[i] == "2015-2017"){
#     CC.new$timeblock[i] <- 1 } 
#   if(CC.new$timepoint[i] == "2017-2019"){
#     CC.new$timeblock[i] <- 3 }
#   if(CC.new$timepoint[i] == "2015-2019"){
#     CC.new$timeblock[i] <- 2 }
#   }

#for loop to assign "timeblock" values to timepoints to make future for loop easier
for(i in 1:length(CC.new$timepoint)) {
  if(CC.new$timepoint[i] == "A"){
    CC.new$timeblock[i] <- 1 } 
  if(CC.new$timepoint[i] == "B"){
    CC.new$timeblock[i] <- 3 }
  if(CC.new$timepoint[i] == "C"){
    CC.new$timeblock[i] <- 2 }
  }

#Remove unneeded collumns
CC.new.1 <- CC.new[,-(9:10)]

#Calculate 2017-2019 Timepoint
#Create new dataframe
CC.new.2 <- as.data.frame(matrix(data=NA,ncol=12, nrow=50))

colnames(CC.new.2) <- colnames(CC.new.1)

ID.variables <- unique(CC.new.1$ID)

#forloop
for(i in 1:length(ID.variables)) {
  xx <- subset(CC.new.1, ID == ID.variables[i])
  after <- xx %>% filter(timeblock == 3)
  if(length(after$timepoint) > 0) next
  before <- xx %>% filter(timeblock == 1)
  full <- xx %>% filter(timeblock == 2)
  before_value <- before$volume.change[1]
  full_value <- full$volume.change[1]
  after_value <- full_value - before_value
  CC.new.2$island.side[i] <- before$island.side[1]
  CC.new.2$timepoint[i] <- "2017-2019"
  CC.new.2$hum_dist[i] <- before$hum_dist[1]
  CC.new.2$site[i] <- before$site[1]
  CC.new.2$pub.site[i] <- before$pub.site[1]
  CC.new.2$ppq[i] <- before$ppq[1]
  CC.new.2$region.3[i] <- before$region.3[1]
  CC.new.2$region.4[i] <- before$region.4[1]
  CC.new.2$region.full[i] <- before$region.full[1]
  CC.new.2$volume.change[i] <- after_value
  CC.new.2$ID[i] <- before$ID[1]
  CC.new.2$timeblock[i] <- 3  
  
}

CC.new.2.1 <- CC.new.2 %>% drop_na()

#Change structure around of new df
CC.new.2.1$hum_dist <- as.factor(CC.new.2.1$hum_dist)
CC.new.2.1$hum_dist <- factor(CC.new.2.1$hum_dist, levels = c("Very High","Medium", "Very Low"))
levels(CC.new.2.1$hum_dist)

#Change timepoint information from A, B,C to year differences
CC.new.2.1$timepoint <- factor(CC.new.2.1$timepoint, levels =c("A", "B", "C"), labels = c("2015-2017", "2017-2019", "2015-2019"))

str(CC.new.1)
levels(CC.new.1$timepoint)

str(CC.new.2.1)

CC.new.2.1$timepoint <- "B"

#Change timepoint information from A, B,C to year differences
CC.new$timepoint <- factor(CC.new$timepoint, levels =c("A", "B", "C"), labels = c("2015-2017", "2017-2019", "2015-2019"))
CC.new


#Bind two together
CC.total <- rbind(CC.new.1, CC.new.2.1)

#Fix human disturbance values
for(i in c(1:nrow(CC.total))) {
  if(CC.total$site[i]=="5") {
    CC.total$hum_dist[i] <- "Very Low"
  } else if(CC.total$site[i]=="19") {
    CC.total$hum_dist[i] <- "Very Low"
  } else if(CC.total$site[i]=="15") {
    CC.total$hum_dist[i] <- "Very Low"
  } else if(CC.total$site[i]=="8") {
    CC.total$hum_dist[i] <- "Medium"
  } else if(CC.total$site[i]=="34") {
    CC.total$hum_dist[i] <- "Medium"
  } else if(CC.total$site[i]=="35") {
   CC.total$hum_dist[i] <- "Medium"
  } else if(CC.total$site[i]=="27") {
   CC.total$hum_dist[i] <- "Very High"
  } else if(CC.total$site[i]=="30") {
   CC.total$hum_dist[i] <- "Very High"
  } else if(CC.total$site[i]=="32") {
    CC.total$hum_dist[i] <- "Very High"
  } else if(CC.total$site[i]=="37") {
    CC.total$hum_dist[i] <- "Very Low"
  }}

CC.total

#Add in continuous human disturbance gradient scores
CC.total$hdist.cont <- 1

#Input values 
for(i in c(1:nrow(CC.total))) {
  if(CC.total$site[i]=="5") {
    CC.total$hdist.cont[i] <- "0"
  } else if(CC.total$site[i]=="19") {
    CC.total$hdist.cont[i] <- "0"
  } else if(CC.total$site[i]=="15") {
    CC.total$hdist.cont[i] <- "0"
  } else if(CC.total$site[i]=="8") {
    CC.total$hdist.cont[i] <- "1212.82819"
  } else if(CC.total$site[i]=="34") {
    CC.total$hdist.cont[i] <- "1212.82819"
  } else if(CC.total$site[i]=="35") {
   CC.total$hdist.cont[i] <- "1212.82819"
  } else if(CC.total$site[i]=="27") {
   CC.total$hdist.cont[i] <- "7276"
  } else if(CC.total$site[i]=="30") {
   CC.total$hdist.cont[i] <- "5085.68478"
  } else if(CC.total$site[i]=="32") {
    CC.total$hdist.cont[i] <- "4860.7457"
  } else if(CC.total$site[i]=="37") {
    CC.total$hdist.cont[i] <- "0"
  }}


#Create Final Output file to model
CC.final <- CC.total[,-(11:12)]

#Square Root transform the h.dist continuous variable
CC.final$sqrt.hdist.cont <- 1
str(CC.final$hdist.cont) 
CC.final$hdist.cont <- as.numeric(CC.final$hdist.cont) #Make continuous value a numeric
CC.final$sqrt.hdist.cont <- sqrt(CC.final$hdist.cont)

colnames(CC.final)

#Set levels for each dataframe
CC.final$timepoint.site.ppq <- paste(CC.final$timepoint, CC.final$site, CC.final$ppq, sep = ".")
levels(CC.final$timepoint.site.ppq)
head(CC.final$timepoint.site.ppq)
CC.final$timepoint.site.ppq<- factor(CC.final$timepoint.site.ppq, levels = c("A.27.1","A.27.2","A.27.3", "A.32.1","A.32.2", "A.32.3", "A.30.1", "A.30.2","A.30.3", "A.8.1","A.8.2", "A.8.3", "A.35.1","A.35.2", "A.35.3", "A.34.1", "A.34.2", "A.34.3", "A.15.1", "A.15.2", "A.15.3", "A.19.1", "A.19.2", "A.5.1", "A.5.2", "A.5.3","B.27.1","B.27.2","B.27.3", "B.32.1","B.32.2", "B.32.3", "B.30.1", "B.30.2","B.30.3", "B.8.1","B.8.2", "B.8.3", "B.35.1","B.35.2", "B.35.3", "B.34.1", "B.34.2", "B.34.3", "B.5.1","B.5.2", "B.5.3",  "B.37.1", "B.37.2", "B.37.3", "C.27.1","C.27.2","C.27.3", "C.32.1","C.32.2", "C.32.3", "C.30.1", "C.30.2","C.30.3", "C.8.1","C.8.2", "C.8.3", "C.35.1","C.35.2", "C.35.3", "C.34.1", "C.34.2", "C.34.3", "C.5.1","C.5.2", "C.5.3"))

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
CC.final<- CC.final[order(CC.final$timepoint.site.ppq),]
row.names(CC.final) <- 1:nrow(CC.final) #Changes the row names so that they are re-orderd 1-80

#Convert Timepoint to year range
CC.final$timepoint <- factor(CC.final$timepoint, levels =c("A", "B", "C"), labels = c("2015-2017", "2017-2019", "2015-2019"))
CC.final

#Create unique collumn for plotting figure later
CC.final$time.interval <- "a"
for(i in 1:length(CC.final$timepoint)) {
  if(CC.final$timepoint[i] == "2015-2017"){
    CC.final$time.interval[i] <-"'15-'17"} 
  if(CC.final$timepoint[i] == "2017-2019"){
    CC.final$time.interval[i] <- "'17-'19" }
  if(CC.final$timepoint[i] == "2015-2019"){
    CC.final$time.interval[i] <- "'15-'19" }
  }



CC.final <- subset(CC.final, select = c("pub.site", "site", "ppq", "hum_dist","sqrt.hdist.cont", "island.side", "region.3", "timepoint","time.interval", "volume.change"))

#Export Clean Data as a csv
write.csv(CC.final, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_CloudCompare_Data_FINAL_14Jan2021.csv")
```

#Complexity + Curvature Metric Quantification
```{r Clean ArcMap complexity data, include = FALSE}
# #Set the Working Directory
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data")

#Load the data
mpq <- read.csv("ArcMAP_MPQ_Complexity_FINAL.csv")

#Change collumn headers to make it easier to code
colnames(mpq)[which(names(mpq)=="Year")] <- "year"
colnames(mpq)[which(names(mpq)=="Site")] <- "site"
colnames(mpq)[which(names(mpq)=="plot")] <- "ppq"
colnames(mpq)[which(names(mpq)=="DEM.scale")] <- "DEM"
colnames(mpq)[which(names(mpq)=="Complexity.Calculation")] <- "rug"
colnames(mpq)[which(names(mpq)=="Avg..BTM_Slope")] <- "slope"
colnames(mpq)[which(names(mpq)=="Avg_terrain_ruggedness..VRM."  )] <- "vrm"
colnames(mpq)[which(names(mpq)=="profile.curvature")] <- "pro.curv"
colnames(mpq)[which(names(mpq)=="planform.curvature")] <- "plan.curv"
colnames(mpq)[which(names(mpq)=="average.curvature")] <- "curv"
colnames(mpq)[which(names(mpq)=="SHAPE_Area")] <- "area_2d"
colnames(mpq)[which(names(mpq)=="SArea")] <- "area_3d"

#Do 3 for-loops of assigning values in new collumns
#1 to assign human disturbance levels
#2 to assign sites to a region 
#3 to assign publication name to site

#1: For look to add human distrubance levels
#Add human_dist collumn to kb Dataframe
mpq$hum_dist <- "a"

# #Delete rows in site collum that are NA
# mpq %>% filter(!is.na(site))
# tail(mpq$site)

#Add according values to human dist collumn
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$hum_dist[i] <- "Very Low"
  } else if(mpq$site[i]=="19") {
    mpq$hum_dist[i] <- "Very Low"
  } else if(mpq$site[i]=="15") {
    mpq$hum_dist[i] <- "Very Low"
  } else if(mpq$site[i]=="8") {
    mpq$hum_dist[i] <- "Medium"
  } else if(mpq$site[i]=="34") {
    mpq$hum_dist[i] <- "Medium"
  } else if(mpq$site[i]=="35") {
   mpq$hum_dist[i] <- "Medium"
  } else if(mpq$site[i]=="27") {
   mpq$hum_dist[i] <- "Very High"
  } else if(mpq$site[i]=="30") {
   mpq$hum_dist[i] <- "Very High"
  } else if(mpq$site[i]=="32") {
    mpq$hum_dist[i] <- "Very High"
  } else if(mpq$site[i]=="37") {
    mpq$hum_dist[i] <- "Very Low"
  }}

#2. Create a collumn for my region assignments & fill it with values
mpq$region.kb <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.kb[i] <- "Vaskes"
  } else if(mpq$site[i]=="19") {
    mpq$region.kb[i] <- "BOW"
  } else if(mpq$site[i]=="15") {
    mpq$region.kb[i] <- "BOW"
  } else if(mpq$site[i]=="8") {
    mpq$region.kb[i] <- "S.Lagoon"
  } else if(mpq$site[i]=="34") {
    mpq$region.kb[i] <- "S.Lagoon"
  } else if(mpq$site[i]=="35") {
   mpq$region.kb[i] <- "S.Lagoon"
  } else if(mpq$site[i]=="27") {
   mpq$region.kb[i] <- "N.Lagoon"
  } else if(mpq$site[i]=="30") {
   mpq$region.kb[i] <- "N.Lagoon"
  } else if(mpq$site[i]=="32") {
    mpq$region.kb[i] <- "N.Lagoon"
  } else if(mpq$site[i]=="37") {
    mpq$region.kb[i] <- "Vaskes"
  }}

#3 Assign publication name to site
mpq$pub.site <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$pub.site[i] <- "VL3"
  } else if(mpq$site[i]=="19") {
    mpq$pub.site[i] <- "VL3"
  } else if(mpq$site[i]=="15") {
    mpq$pub.site[i] <- "VL1"
  } else if(mpq$site[i]=="8") {
    mpq$pub.site[i] <- "M1"
  } else if(mpq$site[i]=="34") {
    mpq$pub.site[i] <- "M3"
  } else if(mpq$site[i]=="35") {
   mpq$pub.site[i] <- "M2"
  } else if(mpq$site[i]=="27") {
   mpq$pub.site[i] <- "VH1"
  } else if(mpq$site[i]=="30") {
   mpq$pub.site[i] <- "VH3"
  } else if(mpq$site[i]=="32") {
    mpq$pub.site[i] <- "VH2"
  } else if(mpq$site[i]=="37") {
    mpq$pub.site[i] <- "VL4"
  }}


mpq

#Create dataframe with only columns I require
mpq.temp <- subset(mpq, select = c("year","hum_dist","site", "pub.site", "ppq", "DEM", "area_2d", "area_3d", "rug", "slope", "vrm", "curv", "pro.curv", "plan.curv", "region.kb"))

#Switch dataframe name back to mpq
mpq <- mpq.temp
str(mpq)

# #Create unique colname
mpq$year.site.ppq <- paste(mpq$year, mpq$site, mpq$ppq, sep = ".")

#Change descriptors to factors (Ex: Year, region, disturbance)
# mpq$region <- as.factor(mpq$region) 
# levels(mpq$region)
mpq$hum_dist <- as.factor(mpq$hum_dist) 
mpq$hum_dist <- factor(mpq$hum_dist, levels = c("Very Low", "Medium", "Very High" ))
mpq$site <- factor(mpq$site, levels =c("27", "30", "32", "8", "34", "35", "5", "15", "19", "37"))
levels(mpq$hum_dist)
#levels(mpq$site.ppq)
#mpq$site.ppq<- factor(mpq$site.ppq, levels = c("27.1", "27.2", "27.3", "30.1", "30.2", "30.3", "32.1", "32.2", "32.3", "8.1", "8.2", "8.3", "34.1", "34.2", "34.3", "35.1", "35.2", "35.3", "5.1", "5.2", "5.3", "15.1", "15.2", "15.3", "19.1", "19.2", "19.3", "37.1", "37.2", "37.3"))

#Reorder the dataframe
colnames(mpq)
mpq <- subset(mpq, select = c ("year",  "hum_dist",  "pub.site", "site","ppq", "DEM", "area_2d", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv", "region.kb"))

#Add in region collumns according to KI publication records
#2. Create 4 subsections for the region collumn:
#2a: Side of island (2 levels)
mpq$island.side <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="19") {
    mpq$island.side[i] <- "Windward"
  } else if(mpq$site[i]=="15") {
    mpq$island.side[i] <- "Windward"
  } else if(mpq$site[i]=="8") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="34") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="35") {
   mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="27") {
   mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="30") {
   mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="32") {
    mpq$island.side[i] <- "Leeward"
  } else if(mpq$site[i]=="37") {
    mpq$island.side[i] <- "Leeward"
  }}

#2b. Region.3 = 3 levels
mpq$region.3 <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.3[i] <- "South Shore"
  } else if(mpq$site[i]=="19") {
    mpq$region.3[i] <- "Windward"
  } else if(mpq$site[i]=="15") {
    mpq$region.3[i] <- "Windward"
  } else if(mpq$site[i]=="8") {
    mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="34") {
    mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="35") {
   mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="27") {
   mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="30") {
   mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="32") {
    mpq$region.3[i] <- "Leeward"
  } else if(mpq$site[i]=="37") {
    mpq$region.3[i] <- "South Shore"
  }}

#2c. Region.4 = 4 levels
mpq$region.4 <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.4[i] <- "Vaskess Bay"
  } else if(mpq$site[i]=="19") {
    mpq$region.4[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="15") {
    mpq$region.4[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="8") {
    mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="34") {
    mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="35") {
   mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="27") {
   mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="30") {
   mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="32") {
    mpq$region.4[i] <- "Leeward"
  } else if(mpq$site[i]=="37") {
    mpq$region.4[i] <- "Vaskess Bay"
  }}


#2d. Full Region Breakdown (5 levels)
#2c. Region.4 = 4 levels
mpq$region.full <- "a"

#Assign Region values
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$region.full[i] <- "Vaskess Bay"
  } else if(mpq$site[i]=="19") {
    mpq$region.full[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="15") {
    mpq$region.full[i] <- "Bay of Wrecks"
  } else if(mpq$site[i]=="8") {
    mpq$region.full[i] <- "South Lagoon"
  } else if(mpq$site[i]=="34") {
    mpq$region.full[i] <- "South Lagoon"
  } else if(mpq$site[i]=="35") {
   mpq$region.full[i] <- "South Lagoon"
  } else if(mpq$site[i]=="27") {
   mpq$region.full[i] <- "North Lagoon"
  } else if(mpq$site[i]=="30") {
   mpq$region.full[i] <- "North Lagoon"
  } else if(mpq$site[i]=="32") {
    mpq$region.full[i] <- "Mid Lagoon"
  } else if(mpq$site[i]=="37") {
    mpq$region.full[i] <- "Vaskess Bay"
  }}

#Add in continuous human disturbance gradient scores
mpq$hdist.cont <- 1

#Input values 
for(i in c(1:nrow(mpq))) {
  if(mpq$site[i]=="5") {
    mpq$hdist.cont[i] <- "0"
  } else if(mpq$site[i]=="19") {
    mpq$hdist.cont[i] <- "0"
  } else if(mpq$site[i]=="15") {
    mpq$hdist.cont[i] <- "0"
  } else if(mpq$site[i]=="8") {
    mpq$hdist.cont[i] <- "1212.82819"
  } else if(mpq$site[i]=="34") {
    mpq$hdist.cont[i] <- "1212.82819"
  } else if(mpq$site[i]=="35") {
   mpq$hdist.cont[i] <- "1212.82819"
  } else if(mpq$site[i]=="27") {
   mpq$hdist.cont[i] <- "7276"
  } else if(mpq$site[i]=="30") {
   mpq$hdist.cont[i] <- "5085.68478"
  } else if(mpq$site[i]=="32") {
    mpq$hdist.cont[i] <- "4860.7457"
  } else if(mpq$site[i]=="37") {
    mpq$hdist.cont[i] <- "0"
  }}


colnames(mpq)
mpq$hdist.cont <- as.numeric(mpq$hdist.cont)

#Square Root transform the h.dist continuous variable
mpq$sqrt.hdist.cont <- 1
mpq$sqrt.hdist.cont <- sqrt(mpq$hdist.cont) 
str(mpq$sqrt.hdist.cont)

#Reorder dataframe to export for future analyses
mpq1 <- subset(mpq, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont","sqrt.hdist.cont","island.side", "region.3", "region.4", "region.full", "region.kb", "DEM", "area_2d", "area_3d", "rug", "vrm", "curv", "pro.curv", "plan.curv"))



#<----------------------------------------------------------------------------------------------------------------------------------------------------
#Create unique id collumn
mpq1$year.site.ppq <- paste(mpq1$year, mpq1$site, mpq1$ppq, sep = ".")

#Break up by DEM
mpq.1 <- subset(mpq1, DEM == 1)
mpq.4 <- subset(mpq1, DEM == 4)
mpq.8 <- subset(mpq1, DEM == 8)

#<--------------------------------------------------------------------------------------------------------->
#1cm DEM
#Set levels for each dataframe
levels(mpq.1$year.site.ppq)
mpq.1$year.site.ppq<- factor(mpq.1$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.1$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
mpq.1<- mpq.1[order(mpq.1$year.site.ppq),]
row.names(mpq.1) <- 1:nrow(mpq.1) #Changes the row names so that they are re-orderd 1-80

#<--------------------------------------------------------------------------------------------------------->
#4cm DEM
#Set levels for each dataframe
levels(mpq.4$year.site.ppq)
mpq.4$year.site.ppq<- factor(mpq.4$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.4$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
mpq.4<- mpq.4[order(mpq.4$year.site.ppq),]
row.names(mpq.4) <- 1:nrow(mpq.4) #Changes the row names so that they are re-orderd 1-80

#<--------------------------------------------------------------------------------------------------------->
#8cm DEM
#Set levels for each dataframe
levels(mpq.8$year.site.ppq)
mpq.8$year.site.ppq<- factor(mpq.8$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(mpq.8$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
mpq.8<- mpq.8[order(mpq.8$year.site.ppq),]
row.names(mpq.8) <- 1:nrow(mpq.8) #Changes the row names so that they are re-orderd 1-80
#<--------------------------------------------------------------------------------------------------------->
#Merge all 3 DEM df's together
mpq.all <- rbind(mpq.1, mpq.4, mpq.8)


#<--------------------------------------------------------------------------------------------------------->
#Break dataframe up into its sub-components
mpq.all #Dataframe with all 5 timepoints for initial modelling



####################################################
################# FRACTAL DIMENSION ################
####################################################

#Equation is D = 2-(slope log(S(s))/log(s))
#     s = resolution of the DEM in meters (ex: 0.01, 0.04, 0.08)
#     S(s) = 3D surface area at the given resolution 


# Atsuko did 3D/2D ratio to # using log(s_area/area) to account for changes in are due to raster aggregate function (unsure if we should do that. We didn't use aggregate function, but will get values similar to Johns.....)

#Create new dataframe to house fractal dimension data
frac <- mpq1

#Drop Complexity measures
frac <- frac[,-(16:20)] #Remove complexity metrics but leave area_3d
frac <- frac[,-(14)] #Remove area_2d

#And make a single DEM category to link back all metadata to
frac.1 <- subset(mpq, DEM == 1)

# #Create unique col name
frac.1$year.site.ppq <- paste(frac.1$year, frac.1$site, frac.1$ppq, sep = ".")

nrow(frac.1) #127
nrow(frac) #381

str(frac)

frac$DEM <- as.numeric(frac$DEM)

#Change DEM scale from cm to meters and log it
frac$resolution <- frac$DEM / 100
frac$resolution.log <- log(frac$DEM / 100)

#Log 3d area
frac$log3d <- log(frac$area_3d)
  
nrow(frac)

#Make a table for the slopes
slope <- as.data.frame(matrix(data=NA, nrow=length(unique(frac.1$year.site.ppq)), ncol= 5))
colnames(slope) <- c("year.site.ppq", "slope.val", "year", "site", "ppq")
slope$year.site.ppq <- unique(frac.1$year.site.ppq)
slope$year <- frac.1$year
slope$site <- frac.1$site
slope$ppq <- frac.1$ppq

nrow(frac.1)


for (i in 1:nrow(slope)){
  xx <- subset(frac, year.site.ppq == slope$year.site.ppq[i])
  lm_i <- lm(log3d ~ resolution.log, xx)
  slope_i <- coef(lm_i)[[2]]
  slope$slope.val[i] <- slope_i
}


#Compute fractal dimension
slope$fractal.dimension <- 2- slope$slope.val
colnames(slope)

#Add in continuous human disturbance gradient scores
slope$hdist.cont <- 1

#Input values 
for(i in c(1:nrow(slope))) {
  if(slope$site[i]=="5") {
    slope$hdist.cont[i] <- "0"
  } else if(slope$site[i]=="19") {
    slope$hdist.cont[i] <- "0"
  } else if(slope$site[i]=="15") {
    slope$hdist.cont[i] <- "0"
  } else if(slope$site[i]=="8") {
    slope$hdist.cont[i] <- "1212.82819"
  } else if(slope$site[i]=="34") {
    slope$hdist.cont[i] <- "1212.82819"
  } else if(slope$site[i]=="35") {
   slope$hdist.cont[i] <- "1212.82819"
  } else if(slope$site[i]=="27") {
   slope$hdist.cont[i] <- "7276"
  } else if(slope$site[i]=="30") {
   slope$hdist.cont[i] <- "5085.68478"
  } else if(slope$site[i]=="32") {
    slope$hdist.cont[i] <- "4860.7457"
  } else if(slope$site[i]=="37") {
    slope$hdist.cont[i] <- "0"
  }}


colnames(slope)
slope$hdist.cont <- as.numeric(slope$hdist.cont)

#Square Root transform the h.dist continuous variable
slope$sqrt.hdist.cont <- 1
slope$sqrt.hdist.cont <- sqrt(slope$hdist.cont) 
str(slope$sqrt.hdist.cont)

#Order dataframe properly
#Set levels for each dataframe
levels(slope$year.site.ppq)
slope$year.site.ppq<- factor(slope$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(slope$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
slope<- slope[order(slope$year.site.ppq),]
row.names(slope) <- 1:nrow(slope) #Changes the row names so that they are re-orderd 1-80

head(slope)
#Reorder dataframe
slope1 <- subset(slope, select = c("year", "sqrt.hdist.cont","site", "ppq", "fractal.dimension"))

ggplot(slope1, aes(x = year, y=fractal.dimension, fill=year)) + geom_boxplot() + theme_classic(base_size = 16) + xlab("Year") + ylab("Fractal Dimension") +  theme(legend.position="none")

#Fractal Dimension dataframe
slope1
frac <- subset(slope1, select = c("fractal.dimension")) #To combine with other metrics in 1cm DEM group

####################################################
############# Curvature Range #####################
####################################################
#Load CloudCompare data
ranges <- read.csv("Complexity.Range.Raw.csv", row.names = 1)

#Create new columns
ranges$vrm.range <- 1 
ranges$pro.range <- 2
ranges$plan.range <- 3

#Calculate range values for vrm, pro, & plan curvatures
ranges$vrm.range <- ranges$vrm.max - ranges$vrm.min
ranges$pro.range <- ranges$pro.max - ranges$pro.min
ranges$plan.range <- ranges$plan.max - ranges$plan.min

#Create final dataframe to later merge with other complexity dataset
range.final <- ranges[,-(6:14)]



#Add onto complexity dataframe
mpq.all #complexity metrics
colnames(mpq.all)
mpq <- cbind(mpq.all, range.final)


#Add collumns of log-transformed profile range
mpq$pro.range.log <- log(mpq$pro.range)
mpq$plan.range.log <- log(mpq$plan.range)

#ReOrder dataframe
colnames(mpq)
mpq <- subset(mpq, select = c("year", "pub.site",  "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "year.site.ppq", "area_2d", "area_3d", "rug", "vrm", "vrm.range", "curv", "pro.curv", "pro.range.log", "plan.curv", "plan.range.log"))
# mpq.test <- subset(mpq, select = c("year", "pub.site",  "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "year.site.ppq", "area_2d", "area_3d", "rug", "vrm", "vrm.range", "curv", "pro.curv", "pro.range", "plan.curv", "plan.range"))


# ggplot(mpq.test, aes(x = year, y=pro.range, fill=year)) + facet_wrap(~hum_dist) + geom_boxplot() + theme_classic(base_size = 18) + xlab("") + ylab("Mean") + ggtitle("Profile Curvature") +  theme(legend.position="none") 
# ggplot(mpq.test, aes(x = year, y=plan.range, fill=year)) + facet_wrap(~hum_dist) + geom_boxplot() + theme_classic(base_size = 18) + xlab("") + ylab("Mean") + ggtitle("Profile Curvature") +  theme(legend.position="none") 


# 
# ggplot(mpq, aes(x = year, y=plan.range.log, fill=year)) + geom_boxplot() + theme_classic(base_size = 18) + xlab("") + ylab("Mean") + ggtitle("Profile Curvature") +  theme(legend.position="none") 

#Rename 2 collumns
colnames(mpq)[which(names(mpq)=="pro.curv")] <- "mean.pro.curv"
colnames(mpq)[which(names(mpq)=="plan.curv")] <- "mean.plan.curv"

mpq

#Subset out 4cm and 8cm dataframes
mpq.dem.4cm <- subset(mpq, DEM == 4)
mpq.dem.8cm <- subset(mpq, DEM==8)

write.csv(mpq.dem.4cm,"~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_FULL_4cm_Data_22Jan21.csv")
write.csv(mpq.dem.8cm,"~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_FULL_8cm_Data_22Jan21.csv")


```

#Subset full complexity df for dignitization
```{r}
#Dataframe to combine with digitization dataframe
mpq.3yrs <- subset(mpq, year == 2015 | year == 2017 | year == 2019) #Dataframe to link with digitization datasets
mpq.3yrs.1cm <- subset(mpq.3yrs, DEM == 1)
mpq.3yrs.4cm <- subset(mpq.3yrs, DEM == 4)
mpq.3yrs.8cm <- subset(mpq.3yrs, DEM == 8)

#Create complexity dataframe first with ALL different metrics
mpq.3yrs.1cm.need.frac <- subset(mpq.3yrs, DEM == 1) #Add Fractal dimension to this 
mpq.3yrs.4cm <- subset(mpq.3yrs, DEM == 4)
mpq.3yrs.8cm <- subset(mpq.3yrs, DEM == 8)

nrow(mpq.3yrs.1cm) #80
nrow(mpq.3yrs.4cm) #80
nrow(mpq.3yrs.8cm) #80

#Need to add in fractal dimension to 1cm dataframe
slope1 #Fractal dataframe
nrow(slope1) #127
slope <- subset(slope1, year == 2015 | year == 2017 | year == 2019)
nrow(slope) #80



mpq.1cm <- cbind(mpq.3yrs.1cm,slope)
mpq.3yrs.1cm <- subset(mpq.1cm, select = c("year", "pub.site", "site", "ppq", "hum_dist", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "area_3d", "rug", "vrm", "vrm.range", "curv", "mean.pro.curv", "pro.range.log", "mean.plan.curv", "plan.range.log", "fractal.dimension"))

mpq.4cm <- mpq.3yrs.4cm
mpq.3yrs.4cm <- subset(mpq.4cm, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "area_3d", "rug", "vrm", "vrm.range", "curv", "mean.pro.curv", "pro.range.log", "mean.plan.curv", "plan.range.log"))


mpq.8cm <- mpq.3yrs.8cm
mpq.3yrs.8cm <- subset(mpq.8cm, select = c("year", "pub.site", "site", "ppq", "hum_dist", "hdist.cont", "sqrt.hdist.cont", "island.side", "region.3", "DEM", "area_3d", "rug", "vrm", "vrm.range", "curv", "mean.pro.curv", "pro.range.log", "mean.plan.curv", "plan.range.log"))


#Final Complexity Dataframes
mpq.3yrs.1cm
mpq.3yrs.4cm
mpq.3yrs.8cm


#Export the digitization Dataframes to merge with digitization data

write.csv(mpq.3yrs.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_3yrs_1cm_Data_14Jan21.csv")
write.csv(mpq.3yrs.4cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_3yrs_4cm_Data_14Jan21.csv")
write.csv(mpq.3yrs.8cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_3yrs_8cm_Data_14Jan21.csv")


#Make full metric dataframe by adding fractal dimension data to 1cm DEM data
frac <- subset(slope1, select = c("fractal.dimension"))
mpq.1cm.dem <- subset(mpq, DEM == 1)

nrow(mpq.1cm.dem) #127 rows
nrow(frac) #127 rows

#Cbind in slope with full complexity dataframe
mpq.all <- cbind(mpq.1cm.dem,frac)

#Export the Dataframe for 1cm
write.csv(mpq.all, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complexity_FULL_1cm_Data_14Jan21.csv")
# 

# Curvature Range Data #Profile Curv Range log transformed
# ggplot(mpq.all, aes(x=pro.range.log)) +
#  geom_histogram(aes(y=..density..), colour="black", fill="white", bins= 30)+
#  geom_density(alpha=.2, fill="#FF6666") + labs(title="red = mean | blue = median",x="Profile Curv Range (log) ", y = "Density") + geom_vline(aes(xintercept = mean(pro.range.log)),col='red',size=0.3) + geom_vline(aes(xintercept = median(pro.range.log)),col='blue',size=0.3)

#Planform Curv Range log transformed
# ggplot(mpq.all, aes(x=plan.range.log)) + 
#  geom_histogram(aes(y=..density..), colour="black", fill="white", bins= 30)+
#  geom_density(alpha=.2, fill="#FF6666") + labs(title="red = mean | blue = median",x="Planform Curv Range (log)", y = "Density") + geom_vline(aes(xintercept = mean(plan.range.log)),col='red',size=0.3) + geom_vline(aes(xintercept = median(plan.range.log)),col='blue',size=0.3)





```

### ArcMap Complexity Distributions
```{r distributions of complexity data, include=FALSE}
mpq

#Metrics
#Surface Rugosity = bounded from 1 upwards
#VRM= "bounded" from 4 to -4, but never reaches those so should appear normal
#Profile Curvature = 
#Planform Curvature = 
# Habitat Volume = unbounded/continuous

###Surface Complexity##
#Simple linear model with DHARMa package to see residuals
m1a <- lm(rug ~ year, data= mpq)
m1.1a<- simulateResiduals(m1a)
plot(m1.1a)

#Not good, try going to a log-normal distribution
mpq$log.s.rug <- "blank"
mpq$log.s.rug <- log(mpq$rug)

#Log normal distribution
m1 <- lm(log.s.rug ~ year, data= mpq)
m1.1<- simulateResiduals(m1)
plot(m1.1)

ggplot(mpq, aes(x = rug)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(rug, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)

#Log transformed data
ggplot(mpq, aes(x = log.s.rug)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(log.s.rug, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


#VRM
m2 <- lm(vrm ~ year, data= mpq)
m2.1<- simulateResiduals(m2)
plot(m2.1)

##VRM
ggplot(mpq, aes(x = vrm)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .001, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(vrm, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


#Profile Curvature
m3 <- lm(pro.curv ~ year, data= mpq)
m3.1<- simulateResiduals(m3)
plot(m3.1)

ggplot(mpq, aes(x = pro.curv)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 10, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(pro.curv, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)

#Planform Curvature
m4 <- lm(plan.curv ~ year, data= mpq)
m4.1<- simulateResiduals(m4)
plot(m4.1)

ggplot(mpq, aes(x = plan.curv)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 10, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(plan.curv, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)

#Habitat Volume
m5 <- lm(volume.change ~ timepoint, data= CC.total)
m5.1<- simulateResiduals(m3)
plot(m5.1)

#Non-transformed data  
ggplot(CC.total, aes(x = volume.change)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(volume.change, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)



plot(fitted(m5), resid(m5))
qqnorm(resid(m5))
qqline(resid(m5))



#Transform to new distribution which can compute it out of negative values as well! (apparently not a good idea- according to DOM)
CC.total$cube.change <- "blank"
CC.total$cube.change <- CC.total$volume.change ^ 1/3

m5.a <- lm(cube.change ~ timepoint, data= CC.total)
m5.1.a<- simulateResiduals(m5.a)
plot(m5.1.a)


###### RANGE DATA #######
#VRM Range
m6 <- lm(vrm.range ~ year, data= range.final)
m6.1<- simulateResiduals(m6)
plot(m6.1)

#Non-transformed data  
ggplot(range.final, aes(x = vrm.range)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = .1, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(vrm.range, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)



#Profile Curvature Range
m7 <- lm(pro.range ~ year, data= range.final)
m7.1<- simulateResiduals(m7)
plot(m7.1)

#Non-transformed data  
ggplot(range.final, aes(x = pro.range)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 100000, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(pro.range, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


#Planform Curvature Range
m8 <- lm(plan.range ~ year, data= range.final)
m8.1<- simulateResiduals(m8)
plot(m8.1)

#Non-transformed data  
ggplot(range.final, aes(x = plan.range)) +
  geom_histogram(aes(y = ..density..), # the histogram will display "density" on its y-axis
                 binwidth = 100000, colour = "blue", fill = "white") +
  geom_density(alpha = .2, fill="#FF6655") +
  geom_vline(aes(xintercept = mean(plan.range, na.rm = T)),
             colour = "red", linetype ="longdash", size = .8)


```


# ArcMap Digitization
### 1. Combine full dataframe 
```{r Combining and cleaning dataframes of digitization data, include = FALSE}
#loading the data
setwd("~/Desktop/GitHub/Bruce_MPQ_Analysis/Data") 
dig.15 <- read.csv("2015.MPQ.Digitization.Data.Final.csv")
dig.17 <- read.csv("2017.MPQ.Digitization.Data.Final.csv")
dig.19 <- read.csv("2019.MPQ.Digitization.Data.Final.csv")

#Filter out extra collumns that mess up the merging process (if they exist)
names(dig.15)
names(dig.17)
names(dig.19)
#dig.15 <- dig.15 %>% select(-c (X, X.1, X.2, X.3, X.4, X.5)) <- to take out collumns I don't want
#dig.17 <- dig.17 %>% select(-c (X, X.1))
#dig.19 <- dig.19 %>% select(-c (X, X.1, X.2, X.3, X.4, X.5))

#Merge all data together
dig <- rbind(dig.15, dig.17, dig.19)

#Rename shape_area to area
colnames(dig)[which(names(dig)=="Year")] <- "year"
colnames(dig)[which(names(dig)=="SHAPE_Area")] <- "area"

#For loop time! Make for looks to add values for human disturbance, publication site name, and region
#1. Add according values to human dist collumn
#1a. Create a collumn for region & fill it with values
dig$hum_dist <- "a"

#1b. Add human dist values
for(i in c(1:nrow(dig))) {
  if(dig$site[i]=="5") {
    dig$hum_dist[i] <- "Very Low"
  } else if(dig$site[i]=="19") {
    dig$hum_dist[i] <- "Very Low"
  } else if(dig$site[i]=="15") {
    dig$hum_dist[i] <- "Very Low"
  } else if(dig$site[i]=="8") {
    dig$hum_dist[i] <- "Medium"
  } else if(dig$site[i]=="34") {
    dig$hum_dist[i] <- "Medium"
  } else if(dig$site[i]=="35") {
   dig$hum_dist[i] <- "Medium"
  } else if(dig$site[i]=="27") {
   dig$hum_dist[i] <- "Very High"
  } else if(dig$site[i]=="30") {
   dig$hum_dist[i] <- "Very High"
  } else if(dig$site[i]=="32") {
    dig$hum_dist[i] <- "Very High"
  } else if(dig$site[i]=="37") {
    dig$hum_dist[i] <- "Very Low"
  }}

#2a. Create a collumn for region & fill it with values
dig$region <- "a"

#2b. Assign Region values
for(i in c(1:nrow(dig))) {
  if(dig$site[i]=="5") {
    dig$region[i] <- "Vaskes"
  } else if(dig$site[i]=="19") {
    dig$region[i] <- "BOW"
  } else if(dig$site[i]=="15") {
    dig$region[i] <- "BOW"
  } else if(dig$site[i]=="8") {
    dig$region[i] <- "S.Lagoon"
  } else if(dig$site[i]=="34") {
    dig$region[i] <- "S.Lagoon"
  } else if(dig$site[i]=="35") {
   dig$region[i] <- "S.Lagoon"
  } else if(dig$site[i]=="27") {
   dig$region[i] <- "N.Lagoon"
  } else if(dig$site[i]=="30") {
   dig$region[i] <- "N.Lagoon"
  } else if(dig$site[i]=="32") {
    dig$region[i] <- "N.Lagoon"
  } else if(dig$site[i]=="37") {
    dig$region[i] <- "Vaskes"
  }}

#3a. Assign publication name to site
dig$pub.site <- "a"

#3b. Assign Region values
for(i in c(1:nrow(dig))) {
  if(dig$site[i]=="5") {
    dig$pub.site[i] <- "VL3"
  } else if(dig$site[i]=="19") {
    dig$pub.site[i] <- "VL2"
  } else if(dig$site[i]=="15") {
    dig$pub.site[i] <- "VL1"
  } else if(dig$site[i]=="8") {
    dig$pub.site[i] <- "M1"
  } else if(dig$site[i]=="34") {
    dig$pub.site[i] <- "M3"
  } else if(dig$site[i]=="35") {
   dig$pub.site[i] <- "M2"
  } else if(dig$site[i]=="27") {
   dig$pub.site[i] <- "VH1"
  } else if(dig$site[i]=="30") {
   dig$pub.site[i] <- "VH3"
  } else if(dig$site[i]=="32") {
    dig$pub.site[i] <- "VH2"
  } else if(dig$site[i]=="37") {
    dig$pub.site[i] <- "VL4"
  }}

# Make a unique column for year.site.ppq
dig$year.site.ppq <- paste(dig$year, dig$site, dig$ppq, sep=".") 
dig$site.ppq <- paste(dig$site, dig$ppq, sep=".") 


#Remove the extra collums in the digitization dataframe that aren't necessary
colnames(dig)
dig <- subset(dig, select = c("year", "hum_dist", "region",  "pub.site", "site", "site.ppq", "year.site.ppq", "ppq" ,"digitizer", "Benthic_Morphology", "area", "SArea"))
colnames(dig)
dig


#Levels of dataframe (make first 4 collumns factors that align with mpq dataframe)
str(dig)
dig$year <- as.factor(dig$year)
dig$hum_dist<- as.factor(dig$hum_dist)
dig$hum_dist <- factor(dig$hum_dist, levels = c("Very High", "Medium", "Very Low" ))
dig$site <- factor(dig$site, levels =c("27", "30", "32", "8", "34", "35", "5", "15", "19", "37"))
dig$site.ppq<- factor(dig$site.ppq, levels = c("27.1", "27.2", "27.3", "30.1", "30.2", "30.3", "32.1", "32.2", "32.3", "8.1", "8.2", "8.3", "34.1", "34.2", "34.3", "35.1", "35.2", "35.3", "5.1", "5.2", "5.3", "15.1", "15.2", "15.3", "19.1", "19.2", "19.3", "37.1", "37.2", "37.3"))
dig$year.site.ppq <- as.factor(dig$year.site.ppq)

dig$year.site.ppq<- factor(dig$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))

levels(dig$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig<- dig[order(dig$year.site.ppq),]
row.names(dig) <- 1:nrow(dig) #Changes the row names so that they are re-orderd 1-80

dig






############################################################################################
#<-----------CREATE Simple Live/Dead Coral Cover Dataframe------------>#
############################################################################################
dig.simple <- dig

#Add new collumn
dig.simple$status <- "Blank"

#4Loop transferring any live coral morphs to "live" and dead = "dead" (macroalgae stays the same)
for(i in c(1:nrow(dig.simple))) {
  if(dig.simple$Benthic_Morphology[i]=="Live_Branching") {
   dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Columnar") {
    dig.simple$status[i] <- "Live.Coral"
 } else if(dig.simple$Benthic_Morphology[i]=="Live_Digitate") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Encrusting") {
    dig.simple$status[i] <- "Live.Coral"
 } else if(dig.simple$Benthic_Morphology[i]=="Live_Encrusting_Columnar") {
    dig.simple$status[i] <- "Live.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Live_Foliose") {
    dig.simple$status[i] <- "Live.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Live_FreeLiving") {
  dig.simple$status[i] <- "Live.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Live_Massive") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Massive_Grooved") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Porites") {
    dig.simple$status[i] <- "Live.Coral"
   } else if(dig.simple$Benthic_Morphology[i]=="Live_SubMassive") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Live_Tabulate") {
    dig.simple$status[i] <- "Live.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Macroalgae") {
    dig.simple$status[i] <- "Macroalgae"
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_Branching") {
    dig.simple$status[i] <- "Dead.Coral"
   } else if(dig.simple$Benthic_Morphology[i]=="Dead_Columnar") {
    dig.simple$status[i] <- "Dead.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_Foliose") {
    dig.simple$status[i] <- "Dead.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="Dead_Massive") {
    dig.simple$status[i] <- "Dead.Coral"  
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_SoftCoral") {
    dig.simple$status[i] <- "Dead.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Dead_Tabulate") {
    dig.simple$status[i] <- "Dead.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_Branching") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_Encrusting") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_Massive") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="NonCoral_SubMassive") {
    dig.simple$status[i] <- "Non.Coral"
  } else if(dig.simple$Benthic_Morphology[i]=="Rubble") {
    dig.simple$status[i] <- "Rubble"
} else if(dig.simple$Benthic_Morphology[i]=="Sand") {
    dig.simple$status[i] <- "Sand"
} else if(dig.simple$Benthic_Morphology[i]=="SoftCoral_Nodular") {
    dig.simple$status[i] <- "Soft.Coral"
} else if(dig.simple$Benthic_Morphology[i]=="SoftCoral_Plating") {
    dig.simple$status[i] <- "Soft.Coral"
}}


#<-----------Summarize Area by Morphology------------>#
#Change area to numeric
dig.simple$area <- as.numeric(dig.simple$area)

# Summarize the total area of each morphology in Long format
str(dig.simple$area)
dig_sum_simple <- dig.simple %>% dplyr::group_by(year, hum_dist, region, site, ppq, year.site.ppq, status) %>% dplyr::summarise(Area = sum(area))

#creating a matrix with the total areas for each year site ppq combination
total_area1 <- dig_sum_simple %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig_sum_simple$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig_sum_simple$year)) {
  xx <- subset(total_area1, year.site.ppq == dig_sum_simple$year.site.ppq[i])
  
  dig_sum_simple$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area into a numeric
dig_sum_simple$Tot_Area <- as.numeric(dig_sum_simple$Tot_Area)

#Calculate proportional and percent cover
dig_sum_simple$per_area <- (dig_sum_simple$Area / dig_sum_simple$Tot_Area) *100 #Calculate percent coverage of each type
dig_sum_simple$prop_area <- (dig_sum_simple$Area / dig_sum_simple$Tot_Area)  #Calculate proportional coverage of each type

#Create unique collumn site.ppq
dig_sum_simple$site.ppq <- paste(dig_sum_simple$site, dig_sum_simple$ppq, sep=".")
colnames(dig_sum_simple)
dig.simple.final <- subset(dig_sum_simple, select = c("year", "hum_dist", "region","site", "ppq","site.ppq", "year.site.ppq", "status", "per_area", "prop_area"))


#Convert to wide format
dig_simple_per_w <- dcast(dig_sum_simple, year + hum_dist + region+ site + site.ppq + year.site.ppq ~status, value.var="per_area", fun.aggregate = sum) 
dig_simple_prop_w <- dcast(dig_sum_simple, year + hum_dist + region+ site + site.ppq + year.site.ppq ~status, value.var="prop_area", fun.aggregate = sum) 

#Dataframes
dig_simple_per_w 
dig_simple_prop_w 


# < ---------- 2b Plot percent cover ---------> #

# #Set Color Pallette
# #Correct levels for how the morphologies will show up on the graph (first ones listed will be the bars stacked on the top)
# dig_sum_simple$status <- factor(dig_sum_simple$status, levels = c("Sand", "Rubble", "Dead.Coral", "Macroalgae", "Non.Coral", "Soft.Coral", "Live.Coral"))
# 
# ##<------Set Colour Pallettes for each morphology type ----->
# sum.simple.cols <- c("Gray30", "Gray35", "Gray40", "Forest Green", "yellow","mediumseagreen", "Dodger Blue")
# 
# morph.sum.simple.colscale<- scale_fill_manual(name="", values=sum.simple.cols, breaks=c("Sand", "Rubble", "Dead.Coral", "Macroalgae", "Non.Coral", "Soft.Coral", "Live.Coral"))





# <--------- 3b. Calculating colony counts of this dataframe -------> #
dig.simple

#Create new dataframe for simple polygon # count
dig.simple2 <- subset(dig.simple, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "status"))
colnames(dig.simple2)

#Add a collumn called "count" with a 1 in it
dig.simple2$count <- 1

#Switch to wide format now
dig.simple2.w <- dcast(dig.simple2, year + hum_dist + region+ site + site.ppq + year.site.ppq ~status, value.var="count", fun.aggregate = sum)

dig.simple2.w

#Summarize by year
dig.simple2.w2 <- dcast(dig.simple2, year ~status, value.var="count", fun.aggregate = sum)

#2015 = 7867 Living Colonies
#2017 = 2504 Living Colonies
#2019 = 5497 Living Colonies
#Total Colonies Digitized = #15,868
#7867+ 2504 + 5497 #15,868


#Plot through time

# ggplot(dig_sum_simple, aes(y=per_area, x=year.site.ppq, fill= status)) + geom_bar(stat = 'identity', position = 'stack') + morph.sum.simple.colscale +theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1) +  geom_vline(xintercept = 20.5, linetype="dashed", color="black", size=0.5)) + geom_vline(xintercept = 56.5, linetype="solid", color="red", size=0.5) + 
#     xlab("Year-Site-PPQ") + ylab("Percent Cover") + #label titles
#   geom_vline(xintercept = 26.5, linetype="solid", color="red", size=0.5)+ theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) + 
#   geom_vline(xintercept = 18.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) + 
#   geom_vline(xintercept = 9.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))  + 
#   geom_vline(xintercept = 35.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) +
# geom_vline(xintercept = 44.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) +
# geom_vline(xintercept = 65.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1)) +
# geom_vline(xintercept = 74.5, linetype="dashed", color="Magenta", size=0.5)+theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))








############################################################################
#################### Semi Dataframe ########################################
############################################################################


#<----Dataframe where massive category includes live_massive and live_massive_grooved --->#
dig2 <- dig

dig2$Benthic_Morphology[dig2$Benthic_Morphology == "Live_Massive_Grooved"] <- "Live_Massive"
dig2$Benthic_Morphology[dig2$Benthic_Morphology == "Live_Digitate"] <- "Live_Branching"
# dig2$Benthic_Morphology[dig2$Benthic_Morphology == "Live_Porites"] <- "Live_Massive"

dig2


#Change area to numeric
dig2$area <- as.numeric(dig2$area)

#Re-input this column
dig2$year.site.ppq <- paste(dig2$year, dig2$site, dig2$ppq, sep=".") 

# Summarize the total area of each morphology in Long format
str(dig2$area)
dig2_sum <- dig2 %>% dplyr::group_by(year, hum_dist, region, site, site.ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(Area = sum(area))


# Wide format total area
dig2.wide <- tidyr::spread(dig2_sum, Benthic_Morphology, Area)
dig2.wide[is.na(dig2.wide)] <- 0

#Create a matrix with the total areas for each year site ppq combination
total_area2 <- dig2_sum %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig2_sum$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig2_sum$year)) {
  xx <- subset(total_area2, year.site.ppq == dig2_sum$year.site.ppq[i])
  
  dig2_sum$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area into a numeric
dig2_sum$Tot_Area <- as.numeric(dig2_sum$Tot_Area)

#Calculate proportional and percent cover
dig2_sum$per_area <- (dig2_sum$Area / dig2_sum$Tot_Area) *100 #Calculate percent coverage of each type
dig2_sum$prop_area <- (dig2_sum$Area / dig2_sum$Tot_Area)  #Calculate proportional coverage of each type

#Convert to wide format
dig2_prop_w <- dcast(dig2_sum, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="prop_area", fun.aggregate = sum) #Convert to wide format

dig2_perc_w <- dcast(dig2_sum, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="per_area", fun.aggregate = sum) #Convert to wide format


# <--------- 3b. Calculating colony counts of this dataframe -------> #
dig2 

#Create new dataframe for simple polygon # count
dig2.num <- subset(dig2, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Benthic_Morphology"))
colnames(dig2.num)

#Add a collumn called "count" with a 1 in it
dig2.num$count <- 1

#Switch to wide format now
dig2.num.w <- dcast(dig2.num, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="count", fun.aggregate = sum)

#Only include categories of "live" colonies
dig2.num.live <- subset(dig2.num.w, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Live_Branching",  "Live_Columnar", "Live_Digitate", "Live_Encrusting", "Live_Encrusting_Columnar", "Live_Foliose", "Live_FreeLiving" , "Live_Massive" , "Live_SubMassive", "Live_Tabulate" , "NonCoral_Encrusting" , "NonCoral_Massive" , "NonCoral_SubMassive",  "SoftCoral_Nodular" , "SoftCoral_Plating",  "NonCoral_Branching"))


#Dataframe for colony count (wide)
dig2.num.w <- dig2.num.live

#End Databases
dig2_prop_w 
dig2_perc_w 
dig2.num.w








#############################################################################
########################### FULL DATABASE ###################################
#############################################################################
#Change area to numeric
dig$area <- as.numeric(dig$area)

# Summarize the total area of each morphology in Long format
str(dig$area)
dig_sum <- dig %>% dplyr::group_by(year, hum_dist, region, site, site.ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(Area = sum(area))

# Wide format total area
dig_wide <- tidyr::spread(dig_sum, Benthic_Morphology, Area)
dig_wide[is.na(dig_wide)] <- 0

#Summarized dataframe of 2d surface area in the plots
dig_sum

#Calculate the % of each morphology at each plot & Graph the proportion of  each morphology   present at each plot using stacked bar charts

#creating a matrix with the total areas for each year site ppq combination
total_area <- dig_sum %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig_sum$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig_sum$year)) {
  xx <- subset(total_area, year.site.ppq == dig_sum$year.site.ppq[i])
  
  dig_sum$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area
dig_sum$Tot_Area <- as.numeric(dig_sum$Tot_Area)

#Calculate percent cover
dig_sum$per_area <- (dig_sum$Area / dig_sum$Tot_Area) * 100 #Calculate percent coverage of each type

#Convert to wide format
dig_per_w<- dcast(dig_sum, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="per_area", fun.aggregate = sum) #Convert to wide format


#### <----- 3a. Proportional Coverage Data ----> ###
#Create a proportional coverage dataframe too
dig_cover <- dig_sum
dig_cover$prop_area <- (dig_cover$Area / dig_cover$Tot_Area) #Calculate proportional coverage of each type
dig_prop_w <- dcast(dig_cover, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="prop_area", fun.aggregate = sum) #Convert to wide format

#Dataframes
dig_per_w #Percent coverage wide
dig_prop_w #Proportional coverage wide


# <--------- 3b. Calculating colony counts of this dataframe -------> #

#Create new dataframe for simple polygon # count
dig.num <- subset(dig, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Benthic_Morphology"))
colnames(dig.num)

#Add a collumn called "count" with a 1 in it
dig.num$count <- 1

#Summarize by status
dig.num.summarized <- dig.num %>% dplyr::group_by(year, hum_dist, region, site, site.ppq, Benthic_Morphology) %>% dplyr::summarise(Count = sum(count))

#Switch to wide format now
dig.num.w <- dcast(dig.num, year + hum_dist + region+ site + site.ppq + year.site.ppq ~Benthic_Morphology, value.var="count", fun.aggregate = sum)
colnames(dig.num.w)
  
#Only include categories of "live" colonies
dig.num.w1 <- subset(dig.num.w, select = c("year", "hum_dist", "region", "site", "site.ppq", "year.site.ppq", "Live_Branching", "Live_Columnar", "Live_Digitate", "Live_Encrusting","Live_Encrusting_Columnar","Live_Foliose",     "Live_FreeLiving", "Live_Massive","Live_Massive_Grooved", "Live_Porites", "Live_SubMassive", "Live_Tabulate", "NonCoral_Encrusting", "NonCoral_Massive", "NonCoral_SubMassive",  "SoftCoral_Nodular", "SoftCoral_Plating", "NonCoral_Branching"))

#Add unique code at end to differentiate these #'s from the % cover df
#Change Names of collumns
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Branching")] <- "DB.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Columnar")] <- "DC.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Foliose")] <- "DF.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Massive")] <- "DM.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_SoftCoral")] <- "DS.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Dead_Tabulate")] <- "DT.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Branching")] <- "LB.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Columnar")] <- "LC.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Digitate")] <- "LD.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Encrusting")] <- "LE.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Encrusting_Columnar")] <- "LEC.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Foliose")] <- "LF.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_FreeLiving")] <- "LFL.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Massive")] <- "LM.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Massive_Grooved")] <- "LMG.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Porites")] <- "LP.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_SubMassive")] <- "LS.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Live_Tabulate")] <- "LT.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Macroalgae")] <- "M.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_Encrusting")] <- "NCE.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_Massive")] <- "NCM.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_SubMassive")] <- "NCS.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Rubble")] <- "R.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="Sand")] <- "S.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="SoftCoral_Nodular")] <- "SCN.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="SoftCoral_Plating")] <- "SCP.count"
colnames(dig.num.w1)[which(names(dig.num.w1)=="NonCoral_Branching")] <- "NCB.count"

#Dataframe for colony count (wide)
dig.num.w1



#########################################################################
###################### Jenn Magel's Classification ######################
#########################################################################
dig.jm <- dig
 
#Rename morphologies into Jenn's Coarse classification
#4Loop transferring any live coral morphs to "live" and dead = "dead" (macroalgae stays the same)
for(i in c(1:nrow(dig.jm))) {
  if(dig.jm$Benthic_Morphology[i]=="Live_Branching") {
   dig.jm$Benthic_Morphology[i] <- "Branching"
  } else if(dig.jm$Benthic_Morphology[i]=="Live_Columnar") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
 } else if(dig.jm$Benthic_Morphology[i]=="Live_Digitate") {
    dig.jm$Benthic_Morphology[i] <- "Branching"
  } else if(dig.jm$Benthic_Morphology[i]=="Live_Encrusting") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
 } else if(dig.jm$Benthic_Morphology[i]=="Live_Encrusting_Columnar") {
    dig.jm$Benthic_Morphology[i] <- "Plating"
} else if(dig.jm$Benthic_Morphology[i]=="Live_Foliose") {
    dig.jm$Benthic_Morphology[i] <- "Plating"
} else if(dig.jm$Benthic_Morphology[i]=="Live_FreeLiving") {
  dig.jm$Benthic_Morphology[i] <- "Massive"
} else if(dig.jm$Benthic_Morphology[i]=="Live_Massive") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
  } else if(dig.jm$Benthic_Morphology[i]=="Live_Massive_Grooved") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
  } else if(dig.jm$Benthic_Morphology[i]=="Live_Porites") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
   } else if(dig.jm$Benthic_Morphology[i]=="Live_SubMassive") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
  } else if(dig.jm$Benthic_Morphology[i]=="Live_Tabulate") {
    dig.jm$Benthic_Morphology[i] <- "Plating"
  } else if(dig.jm$Benthic_Morphology[i]=="Macroalgae") {
    dig.jm$Benthic_Morphology[i] <- "Macroalgae"
  } else if(dig.jm$Benthic_Morphology[i]=="Dead_Branching") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
   } else if(dig.jm$Benthic_Morphology[i]=="Dead_Columnar") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
  } else if(dig.jm$Benthic_Morphology[i]=="Dead_Foliose") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
} else if(dig.jm$Benthic_Morphology[i]=="Dead_Massive") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
  } else if(dig.jm$Benthic_Morphology[i]=="Dead_SoftCoral") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
  } else if(dig.jm$Benthic_Morphology[i]=="Dead_Tabulate") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
  } else if(dig.jm$Benthic_Morphology[i]=="NonCoral_Branching") {
    dig.jm$Benthic_Morphology[i] <- "Branching"
  } else if(dig.jm$Benthic_Morphology[i]=="NonCoral_Encrusting") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
  } else if(dig.jm$Benthic_Morphology[i]=="NonCoral_Massive") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
  } else if(dig.jm$Benthic_Morphology[i]=="NonCoral_SubMassive") {
    dig.jm$Benthic_Morphology[i] <- "Massive"
  } else if(dig.jm$Benthic_Morphology[i]=="Rubble") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
} else if(dig.jm$Benthic_Morphology[i]=="Sand") {
    dig.jm$Benthic_Morphology[i] <- "Abiotic"
} else if(dig.jm$Benthic_Morphology[i]=="SoftCoral_Nodular") {
    dig.jm$Benthic_Morphology[i] <- "Plating"
} else if(dig.jm$Benthic_Morphology[i]=="SoftCoral_Plating") {
    dig.jm$Benthic_Morphology[i] <- "Plating"
}}


dig.jm





#<-----------Summarize Area by Morphology------------>#
#Change area to numeric
dig.jm$area <- as.numeric(dig.jm$area)

# Summarize the total area of each morphology in Long format
str(dig.jm$area)
dig.jm.sum <- dig.jm %>% dplyr::group_by(year, hum_dist, region, site, ppq, year.site.ppq, Benthic_Morphology) %>% dplyr::summarise(Area = sum(area))

#creating a matrix with the total areas for each year site ppq combination
total_area2 <- dig.jm.sum %>% dplyr::group_by(year.site.ppq) %>% dplyr::summarise(tot_area = sum(Area))

dig.jm.sum$Tot_Area <- "blank"

#loop that takes the total area for each year site ppq combination and puts it in a new column
for (i in 1:length(dig.jm.sum$year)) {
  xx <- subset(total_area2, year.site.ppq == dig.jm.sum$year.site.ppq[i])
  
  dig.jm.sum$Tot_Area[i] <- xx$tot_area[1]
}

#Turn area into a numeric
dig.jm.sum$Tot_Area <- as.numeric(dig.jm.sum$Tot_Area)

#Calculate proportional and percent cover
dig.jm.sum$per_area <- (dig.jm.sum$Area / dig.jm.sum$Tot_Area) *100 #Calculate percent coverage of each type

#Create unique collumn site.ppq
dig.jm.sum$site.ppq <- paste(dig.jm.sum$site, dig.jm.sum$ppq, sep=".")
colnames(dig.jm.sum)
dig.jm.sum.final <- subset(dig.jm.sum, select = c("year", "hum_dist", "region","site", "ppq","year.site.ppq", "Benthic_Morphology", "per_area"))

#Convert to wide format
dig.jm.wide <- dcast(dig.jm.sum.final, year + hum_dist + region+ site + year.site.ppq + year.site.ppq ~Benthic_Morphology, value.var="per_area", fun.aggregate = sum) 


#Set levels for the dataframe
levels(dig.jm.wide$year.site.ppq)
dig.jm.wide$year.site.ppq<- factor(dig.jm.wide$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(dig.jm.wide$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig.jm.wide<- dig.jm.wide[order(dig.jm.wide$year.site.ppq),]
row.names(dig.jm.wide) <- 1:nrow(dig.jm.wide) #Changes the row names so that they are re-orderd 1-80

#Final Dataframe:
colnames(dig.jm.wide)



#Dataframe that is in long format
dig.jm.sum.final

#Set levels for the dataframe
levels(dig.jm.sum.final$year.site.ppq)
dig.jm.sum.final$year.site.ppq<- factor(dig.jm.sum.final$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2016a.27.1", "2016a.27.2", "2016a.27.3", "2016a.32.1", "2016a.32.2", "2016a.32.3", "2016a.30.1", "2016a.30.2", "2016a.30.3", "2016a.8.1", "2016a.8.2", "2016a.8.3", "2016a.35.1", "2016a.35.2", "2016a.34.1", "2016a.34.2", "2016a.34.3", "2016a.15.1", "2016a.5.1", "2016a.5.2", "2016a.5.3","2016b.27.1", "2016b.27.2", "2016b.27.3", "2016b.32.1", "2016b.32.2", "2016b.32.3", "2016b.30.1", "2016b.30.2", "2016b.30.3", "2016b.8.1", "2016b.8.2", "2016b.8.3", "2016b.35.1", "2016b.35.2", "2016b.35.3",  "2016b.34.1", "2016b.34.2", "2016b.34.3", "2016b.15.1", "2016b.15.2", "2016b.15.3", "2016b.19.1", "2016b.19.2", "2016b.5.1", "2016b.5.2", "2016b.5.3","2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))
levels(dig.jm.sum.final$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig.jm.long <- dig.jm.sum.final[order(dig.jm.sum.final$year.site.ppq),]
row.names(dig.jm.sum.final) <- 1:nrow(dig.jm.sum.final) #Changes the row names so that they are re-orderd 1-80

#Final Dataframe:
colnames(dig.jm.long)


```




### 2. Combine Digitization + Complexity Dataframes
```{r combining complexity and digitization dataframes}
#<--------------------- Digitization Dataframes ------------------->
#Full database percent cover
#A. Full Perfent Cover Dataframe
dig_per_w #Full, complex morphological ID system used
dig_per_w$year.site.ppq<- factor(dig_per_w$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))

levels(dig_per_w$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig_per_w<- dig_per_w[order(dig_per_w$year.site.ppq),]
row.names(dig_per_w) <- 1:nrow(dig_per_w) #Changes the row names so that they are re-orderd 1-80

#Compare that rows matchup in the dataframes you are going to merge
mpq.3yrs.1cm
dig_per_w

#Remove any of the metadata from the digitiation dataframe
dig.per.full <- dig_per_w[,-c(1:6, 26:28)] #Remove rare non-coral morphologies too (NOT non-coral_submassive though)

#<---------- Combine Complexity + Digitization dataframes ------>
mpq.dig.1cm <- cbind(mpq.3yrs.1cm,dig.per.full)
mpq.dig.4cm <- cbind(mpq.3yrs.4cm,dig.per.full)
mpq.dig.8cm <- cbind(mpq.3yrs.8cm,dig.per.full)



#####B. Semi- Morphology Dataframe (Massive colonies are less diversified, digitate = Branching)
dig2_perc_w #Live Massive category now includes all massive_grooved; live_Branching now includes live_digitate)
dig2_perc_w$year.site.ppq<- factor(dig2_perc_w$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))

levels(dig2_perc_w$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig2_perc_w<- dig2_perc_w[order(dig2_perc_w$year.site.ppq),]
row.names(dig2_perc_w) <- 1:nrow(dig2_perc_w) #Changes the row names so that they are re-orderd 1-80

#Compare that rows matchup in the dataframes you are going to merge
mpq.3yrs.1cm
dig2_perc_w

#Remove any of the metadata from the digitiation dataframe
dig.per.semi <- dig2_perc_w[,-c(1:6, 24:26)]  #Remove metadata + rare non-coral morphologies (Not non_coral_Submassive though!)


#C. Simplified Live/Dead Morphology Dataframe
dig_simple_per_w
dig_simple_per_w$year.site.ppq<- factor(dig_simple_per_w$year.site.ppq, levels = c("2015.27.1", "2015.27.2", "2015.27.3", "2015.32.1", "2015.32.2", "2015.32.3", "2015.30.1", "2015.30.2", "2015.30.3", "2015.8.1", "2015.8.2", "2015.8.3", "2015.35.1", "2015.35.2", "2015.35.3", "2015.34.1", "2015.34.2", "2015.34.3", "2015.15.1", "2015.15.2", "2015.15.3", "2015.19.1", "2015.19.2", "2015.5.1", "2015.5.2", "2015.5.3", "2017.27.1", "2017.27.2", "2017.27.3", "2017.32.1", "2017.32.2", "2017.32.3", "2017.30.1", "2017.30.2", "2017.30.3", "2017.8.1", "2017.8.2", "2017.8.3", "2017.35.1", "2017.35.2", "2017.35.3", "2017.34.1", "2017.34.2", "2017.34.3", "2017.15.1", "2017.15.2", "2017.15.3", "2017.19.1", "2017.19.2", "2017.19.3", "2017.5.1", "2017.5.2", "2017.5.3", "2017.37.1", "2017.37.2", "2017.37.3", "2019.27.1", "2019.27.2", "2019.27.3", "2019.32.1", "2019.32.2", "2019.32.3", "2019.30.1", "2019.30.2", "2019.30.3", "2019.8.1", "2019.8.2", "2019.8.3", "2019.35.1", "2019.35.2", "2019.35.3", "2019.34.1", "2019.34.2", "2019.34.3", "2019.5.1", "2019.5.2", "2019.5.3", "2019.37.1", "2019.37.2", "2019.37.3"))

levels(dig_simple_per_w$year.site.ppq)

#Reorder dataframe by disturbance publication site names (VH -- M -- VL)
dig_simple_per_w<- dig_simple_per_w[order(dig_simple_per_w$year.site.ppq),]
row.names(dig_simple_per_w) <- 1:nrow(dig_simple_per_w) #Changes the row names so that they are re-orderd 1-80

#Compare that rows matchup in the dataframes you are going to merge
mpq.3yrs.1cm
dig_simple_per_w

#Remove any of the metadata from the digitiation dataframe
dig.per.simple <- dig_simple_per_w[,-c(1:6)]  #Remove metadata + rare non-coral morphologies (Not non_coral_Submassive though!)

#<---------- JM Dataframe ------>
head(dig.jm.wide) 
dim(dig.jm.wide) #80 rows, 11 collumns

#Remove any of the metadata from the digitiation dataframe
dig.jm <- dig.jm.wide[,-c(1:6)]  #Remove metadata + rare non-coral morphologies (Not non_coral_Submassive though!)






#<---------- Combine Complexity + Digitization dataframes ------>
# #Dataframe to combine with digitization dataframe
# mpq.3yrs <- subset(mpq, year == 2015 | year == 2017 | year == 2019) #Dataframe to link with digitization datasets
# 
# mpq.3yrs.1cm <- subset(mpq.3yrs, DEM == 1)
# mpq.3yrs.4cm <- subset(mpq.3yrs, DEM == 4)
# mpq.3yrs.8cm <- subset(mpq.3yrs, DEM == 8)


#1cm
mpq.dig.full.1cm <- cbind(mpq.3yrs.1cm,dig.per.full)
mpq.dig.semi.1cm <- cbind(mpq.3yrs.1cm,dig.per.semi)
mpq.dig.simple.1cm <- cbind(mpq.3yrs.1cm,dig.per.simple)
mpq.dig.jm.1cm <- cbind(mpq.3yrs.1cm,dig.jm)


############################################################################################
#<---------- Export dataframes ------>
#A. 1cm Dataframes
# write.csv(mpq.dig.full.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_FULL_1cm_Data_11Jan21.csv")
# write.csv(mpq.dig.simple.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SIMPLE_1cm_Data_11Jan21.csv")
write.csv(mpq.dig.semi.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_SEMI_1cm_Data_11Jan21.csv")

write.csv(mpq.dig.jm.1cm, "~/Desktop/GitHub/Bruce_MPQ_Analysis/Data/BaumLab_Complex+Digitization_JM.Classificaition_1cm_Data_11Jan21.csv")








```
